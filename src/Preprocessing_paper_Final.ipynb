{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fahim/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame, read_csv, concat, read_table, Series\n",
    "from operator import itemgetter\n",
    "import importlib\n",
    "import re \n",
    "import string\n",
    "import nltk\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import model_helper_functions\n",
    "importlib.reload(model_helper_functions)\n",
    "from model_helper_functions import *\n",
    "import preprocess_helper_functions\n",
    "importlib.reload(preprocess_helper_functions)\n",
    "from preprocess_helper_functions import *\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "from urlextract import URLExtract\n",
    "extractor = URLExtract()\n",
    "rare_word_thresh = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abbrev_words_dict = pickle.load(open('../data/abbreviated_words_map.csv', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def list_to_dict(mylist):\n",
    "    mylist = [str(x).lower() for x in mylist]\n",
    "    ret_dict = dict(zip(mylist, [1]*len(mylist))) #make dictionary for efficient search\n",
    "    return ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_badlist = read_table('../data/profane_list.txt', header=None, comment='#')\n",
    "all_badlist = all_badlist.values.flatten().tolist()\n",
    "all_badlist = sorted(set([x.lower() for x in all_badlist]))\n",
    "all_badlist = [strip_non_printable_chars(str(x)).strip() for x in all_badlist]\n",
    "#all_badlist_dict = dict(zip(all_badlist, [1] * len(all_badlist)))\n",
    "\n",
    "#Read compiled acronyms and see if any acronyms are there\n",
    "acronyms = read_csv('../data/compiled_acronyms_final.csv', encoding = 'latin-1')\n",
    "acronyms = acronyms.apply(lambda x: x.astype(str).str.lower())\n",
    "acronyms = acronyms.dropna()\n",
    "acronyms = acronyms.drop_duplicates().reset_index(drop=True)\n",
    "global acronyms_dict \n",
    "acronyms_dict = dict(acronyms.values)\n",
    "\n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import wordnet\n",
    "proper_words = words.words()\n",
    "proper_words = sorted(set([x.lower() for x in proper_words]))\n",
    "global proper_words_dict\n",
    "proper_words_dict = list_to_dict(proper_words)\n",
    "\n",
    "proper_words.extend(all_badlist)\n",
    "global proper_words_with_profane_dict\n",
    "proper_words_with_profane_dict = list_to_dict(proper_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extreme_profane = read_csv('../data/profane_x_common.csv', header=None)\n",
    "extreme_profane = extreme_profane.values.flatten().tolist()\n",
    "extreme_profane = [x.lower() for x in extreme_profane]\n",
    "\n",
    "badlist3 = read_csv('../data/profane_list_common.csv', encoding='latin-1')\n",
    "badlist_common = badlist3.values.flatten().tolist()\n",
    "badlist_common = [x.lower() for x in badlist_common]\n",
    "\n",
    "all_badlist_combined = sorted(set(all_badlist + badlist_common + extreme_profane))\n",
    "all_badlist_combined_dict = dict(zip(all_badlist_combined, [1] * len(all_badlist_combined)))\n",
    "\n",
    "profane_list_map = read_csv('../data/profane_list_common_mapping.csv', header=None)\n",
    "profane_list_map = profane_list_map.apply(lambda x: x.astype(str).str.lower())\n",
    "profane_list_map = dict(profane_list_map.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "citynames = read_table('../data/citynames.txt', sep='\\t', header=None, encoding='utf-8')\n",
    "citynames = citynames.iloc[:, 1].str.lower().values\n",
    "citynames = list_to_dict(citynames)\n",
    "\n",
    "#Look for countries\n",
    "countries = read_table('../data/countries.txt', header=None).values.flatten()\n",
    "countries = list_to_dict(countries)\n",
    "\n",
    "#Look for nationalities\n",
    "nationalities = read_table('../data/nationalities.txt', header=None).values.flatten()\n",
    "nationalities = list_to_dict(nationalities)\n",
    "\n",
    "ethnicities = read_table('../data/ethnicities.txt', header=None).values.flatten()\n",
    "ethnicities = list_to_dict(ethnicities)\n",
    "\n",
    "#Look for persons name\n",
    "person_names = []\n",
    "for fn in ['../data/names.first.female.txt', \n",
    "           '../data/names.first.male.txt',\n",
    "           '../data/names.last.txt',\n",
    "           '../data/muslim_names.txt',\n",
    "           '../data/englishnames.txt',\n",
    "          ]:\n",
    "    with open(fn, 'r') as ofd:\n",
    "        for line in ofd.readlines():\n",
    "            person_names.append(line.rstrip('\\n').lower())\n",
    "\n",
    "spanishnames = read_csv('../data/spanishnames.csv', encoding='utf-8')['nombre'].str.lower().str.split(' ')\n",
    "spanishnames = list(set(spanishnames.apply(Series).unstack().values))\n",
    "person_names.extend(spanishnames)\n",
    "\n",
    "person_names_dict = list_to_dict(person_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = read_csv(\"../data/train.csv\")\n",
    "train_data.head()\n",
    "train_data.fillna('NULL', inplace= True)\n",
    "train_data['profane'] = train_data[classes].any(axis = 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train_data['profane'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get word frequency table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the Word Frequency table\n",
    "tmp = train_data['comment_text'].str.cat(sep=' ')\n",
    "words = tmp.split()\n",
    "word_dist_dict = nltk.FreqDist(words)\n",
    "word_dist_dict_most_common = word_dist_dict.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_dist_dict_df = DataFrame(word_dist_dict_most_common, columns=['raw_word', 'freq'])\n",
    "word_dist_dict_df.to_csv('../data/word_dist_train.csv', index=False)\n",
    "pickle.dump(word_dist_dict, open('../data/word_dist_train.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp_steps = [\n",
    "            ['raw'],  \n",
    "            ['convert_to_lower'],\n",
    "            ['remove_whitespaces'], \n",
    "            ['remove_leaky'], \n",
    "            ['trim_words_len'],\n",
    "            ['strip_non_printable_chars'],\n",
    "            ['replace_abbreviation_words'],\n",
    "            ['replace_acronyms'],\n",
    "            ['remove_stopwords'],\n",
    "            ['remove_rare_words'],\n",
    "            ['remove_non_alphanumeric'],\n",
    "            ['remove_non_alphabet_words'],\n",
    "            ['remove_words_containing_non_alphabets'],\n",
    "            ['black_listed_words_regex_mapping'],\n",
    "            ['check_if_proper_name_place_or_ethnicity'],\n",
    "            ['replace_profane_words_using_fuzzy'],\n",
    "            ['replace_common_words_using_fuzzy'],\n",
    "            ['lemmatize_english_words'],\n",
    "            ['stemming_english_words'],\n",
    "            ['extract_info_from_url'],\n",
    "       \n",
    "#     ['convert_to_lower', 'remove_whitespaces', 'trim_words_len'],\n",
    "#     ['convert_to_lower', 'remove_whitespaces', 'trim_words_len', \n",
    "#      'strip_non_printable_chars', 'remove_leaky'],\n",
    "#     ['convert_to_lower', 'remove_whitespaces', 'trim_words_len', \n",
    "#      'strip_non_printable_chars',  'replace_abbreviation_words', 'replace_acronyms'],\n",
    "#     ['convert_to_lower', 'remove_whitespaces', 'trim_words_len', \n",
    "#      'strip_non_printable_chars',  'remove_stopwords'],\n",
    "#     ['convert_to_lower', 'remove_whitespaces', 'trim_words_len', \n",
    "#      'strip_non_printable_chars',  'remove_rare_words'],\n",
    "#     ['convert_to_lower', 'remove_whitespaces', 'trim_words_len', \n",
    "#      'strip_non_printable_chars', 'replace_abbreviation_words', 'replace_acronyms', \n",
    "#      'remove_stopwords', 'remove_rare_words'], \n",
    "#     ['convert_to_lower', 'remove_whitespaces', 'trim_words_len', \n",
    "#      'strip_non_printable_chars', 'remove_non_alphanumeric'],\n",
    "#     ['convert_to_lower', 'remove_whitespaces', 'trim_words_len', \n",
    "#      'strip_non_printable_chars', 'remove_non_alphabet_words'],\n",
    "#     ['convert_to_lower', 'remove_whitespaces', 'trim_words_len', \n",
    "#      'strip_non_printable_chars', 'remove_non_alphanumeric', \n",
    "#      'remove_non_alphabet_words'],\n",
    "#     ['convert_to_lower', 'remove_whitespaces', 'trim_words_len', \n",
    "#      'strip_non_printable_chars','replace_abbreviation_words', 'replace_acronyms',\n",
    "#      'black_listed_words_regex_mapping'], \n",
    "#     ['convert_to_lower', 'remove_whitespaces', 'trim_words_len', \n",
    "#      'strip_non_printable_chars','replace_abbreviation_words', 'replace_acronyms',\n",
    "#      'black_listed_words_regex_mapping', 'replace_profane_words_using_fuzzy', \n",
    "#      'replace_common_words_using_fuzzy'],\n",
    "#     ['convert_to_lower', 'remove_whitespaces', 'trim_words_len', \n",
    "#      'strip_non_printable_chars','replace_abbreviation_words',  'replace_acronyms', \n",
    "#      'remove_leaky',  'extract_info_from_url',  'black_listed_words_regex_mapping', \n",
    "#      'replace_profane_words_using_fuzzy', 'replace_common_words_using_fuzzy', \n",
    "#      'check_if_proper_name_place_or_ethnicity'],\n",
    "#     ['convert_to_lower', 'remove_whitespaces', 'trim_words_len', \n",
    "#      'strip_non_printable_chars', 'replace_abbreviation_words',  'replace_acronyms', \n",
    "#      'remove_leaky',  'remove_non_alphabet_words', 'remove_stopwords', \n",
    "#      'stemming_english_words'],\n",
    "#     ['convert_to_lower', 'lemmatize_english_words'],\n",
    "#     ['convert_to_lower','remove_non_alphabet_words', \n",
    "#      'black_listed_words_regex_mapping',  'replace_common_words_using_fuzzy', \n",
    "#      'stemming_english_words']\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 30\n",
    "\n",
    "def get_corresponding_mapping(word_dist_dict_most_common, op_type):\n",
    "    print(op_type)\n",
    "    if op_type == 'raw':\n",
    "        new_dict = dict([(x[0], x[0]) for x in word_dist_dict_most_common])\n",
    "    elif op_type ==  'convert_to_lower': # remove white spaces \n",
    "        new_dict = convert_to_lower_from_dict(word_dist_dict_most_common)\n",
    "    elif op_type ==  'remove_whitespaces': # remove white spaces \n",
    "        new_dict = remove_white_spaces_from_dict(word_dist_dict_most_common)\n",
    "    elif op_type == 'remove_leaky':\n",
    "        new_dict = remove_leaky_information_from_dict(word_dist_dict_most_common)\n",
    "    elif op_type == 'extract_info_from_url':\n",
    "        new_dict = extract_info_from_url(word_dist_dict_most_common, extractor)\n",
    "    elif op_type == 'trim_words_len':\n",
    "        new_dict = trim_words_len(word_dist_dict_most_common, maxlen)\n",
    "    elif op_type == 'replace_abbreviation_words':\n",
    "        new_dict = replace_abbreviation_words_from_dict(word_dist_dict_most_common, abbrev_words_dict)\n",
    "    elif op_type == 'strip_non_printable_chars':\n",
    "        new_dict = strip_non_printable_chars_from_dict(word_dist_dict_most_common)\n",
    "    elif op_type == 'replace_acronyms':\n",
    "        new_dict = replace_acronyms_from_dict(word_dist_dict_most_common, acronyms_dict, proper_words_with_profane_dict)\n",
    "    elif op_type == 'remove_stopwords':\n",
    "        new_dict = remove_stopwords_from_dict(word_dist_dict_most_common, stop_words_dict)\n",
    "    elif op_type == 'remove_rare_words':\n",
    "        new_dict = remove_rare_words_from_dict(word_dist_dict_most_common, word_dist_dict, rare_word_thresh)\n",
    "    elif op_type == 'remove_non_alphanumeric':\n",
    "        new_dict = remove_non_alphanumeric_from_dict(word_dist_dict_most_common)    \n",
    "    elif op_type == 'remove_non_alphabet_words':\n",
    "        new_dict = remove_non_alphabet_words(word_dist_dict_most_common)    \n",
    "    elif op_type == 'remove_words_containing_non_alphabets':\n",
    "        new_dict = remove_words_containing_non_alphabets_from_dict(word_dist_dict_most_common)    \n",
    "    elif op_type == 'black_listed_words_regex_mapping':\n",
    "        new_dict = black_listed_words_regex_mapping_from_dict(word_dist_dict_most_common, all_badlist, profane_list_map, extreme_profane)\n",
    "    elif op_type == 'replace_profane_words_using_fuzzy':\n",
    "        new_dict = replace_profane_words_using_fuzzy(word_dist_dict_most_common, proper_words_dict, extreme_profane, profane_list_map, badlist_common)\n",
    "    elif op_type == 'check_if_proper_name_place_or_ethnicity':\n",
    "        new_dict = check_if_proper_name_place_or_ethnicity_from_dict(word_dist_dict_most_common, proper_words_dict, citynames, countries, nationalities, \\\n",
    "                                              ethnicities, person_names_dict)\n",
    "    elif op_type == 'replace_common_words_using_fuzzy':\n",
    "        new_dict = replace_common_words_using_fuzzy(word_dist_dict_most_common, word_dist_dict_most_common, wordnet_lemmatizer, proper_words_dict)\n",
    "    elif op_type == 'lemmatize_english_words':\n",
    "        new_dict = lemmatize_english_words(word_dist_dict_most_common, wordnet_lemmatizer)\n",
    "    elif op_type == 'stemming_english_words':\n",
    "        new_dict = stemming_english_words(word_dist_dict_most_common, stemmer)\n",
    "    else:\n",
    "        print (\"Error......\")\n",
    "        new_dict = 'Error .......'\n",
    "    return new_dict\n",
    "\n",
    "def get_new_distribution(X):\n",
    "    tmp = X.str.cat(sep=' ')\n",
    "    words = tmp.split()\n",
    "    w_d_dict = nltk.FreqDist(words) #Word distribution dict\n",
    "    w_d_most_common = w_d_dict.most_common()\n",
    "    return w_d_most_common\n",
    "\n",
    "# def get_corresponding_mapping_multiple(word_dist_dict_most_common, op_types):\n",
    "#     curr_list = word_dist_dict_most_common.copy()\n",
    "#     new_dict = {}\n",
    "#     for op_type in op_types:\n",
    "#         print (op_type)\n",
    "#         tmp_map = get_corresponding_mapping(curr_list, op_type)\n",
    "#         if not new_dict:\n",
    "#             new_dict = tmp_map\n",
    "#         else: \n",
    "#             new_dict = update_dict_with_next_level_val(new_dict, tmp_map)\n",
    "#         curr_list = [(new_dict[x], 1) for x in new_dict]\n",
    "#     return new_dict\n",
    "\n",
    "def get_corresponding_mapping_multiple(word_dist_dict_most_common, op_types, train_data):\n",
    "    curr_word_dist_dict_most_common = word_dist_dict_most_common.copy()\n",
    "    comment_data = train_data['comment_text']\n",
    "    for op_type in op_types:\n",
    "        print (op_type)\n",
    "        new_mapped_dict = get_corresponding_mapping(curr_word_dist_dict_most_common, op_type)\n",
    "        comment_data = comment_data.apply(replace_words_from_a_mapping_no_check, args = [new_mapped_dict, 0])\n",
    "        curr_word_dist_dict_most_common = get_new_distribution(comment_data)\n",
    "    return comment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words_dict = dict(zip(stop_words, [1] * len(stop_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling NB SVM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_results = pickle.load(open(\"../data/results_nbsvm.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Add the preprocessing step here \n",
    "import pickle\n",
    "# combined_results = {} #Uncomment \n",
    "for pp_step in pp_steps:\n",
    "    if len(pp_step) == 1:\n",
    "        new_mapped_dict = get_corresponding_mapping(word_dist_dict_most_common, pp_step[0])\n",
    "        X = train_data['comment_text'].apply(replace_words_from_a_mapping_no_check, args = [new_mapped_dict, 0])\n",
    "    else:\n",
    "        X = get_corresponding_mapping_multiple(word_dist_dict_most_common, pp_step, train_data)\n",
    "    vocab = set(' '.join(X.values).split())\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,4), min_df=1, vocabulary= vocab)\n",
    "    results = []\n",
    "    k_fold_num = 0\n",
    "    cv = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=42)\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        print (\"\\n\\n *****Processing fold \", k_fold_num, \" of \", cv.n_splits, \" ......\")\n",
    "        X_train_data, X_test_data = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        X_train = vectorizer.fit_transform(X_train_data)\n",
    "        X_test = vectorizer.transform(X_test_data)\n",
    "        res = call_NB_SVM_algorithm(X_train, y_train, X_test, y_test)\n",
    "        results.append(res)\n",
    "        k_fold_num += 1\n",
    "#         if k_fold_num ==2:\n",
    "#             break\n",
    "    scores = extract_combined_results(results)\n",
    "    combined_results[' '.join(pp_step)] = scores\n",
    "    pickle.dump(combined_results, open(\"../data/results_nbsvm.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_results = pickle.load(open(\"../data/results_logit.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert_to_lower\n",
      "convert_to_lower\n",
      "remove_whitespaces\n",
      "remove_whitespaces\n",
      "trim_words_len\n",
      "trim_words_len\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7351133951513797\n",
      "Log Loss:  1.5395094535271634\n",
      "Accuracy:  0.9554267452061662\n",
      "AUC score:  0.9715448633514437\n",
      "Num of comments missclassified:  7113\n",
      "[[142597    753]\n",
      " [  6360   9870]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95730   0.99475   0.97567    143350\n",
      "          1    0.92912   0.60813   0.73511     16230\n",
      "\n",
      "avg / total    0.95444   0.95543   0.95120    159580\n",
      "\n",
      "convert_to_lower\n",
      "convert_to_lower\n",
      "remove_whitespaces\n",
      "remove_whitespaces\n",
      "trim_words_len\n",
      "trim_words_len\n",
      "strip_non_printable_chars\n",
      "strip_non_printable_chars\n",
      "remove_leaky\n",
      "remove_leaky\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7366227580561137\n",
      "Log Loss:  1.5319341761051568\n",
      "Accuracy:  0.9556460709362076\n",
      "AUC score:  0.9715893214927294\n",
      "Num of comments missclassified:  7078\n",
      "[[142604    746]\n",
      " [  6332   9898]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95749   0.99480   0.97578    143350\n",
      "          1    0.92991   0.60986   0.73662     16230\n",
      "\n",
      "avg / total    0.95468   0.95565   0.95146    159580\n",
      "\n",
      "convert_to_lower\n",
      "convert_to_lower\n",
      "remove_whitespaces\n",
      "remove_whitespaces\n",
      "trim_words_len\n",
      "trim_words_len\n",
      "strip_non_printable_chars\n",
      "strip_non_printable_chars\n",
      "replace_abbreviation_words\n",
      "replace_abbreviation_words\n",
      "replace_acronyms\n",
      "replace_acronyms\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7310524358497581\n",
      "Log Loss:  1.5652656683385051\n",
      "Accuracy:  0.9546810377240256\n",
      "AUC score:  0.9708602490231868\n",
      "Num of comments missclassified:  7232\n",
      "[[142519    831]\n",
      " [  6401   9829]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95702   0.99420   0.97526    143350\n",
      "          1    0.92205   0.60561   0.73105     16230\n",
      "\n",
      "avg / total    0.95346   0.95468   0.95042    159580\n",
      "\n",
      "convert_to_lower\n",
      "convert_to_lower\n",
      "remove_whitespaces\n",
      "remove_whitespaces\n",
      "trim_words_len\n",
      "trim_words_len\n",
      "strip_non_printable_chars\n",
      "strip_non_printable_chars\n",
      "remove_stopwords\n",
      "remove_stopwords\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7247328878317665\n",
      "Log Loss:  1.5780345007519765\n",
      "Accuracy:  0.9543113172076702\n",
      "AUC score:  0.9702495568047477\n",
      "Num of comments missclassified:  7291\n",
      "[[142691    659]\n",
      " [  6632   9598]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95559   0.99540   0.97509    143350\n",
      "          1    0.93575   0.59137   0.72473     16230\n",
      "\n",
      "avg / total    0.95357   0.95431   0.94963    159580\n",
      "\n",
      "convert_to_lower\n",
      "convert_to_lower\n",
      "remove_whitespaces\n",
      "remove_whitespaces\n",
      "trim_words_len\n",
      "trim_words_len\n",
      "strip_non_printable_chars\n",
      "strip_non_printable_chars\n",
      "remove_rare_words\n",
      "remove_rare_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.729811461638977\n",
      "Log Loss:  1.5663475952848835\n",
      "Accuracy:  0.9546497054768768\n",
      "AUC score:  0.968954452701949\n",
      "Num of comments missclassified:  7237\n",
      "[[142569    781]\n",
      " [  6456   9774]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95668   0.99455   0.97525    143350\n",
      "          1    0.92601   0.60222   0.72981     16230\n",
      "\n",
      "avg / total    0.95356   0.95465   0.95029    159580\n",
      "\n",
      "convert_to_lower\n",
      "convert_to_lower\n",
      "remove_whitespaces\n",
      "remove_whitespaces\n",
      "trim_words_len\n",
      "trim_words_len\n",
      "strip_non_printable_chars\n",
      "strip_non_printable_chars\n",
      "replace_abbreviation_words\n",
      "replace_abbreviation_words\n",
      "replace_acronyms\n",
      "replace_acronyms\n",
      "remove_stopwords\n",
      "remove_stopwords\n",
      "remove_rare_words\n",
      "remove_rare_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7147970910735145\n",
      "Log Loss:  1.638204395296162\n",
      "Accuracy:  0.9525692442661988\n",
      "AUC score:  0.9660427193158342\n",
      "Num of comments missclassified:  7569\n",
      "[[142526    824]\n",
      " [  6745   9485]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95481   0.99425   0.97413    143350\n",
      "          1    0.92007   0.58441   0.71480     16230\n",
      "\n",
      "avg / total    0.95128   0.95257   0.94776    159580\n",
      "\n",
      "convert_to_lower\n",
      "convert_to_lower\n",
      "remove_whitespaces\n",
      "remove_whitespaces\n",
      "trim_words_len\n",
      "trim_words_len\n",
      "strip_non_printable_chars\n",
      "strip_non_printable_chars\n",
      "remove_non_alphanumeric\n",
      "remove_non_alphanumeric\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7240353849049501\n",
      "Log Loss:  1.5866922162053214\n",
      "Accuracy:  0.95406065923048\n",
      "AUC score:  0.969855461074573\n",
      "Num of comments missclassified:  7331\n",
      "[[142632    718]\n",
      " [  6613   9617]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95569   0.99499   0.97494    143350\n",
      "          1    0.93053   0.59254   0.72404     16230\n",
      "\n",
      "avg / total    0.95313   0.95406   0.94943    159580\n",
      "\n",
      "convert_to_lower\n",
      "convert_to_lower\n",
      "remove_whitespaces\n",
      "remove_whitespaces\n",
      "trim_words_len\n",
      "trim_words_len\n",
      "strip_non_printable_chars\n",
      "strip_non_printable_chars\n",
      "remove_non_alphabet_words\n",
      "remove_non_alphabet_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7278044391121777\n",
      "Log Loss:  1.571325386206043\n",
      "Accuracy:  0.9545055771399925\n",
      "AUC score:  0.9702170318930805\n",
      "Num of comments missclassified:  7260\n",
      "[[142614    736]\n",
      " [  6524   9706]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95626   0.99487   0.97518    143350\n",
      "          1    0.92952   0.59803   0.72780     16230\n",
      "\n",
      "avg / total    0.95354   0.95451   0.95002    159580\n",
      "\n",
      "convert_to_lower\n",
      "convert_to_lower\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove_whitespaces\n",
      "remove_whitespaces\n",
      "trim_words_len\n",
      "trim_words_len\n",
      "strip_non_printable_chars\n",
      "strip_non_printable_chars\n",
      "remove_non_alphanumeric\n",
      "remove_non_alphanumeric\n",
      "remove_non_alphabet_words\n",
      "remove_non_alphabet_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7278044391121777\n",
      "Log Loss:  1.571325386206043\n",
      "Accuracy:  0.9545055771399925\n",
      "AUC score:  0.9702170318930805\n",
      "Num of comments missclassified:  7260\n",
      "[[142614    736]\n",
      " [  6524   9706]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95626   0.99487   0.97518    143350\n",
      "          1    0.92952   0.59803   0.72780     16230\n",
      "\n",
      "avg / total    0.95354   0.95451   0.95002    159580\n",
      "\n",
      "convert_to_lower\n",
      "convert_to_lower\n",
      "remove_whitespaces\n",
      "remove_whitespaces\n",
      "trim_words_len\n",
      "trim_words_len\n",
      "strip_non_printable_chars\n",
      "strip_non_printable_chars\n",
      "replace_abbreviation_words\n",
      "replace_abbreviation_words\n",
      "replace_acronyms\n",
      "replace_acronyms\n",
      "black_listed_words_regex_mapping\n",
      "black_listed_words_regex_mapping\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7421249724649386\n",
      "Log Loss:  1.5202474359890799\n",
      "Accuracy:  0.9559844592054142\n",
      "AUC score:  0.9727315982902732\n",
      "Num of comments missclassified:  7024\n",
      "[[142449    901]\n",
      " [  6123  10107]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95879   0.99371   0.97594    143350\n",
      "          1    0.91815   0.62274   0.74212     16230\n",
      "\n",
      "avg / total    0.95465   0.95598   0.95216    159580\n",
      "\n",
      "convert_to_lower\n",
      "convert_to_lower\n",
      "remove_whitespaces\n",
      "remove_whitespaces\n",
      "trim_words_len\n",
      "trim_words_len\n",
      "strip_non_printable_chars\n",
      "strip_non_printable_chars\n",
      "replace_abbreviation_words\n",
      "replace_abbreviation_words\n",
      "replace_acronyms\n",
      "replace_acronyms\n",
      "black_listed_words_regex_mapping\n",
      "black_listed_words_regex_mapping\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "replace_profane_words_using_fuzzy\n",
      "replace_profane_words_using_fuzzy\n",
      "Done  100000\n",
      "Done  200000\n",
      "Done  300000\n",
      "Done  400000\n",
      "replace_common_words_using_fuzzy\n",
      "replace_common_words_using_fuzzy\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7465693430656934\n",
      "Log Loss:  1.5029328017736503\n",
      "Accuracy:  0.9564857751597945\n",
      "AUC score:  0.973268451138704\n",
      "Num of comments missclassified:  6944\n",
      "[[142408    942]\n",
      " [  6002  10228]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95956   0.99343   0.97620    143350\n",
      "          1    0.91567   0.63019   0.74657     16230\n",
      "\n",
      "avg / total    0.95509   0.95649   0.95285    159580\n",
      "\n",
      "convert_to_lower\n",
      "convert_to_lower\n",
      "remove_whitespaces\n",
      "remove_whitespaces\n",
      "trim_words_len\n",
      "trim_words_len\n",
      "strip_non_printable_chars\n",
      "strip_non_printable_chars\n",
      "replace_abbreviation_words\n",
      "replace_abbreviation_words\n",
      "replace_acronyms\n",
      "replace_acronyms\n",
      "remove_leaky\n",
      "remove_leaky\n",
      "extract_info_from_url\n",
      "extract_info_from_url\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "black_listed_words_regex_mapping\n",
      "black_listed_words_regex_mapping\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "replace_profane_words_using_fuzzy\n",
      "replace_profane_words_using_fuzzy\n",
      "Done  100000\n",
      "Done  200000\n",
      "Done  300000\n",
      "Done  400000\n",
      "replace_common_words_using_fuzzy\n",
      "replace_common_words_using_fuzzy\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "check_if_proper_name_place_or_ethnicity\n",
      "check_if_proper_name_place_or_ethnicity\n",
      "Done  100000\n",
      "Done  200000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7476853539403658\n",
      "Log Loss:  1.4981712509332983\n",
      "Accuracy:  0.9566236370472491\n",
      "AUC score:  0.9733071563917792\n",
      "Num of comments missclassified:  6922\n",
      "[[142402    948]\n",
      " [  5974  10256]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95974   0.99339   0.97627    143350\n",
      "          1    0.91539   0.63192   0.74769     16230\n",
      "\n",
      "avg / total    0.95523   0.95662   0.95302    159580\n",
      "\n",
      "convert_to_lower\n",
      "convert_to_lower\n",
      "remove_whitespaces\n",
      "remove_whitespaces\n",
      "trim_words_len\n",
      "trim_words_len\n",
      "strip_non_printable_chars\n",
      "strip_non_printable_chars\n",
      "replace_abbreviation_words\n",
      "replace_abbreviation_words\n",
      "replace_acronyms\n",
      "replace_acronyms\n",
      "remove_leaky\n",
      "remove_leaky\n",
      "remove_non_alphabet_words\n",
      "remove_non_alphabet_words\n",
      "remove_stopwords\n",
      "remove_stopwords\n",
      "stemming_english_words\n",
      "stemming_english_words\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7292153589315525\n",
      "Log Loss:  1.5797671772487032\n",
      "Accuracy:  0.954261185612232\n",
      "AUC score:  0.9693476187375366\n",
      "Num of comments missclassified:  7299\n",
      "[[142453    897]\n",
      " [  6402   9828]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95699   0.99374   0.97502    143350\n",
      "          1    0.91636   0.60555   0.72922     16230\n",
      "\n",
      "avg / total    0.95286   0.95426   0.95002    159580\n",
      "\n",
      "convert_to_lower\n",
      "convert_to_lower\n",
      "lemmatize_english_words\n",
      "lemmatize_english_words\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7338065331301794\n",
      "Log Loss:  1.55033149387313\n",
      "Accuracy:  0.9551134227346786\n",
      "AUC score:  0.9700566148758442\n",
      "Num of comments missclassified:  7163\n",
      "[[142544    806]\n",
      " [  6357   9873]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95731   0.99438   0.97549    143350\n",
      "          1    0.92452   0.60832   0.73381     16230\n",
      "\n",
      "avg / total    0.95397   0.95511   0.95091    159580\n",
      "\n",
      "convert_to_lower\n",
      "convert_to_lower\n",
      "remove_non_alphabet_words\n",
      "remove_non_alphabet_words\n",
      "black_listed_words_regex_mapping\n",
      "black_listed_words_regex_mapping\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "replace_common_words_using_fuzzy\n",
      "replace_common_words_using_fuzzy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "stemming_english_words\n",
      "stemming_english_words\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7518747724790681\n",
      "Log Loss:  1.4752289130227163\n",
      "Accuracy:  0.9572878806868028\n",
      "AUC score:  0.9738810422894987\n",
      "Num of comments missclassified:  6816\n",
      "[[142437    913]\n",
      " [  5903  10327]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96021   0.99363   0.97663    143350\n",
      "          1    0.91877   0.63629   0.75187     16230\n",
      "\n",
      "avg / total    0.95599   0.95729   0.95377    159580\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Add the preprocessing step here \n",
    "# combined_results = {} #Uncomment \n",
    "for pp_step in pp_steps:\n",
    "    if len(pp_step) == 1:\n",
    "        new_mapped_dict = get_corresponding_mapping(word_dist_dict_most_common, pp_step[0])\n",
    "        X = train_data['comment_text'].apply(replace_words_from_a_mapping_no_check, args = [new_mapped_dict, 0])\n",
    "    else:\n",
    "        X = get_corresponding_mapping_multiple(word_dist_dict_most_common, pp_step, train_data)\n",
    "    vocab = set(' '.join(X.values).split())\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,4), min_df=1, vocabulary= vocab)\n",
    "    results = []\n",
    "    k_fold_num = 0\n",
    "    cv = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=42)\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        print (\"\\n\\n *****Processing fold \", k_fold_num, \" of \", cv.n_splits, \" ......\")\n",
    "        X_train_data, X_test_data = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        X_train = vectorizer.fit_transform(X_train_data)\n",
    "        X_test = vectorizer.transform(X_test_data)\n",
    "        res = call_logreg_algorithm(X_train, y_train, X_test, y_test)\n",
    "        results.append(res)\n",
    "        k_fold_num += 1\n",
    "\n",
    "#         if k_fold_num ==1:\n",
    "#             break\n",
    "    scores = extract_combined_results(results)\n",
    "    combined_results[' '.join(pp_step)] = scores\n",
    "    pickle.dump(combined_results, open(\"../data/results_logit.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call XGBoost Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_results = pickle.load(open(\"../data/results_xgboost.pkl\", \"rb\"))\n",
    "len(combined_results.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert_to_lower\n",
      "convert_to_lower\n",
      "remove_whitespaces\n",
      "remove_whitespaces\n",
      "trim_words_len\n",
      "trim_words_len\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5734956461465147\n",
      "Log Loss:  2.1308086271067452\n",
      "Accuracy:  0.9383068053640807\n",
      "AUC score:  0.919502285875283\n",
      "Num of comments missclassified:  9845\n",
      "[[143116    234]\n",
      " [  9611   6619]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93707   0.99837   0.96675    143350\n",
      "          1    0.96585   0.40783   0.57350     16230\n",
      "\n",
      "avg / total    0.94000   0.93831   0.92675    159580\n",
      "\n",
      "convert_to_lower\n",
      "convert_to_lower\n",
      "remove_whitespaces\n",
      "remove_whitespaces\n",
      "trim_words_len\n",
      "trim_words_len\n",
      "strip_non_printable_chars\n",
      "strip_non_printable_chars\n",
      "remove_leaky\n",
      "remove_leaky\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5738294278165201\n",
      "Log Loss:  2.129510009122243\n",
      "Accuracy:  0.9383444040606592\n",
      "AUC score:  0.9193252347177959\n",
      "Num of comments missclassified:  9839\n",
      "[[143117    233]\n",
      " [  9606   6624]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93710   0.99837   0.96677    143350\n",
      "          1    0.96602   0.40813   0.57383     16230\n",
      "\n",
      "avg / total    0.94004   0.93834   0.92680    159580\n",
      "\n",
      "convert_to_lower\n",
      "convert_to_lower\n",
      "remove_whitespaces\n",
      "remove_whitespaces\n",
      "trim_words_len\n",
      "trim_words_len\n",
      "strip_non_printable_chars\n",
      "strip_non_printable_chars\n",
      "replace_abbreviation_words\n",
      "replace_abbreviation_words\n",
      "replace_acronyms\n",
      "replace_acronyms\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5689000172681747\n",
      "Log Loss:  2.1613265881732775\n",
      "Accuracy:  0.9374232359944855\n",
      "AUC score:  0.9195178299991339\n",
      "Num of comments missclassified:  9986\n",
      "[[143005    345]\n",
      " [  9641   6589]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93684   0.99759   0.96626    143350\n",
      "          1    0.95025   0.40598   0.56890     16230\n",
      "\n",
      "avg / total    0.93820   0.93742   0.92585    159580\n",
      "\n",
      "convert_to_lower\n",
      "convert_to_lower\n",
      "remove_whitespaces\n",
      "remove_whitespaces\n",
      "trim_words_len\n",
      "trim_words_len\n",
      "strip_non_printable_chars\n",
      "strip_non_printable_chars\n",
      "remove_stopwords\n",
      "remove_stopwords\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5640623639055831\n",
      "Log Loss:  2.166520594122059\n",
      "Accuracy:  0.9372728412081714\n",
      "AUC score:  0.9006920731609035\n",
      "Num of comments missclassified:  10010\n",
      "[[143094    256]\n",
      " [  9754   6476]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93618   0.99821   0.96621    143350\n",
      "          1    0.96197   0.39901   0.56406     16230\n",
      "\n",
      "avg / total    0.93881   0.93727   0.92531    159580\n",
      "\n",
      "convert_to_lower\n",
      "convert_to_lower\n",
      "remove_whitespaces\n",
      "remove_whitespaces\n",
      "trim_words_len\n",
      "trim_words_len\n",
      "strip_non_printable_chars\n",
      "strip_non_printable_chars\n",
      "remove_rare_words\n",
      "remove_rare_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5641025641025641\n",
      "Log Loss:  2.1634903869490283\n",
      "Accuracy:  0.937360571500188\n",
      "AUC score:  0.9158504077138432\n",
      "Num of comments missclassified:  9996\n",
      "[[143116    234]\n",
      " [  9762   6468]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93615   0.99837   0.96626    143350\n",
      "          1    0.96509   0.39852   0.56410     16230\n",
      "\n",
      "avg / total    0.93909   0.93736   0.92535    159580\n",
      "\n",
      "convert_to_lower\n",
      "convert_to_lower\n",
      "remove_whitespaces\n",
      "remove_whitespaces\n",
      "trim_words_len\n",
      "trim_words_len\n",
      "strip_non_printable_chars\n",
      "strip_non_printable_chars\n",
      "replace_abbreviation_words\n",
      "replace_abbreviation_words\n",
      "replace_acronyms\n",
      "replace_acronyms\n",
      "remove_stopwords\n",
      "remove_stopwords\n",
      "remove_rare_words\n",
      "remove_rare_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5538193688792165\n",
      "Log Loss:  2.2186821849232063\n",
      "Accuracy:  0.935762626895601\n",
      "AUC score:  0.8958468911644843\n",
      "Num of comments missclassified:  10251\n",
      "[[142967    383]\n",
      " [  9868   6362]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93543   0.99733   0.96539    143350\n",
      "          1    0.94322   0.39199   0.55382     16230\n",
      "\n",
      "avg / total    0.93623   0.93576   0.92353    159580\n",
      "\n",
      "convert_to_lower\n",
      "convert_to_lower\n",
      "remove_whitespaces\n",
      "remove_whitespaces\n",
      "trim_words_len\n",
      "trim_words_len\n",
      "strip_non_printable_chars\n",
      "strip_non_printable_chars\n",
      "remove_non_alphanumeric\n",
      "remove_non_alphanumeric\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5694420302450895\n",
      "Log Loss:  2.1444440432897864\n",
      "Accuracy:  0.9379120190500063\n",
      "AUC score:  0.9157488997217149\n",
      "Num of comments missclassified:  9908\n",
      "[[143120    230]\n",
      " [  9678   6552]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93666   0.99840   0.96654    143350\n",
      "          1    0.96609   0.40370   0.56944     16230\n",
      "\n",
      "avg / total    0.93965   0.93791   0.92616    159580\n",
      "\n",
      "convert_to_lower\n",
      "convert_to_lower\n",
      "remove_whitespaces\n",
      "remove_whitespaces\n",
      "trim_words_len\n",
      "trim_words_len\n",
      "strip_non_printable_chars\n",
      "strip_non_printable_chars\n",
      "remove_non_alphabet_words\n",
      "remove_non_alphabet_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5723701326858035\n",
      "Log Loss:  2.134488020511424\n",
      "Accuracy:  0.938200275723775\n",
      "AUC score:  0.9161101140068613\n",
      "Num of comments missclassified:  9862\n",
      "[[143118    232]\n",
      " [  9630   6600]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93695   0.99838   0.96669    143350\n",
      "          1    0.96604   0.40665   0.57237     16230\n",
      "\n",
      "avg / total    0.93991   0.93820   0.92659    159580\n",
      "\n",
      "convert_to_lower\n",
      "convert_to_lower\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove_whitespaces\n",
      "remove_whitespaces\n",
      "trim_words_len\n",
      "trim_words_len\n",
      "strip_non_printable_chars\n",
      "strip_non_printable_chars\n",
      "remove_non_alphanumeric\n",
      "remove_non_alphanumeric\n",
      "remove_non_alphabet_words\n",
      "remove_non_alphabet_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5723701326858035\n",
      "Log Loss:  2.134488020511424\n",
      "Accuracy:  0.938200275723775\n",
      "AUC score:  0.9161101140068613\n",
      "Num of comments missclassified:  9862\n",
      "[[143118    232]\n",
      " [  9630   6600]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93695   0.99838   0.96669    143350\n",
      "          1    0.96604   0.40665   0.57237     16230\n",
      "\n",
      "avg / total    0.93991   0.93820   0.92659    159580\n",
      "\n",
      "convert_to_lower\n",
      "convert_to_lower\n",
      "remove_whitespaces\n",
      "remove_whitespaces\n",
      "trim_words_len\n",
      "trim_words_len\n",
      "strip_non_printable_chars\n",
      "strip_non_printable_chars\n",
      "replace_abbreviation_words\n",
      "replace_abbreviation_words\n",
      "replace_acronyms\n",
      "replace_acronyms\n",
      "black_listed_words_regex_mapping\n",
      "black_listed_words_regex_mapping\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.6236082008299438\n",
      "Log Loss:  1.9827681811282156\n",
      "Accuracy:  0.9425930567740318\n",
      "AUC score:  0.9305960616710304\n",
      "Num of comments missclassified:  9161\n",
      "[[142830    520]\n",
      " [  8641   7589]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.94295   0.99637   0.96893    143350\n",
      "          1    0.93587   0.46759   0.62361     16230\n",
      "\n",
      "avg / total    0.94223   0.94259   0.93381    159580\n",
      "\n",
      "convert_to_lower\n",
      "convert_to_lower\n",
      "remove_whitespaces\n",
      "remove_whitespaces\n",
      "trim_words_len\n",
      "trim_words_len\n",
      "strip_non_printable_chars\n",
      "strip_non_printable_chars\n",
      "replace_abbreviation_words\n",
      "replace_abbreviation_words\n",
      "replace_acronyms\n",
      "replace_acronyms\n",
      "black_listed_words_regex_mapping\n",
      "black_listed_words_regex_mapping\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "replace_profane_words_using_fuzzy\n",
      "replace_profane_words_using_fuzzy\n",
      "Done  100000\n",
      "Done  200000\n",
      "Done  300000\n",
      "Done  400000\n",
      "replace_common_words_using_fuzzy\n",
      "replace_common_words_using_fuzzy\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.6301805289539102\n",
      "Log Loss:  1.9641550141091102\n",
      "Accuracy:  0.9431319714249906\n",
      "AUC score:  0.9325080194217196\n",
      "Num of comments missclassified:  9075\n",
      "[[142773    577]\n",
      " [  8498   7732]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.94382   0.99597   0.96920    143350\n",
      "          1    0.93056   0.47640   0.63018     16230\n",
      "\n",
      "avg / total    0.94247   0.94313   0.93472    159580\n",
      "\n",
      "convert_to_lower\n",
      "convert_to_lower\n",
      "remove_whitespaces\n",
      "remove_whitespaces\n",
      "trim_words_len\n",
      "trim_words_len\n",
      "strip_non_printable_chars\n",
      "strip_non_printable_chars\n",
      "replace_abbreviation_words\n",
      "replace_abbreviation_words\n",
      "replace_acronyms\n",
      "replace_acronyms\n",
      "remove_leaky\n",
      "remove_leaky\n",
      "extract_info_from_url\n",
      "extract_info_from_url\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "black_listed_words_regex_mapping\n",
      "black_listed_words_regex_mapping\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "replace_profane_words_using_fuzzy\n",
      "replace_profane_words_using_fuzzy\n",
      "Done  100000\n",
      "Done  200000\n",
      "Done  300000\n",
      "Done  400000\n",
      "replace_common_words_using_fuzzy\n",
      "replace_common_words_using_fuzzy\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "check_if_proper_name_place_or_ethnicity\n",
      "check_if_proper_name_place_or_ethnicity\n",
      "Done  100000\n",
      "Done  200000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.6304772764293859\n",
      "Log Loss:  1.9639386186985608\n",
      "Accuracy:  0.9431382378744203\n",
      "AUC score:  0.9322049465081758\n",
      "Num of comments missclassified:  9074\n",
      "[[142765    585]\n",
      " [  8489   7741]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.94388   0.99592   0.96920    143350\n",
      "          1    0.92974   0.47696   0.63048     16230\n",
      "\n",
      "avg / total    0.94244   0.94314   0.93475    159580\n",
      "\n",
      "convert_to_lower\n",
      "convert_to_lower\n",
      "remove_whitespaces\n",
      "remove_whitespaces\n",
      "trim_words_len\n",
      "trim_words_len\n",
      "strip_non_printable_chars\n",
      "strip_non_printable_chars\n",
      "replace_abbreviation_words\n",
      "replace_abbreviation_words\n",
      "replace_acronyms\n",
      "replace_acronyms\n",
      "remove_leaky\n",
      "remove_leaky\n",
      "remove_non_alphabet_words\n",
      "remove_non_alphabet_words\n",
      "remove_stopwords\n",
      "remove_stopwords\n",
      "stemming_english_words\n",
      "stemming_english_words\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5870945888728936\n",
      "Log Loss:  2.1106812333625755\n",
      "Accuracy:  0.9388895851610477\n",
      "AUC score:  0.9123058488878802\n",
      "Num of comments missclassified:  9752\n",
      "[[142895    455]\n",
      " [  9297   6933]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93891   0.99683   0.96700    143350\n",
      "          1    0.93841   0.42717   0.58709     16230\n",
      "\n",
      "avg / total    0.93886   0.93889   0.92836    159580\n",
      "\n",
      "convert_to_lower\n",
      "convert_to_lower\n",
      "lemmatize_english_words\n",
      "lemmatize_english_words\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5720599705347084\n",
      "Log Loss:  2.137518192609996\n",
      "Accuracy:  0.9381125454317584\n",
      "AUC score:  0.9207652849978111\n",
      "Num of comments missclassified:  9876\n",
      "[[143103    247]\n",
      " [  9629   6601]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93695   0.99828   0.96664    143350\n",
      "          1    0.96393   0.40672   0.57206     16230\n",
      "\n",
      "avg / total    0.93970   0.93811   0.92651    159580\n",
      "\n",
      "convert_to_lower\n",
      "convert_to_lower\n",
      "remove_non_alphabet_words\n",
      "remove_non_alphabet_words\n",
      "black_listed_words_regex_mapping\n",
      "black_listed_words_regex_mapping\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "replace_common_words_using_fuzzy\n",
      "replace_common_words_using_fuzzy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "stemming_english_words\n",
      "stemming_english_words\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.6348413510747185\n",
      "Log Loss:  1.9303904003526295\n",
      "Accuracy:  0.9441095375360321\n",
      "AUC score:  0.9327217975986543\n",
      "Num of comments missclassified:  8919\n",
      "[[142908    442]\n",
      " [  8477   7753]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.94400   0.99692   0.96974    143350\n",
      "          1    0.94606   0.47770   0.63484     16230\n",
      "\n",
      "avg / total    0.94421   0.94411   0.93568    159580\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Add the preprocessing step here \n",
    "# combined_results = {} #Uncomment \n",
    "for pp_step in pp_steps[20:]:\n",
    "    if len(pp_step) == 1:\n",
    "        new_mapped_dict = get_corresponding_mapping(word_dist_dict_most_common, pp_step[0])\n",
    "        X = train_data['comment_text'].apply(replace_words_from_a_mapping_no_check, args = [new_mapped_dict, 0])\n",
    "    else:\n",
    "        X = get_corresponding_mapping_multiple(word_dist_dict_most_common, pp_step, train_data)\n",
    "    vocab = set(' '.join(X.values).split())\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,4), min_df=1, vocabulary= vocab)\n",
    "    results = []\n",
    "    k_fold_num = 0\n",
    "    cv = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=42)\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        print (\"\\n\\n *****Processing fold \", k_fold_num, \" of \", cv.n_splits, \" ......\")\n",
    "        X_train_data, X_test_data = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        X_train = vectorizer.fit_transform(X_train_data)\n",
    "        X_test = vectorizer.transform(X_test_data)\n",
    "        res = call_xgboost_algorithm(xgb, vectorizer, X_train, y_train, X_test, y_test)\n",
    "        results.append(res)\n",
    "        k_fold_num += 1\n",
    "\n",
    "#         if k_fold_num ==1:\n",
    "#             break\n",
    "    scores = extract_combined_results(results)\n",
    "    combined_results[' '.join(pp_step)] = scores\n",
    "    pickle.dump(combined_results, open(\"../data/results_xgboost.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fasttext Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_results = pickle.load(open(\"../data/individual_fasttext.pkl\", \"rb\"))\n",
    "len(combined_results.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert_to_lower\n",
      "convert_to_lower\n",
      "remove_whitespaces\n",
      "remove_whitespaces\n",
      "trim_words_len\n",
      "trim_words_len\n",
      "strip_non_printable_chars\n",
      "strip_non_printable_chars\n",
      "replace_abbreviation_words\n",
      "replace_abbreviation_words\n",
      "replace_acronyms\n",
      "replace_acronyms\n",
      "remove_leaky\n",
      "remove_leaky\n",
      "remove_non_alphabet_words\n",
      "remove_non_alphabet_words\n",
      "remove_stopwords\n",
      "remove_stopwords\n",
      "stemming_english_words\n",
      "stemming_english_words\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 197s 1ms/step - loss: 0.1230 - acc: 0.9549\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 176s 1ms/step - loss: 0.1041 - acc: 0.9611\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.0991 - acc: 0.9629\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 198s 1ms/step - loss: 0.1272 - acc: 0.9536\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 177s 1ms/step - loss: 0.1045 - acc: 0.9612\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.0997 - acc: 0.9632\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 198s 1ms/step - loss: 0.1227 - acc: 0.9552\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1044 - acc: 0.9608\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.0994 - acc: 0.9626\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 198s 1ms/step - loss: 0.1275 - acc: 0.9536\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1057 - acc: 0.9612\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1008 - acc: 0.9623\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 198s 1ms/step - loss: 0.1252 - acc: 0.9538\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1039 - acc: 0.9609\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.0996 - acc: 0.9626\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 199s 1ms/step - loss: 0.1255 - acc: 0.9543\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 179s 1ms/step - loss: 0.1053 - acc: 0.9605\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1004 - acc: 0.9629\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 199s 1ms/step - loss: 0.1234 - acc: 0.9552\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1043 - acc: 0.9612\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.0999 - acc: 0.9629\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 200s 1ms/step - loss: 0.1232 - acc: 0.9546\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1044 - acc: 0.9608\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.0992 - acc: 0.9627\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 200s 1ms/step - loss: 0.1250 - acc: 0.9545\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1057 - acc: 0.9606\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 179s 1ms/step - loss: 0.1008 - acc: 0.9626\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 200s 1ms/step - loss: 0.1235 - acc: 0.9551\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 179s 1ms/step - loss: 0.1044 - acc: 0.9612\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 179s 1ms/step - loss: 0.1000 - acc: 0.9631\n",
      "F1-score:  0.8008754186424378\n",
      "Log Loss:  1.2997044260325985\n",
      "Accuracy:  0.9623699711743327\n",
      "AUC score:  0.977815681278517\n",
      "Num of comments missclassified:  6005\n",
      "[[141499   1851]\n",
      " [  4154  12076]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.97148   0.98709   0.97922    143350\n",
      "          1    0.86709   0.74405   0.80088     16230\n",
      "\n",
      "avg / total    0.96086   0.96237   0.96108    159580\n",
      "\n",
      "convert_to_lower\n",
      "convert_to_lower\n",
      "lemmatize_english_words\n",
      "lemmatize_english_words\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 202s 1ms/step - loss: 0.1258 - acc: 0.9536\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 180s 1ms/step - loss: 0.1012 - acc: 0.9619\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 180s 1ms/step - loss: 0.0960 - acc: 0.9636\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 204s 1ms/step - loss: 0.1223 - acc: 0.9545\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 182s 1ms/step - loss: 0.1021 - acc: 0.9612\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 182s 1ms/step - loss: 0.0975 - acc: 0.9632\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 204s 1ms/step - loss: 0.1213 - acc: 0.9553\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 181s 1ms/step - loss: 0.1012 - acc: 0.9618\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 181s 1ms/step - loss: 0.0963 - acc: 0.9633\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 203s 1ms/step - loss: 0.1263 - acc: 0.9531\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 181s 1ms/step - loss: 0.1031 - acc: 0.9612\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 181s 1ms/step - loss: 0.0981 - acc: 0.9631\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 207s 1ms/step - loss: 0.1260 - acc: 0.9537\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 181s 1ms/step - loss: 0.1028 - acc: 0.9612\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 181s 1ms/step - loss: 0.0982 - acc: 0.9630\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 204s 1ms/step - loss: 0.1281 - acc: 0.9530\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 181s 1ms/step - loss: 0.1052 - acc: 0.9607\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 181s 1ms/step - loss: 0.1000 - acc: 0.9625\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 204s 1ms/step - loss: 0.1250 - acc: 0.9543\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 181s 1ms/step - loss: 0.1039 - acc: 0.9605\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 181s 1ms/step - loss: 0.0978 - acc: 0.9629\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 205s 1ms/step - loss: 0.1281 - acc: 0.9531\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 180s 1ms/step - loss: 0.1041 - acc: 0.9609\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 181s 1ms/step - loss: 0.0986 - acc: 0.9627\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 204s 1ms/step - loss: 0.1240 - acc: 0.9543\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 180s 1ms/step - loss: 0.1018 - acc: 0.9618\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 180s 1ms/step - loss: 0.0973 - acc: 0.9635\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 205s 1ms/step - loss: 0.1241 - acc: 0.9540\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 182s 1ms/step - loss: 0.1026 - acc: 0.9616\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 182s 1ms/step - loss: 0.0971 - acc: 0.9636\n",
      "F1-score:  0.8038172507814059\n",
      "Log Loss:  1.2769782279900868\n",
      "Accuracy:  0.9630279483644567\n",
      "AUC score:  0.978714159747147\n",
      "Num of comments missclassified:  5900\n",
      "[[141593   1757]\n",
      " [  4143  12087]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.97157   0.98774   0.97959    143350\n",
      "          1    0.87309   0.74473   0.80382     16230\n",
      "\n",
      "avg / total    0.96156   0.96303   0.96171    159580\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#combined_results = {}\n",
    "for pp_step in pp_steps:\n",
    "    if len(pp_step) == 1:\n",
    "        new_mapped_dict = get_corresponding_mapping(word_dist_dict_most_common, pp_step[0])\n",
    "        X = train_data['comment_text'].apply(replace_words_from_a_mapping_no_check, args = [new_mapped_dict, 0])\n",
    "    else:\n",
    "        X = get_corresponding_mapping_multiple(word_dist_dict_most_common, pp_step, train_data)\n",
    "    results = []\n",
    "    k_fold_num = 0\n",
    "    cv = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=42)\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        print (\"\\n\\n *****Processing fold \", k_fold_num, \" of \", cv.n_splits, \" ......\")\n",
    "        X_train_data, X_test_data = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        texts_train = X_train_data.values\n",
    "        texts_test  = X_test_data.values\n",
    "        train = X.copy()\n",
    "        X_train, X_test, embedding_matrix = preprocess_data_for_fasttext(texts_train, texts_test, train)\n",
    "        res = call_fasttext_algorithm(X_train, y_train, X_test, y_test, embedding_matrix)\n",
    "        results.append(res)\n",
    "        k_fold_num += 1\n",
    "\n",
    "#         if k_fold_num ==1:\n",
    "#             break\n",
    "    scores = extract_combined_results(results)\n",
    "    combined_results[' '.join(pp_step)] = scores\n",
    "    pickle.dump(combined_results, open(\"../data/individual_fasttext_part.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# <font color = 'red' > Greedy to select the best transformation sequence  </color>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add the preprocessing step here\n",
    "def call_logit_to_recursive_transformation_Addition(pp_steps, word_dist_dict_most_common,train_data, algo):\n",
    "    combined_results = {} #Uncomment \n",
    "    for pp_step in pp_steps:\n",
    "        if len(pp_step) == 1:\n",
    "            new_mapped_dict = get_corresponding_mapping(word_dist_dict_most_common, pp_step[0])\n",
    "        else:\n",
    "            new_mapped_dict = get_corresponding_mapping_multiple(word_dist_dict_most_common, pp_step, train_data)\n",
    "        X = train_data['comment_text'].apply(replace_words_from_a_mapping_no_check, args = [new_mapped_dict, 0])\n",
    "        vocab = set(' '.join(X.values).split())\n",
    "        vectorizer = TfidfVectorizer(ngram_range=(1,4), min_df=1, vocabulary= vocab)\n",
    "        results = []\n",
    "        k_fold_num = 0\n",
    "        cv = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=42)\n",
    "        for train_index, test_index in cv.split(X, y):\n",
    "            print (\"\\n\\n *****Processing fold \", k_fold_num, \" of \", cv.n_splits, \" ......\")\n",
    "            X_train_data, X_test_data = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            X_train = vectorizer.fit_transform(X_train_data)\n",
    "            X_test = vectorizer.transform(X_test_data)\n",
    "            if algo == 'logit':\n",
    "                res = call_logreg_algorithm(X_train, y_train, X_test, y_test)\n",
    "            elif algo == 'nbsvm':\n",
    "                res = call_NB_SVM_algorithm(X_train, y_train, X_test, y_test)\n",
    "            else:\n",
    "                return 'ERROR'\n",
    "            results.append(res)\n",
    "            k_fold_num += 1\n",
    "\n",
    "#             if k_fold_num ==1:\n",
    "#                 break\n",
    "        scores = extract_combined_results(results)\n",
    "        combined_results[' '.join(pp_step)] = scores\n",
    "        import pickle\n",
    "        pickle.dump(combined_results, open(\"../data/results_logit_1.pkl\", \"wb\"))\n",
    "    return combined_results, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add the preprocessing step here \n",
    "#Add the preprocessing step here\n",
    "def call_xgboost_to_recursive_transformation_Addition(pp_steps, word_dist_dict_most_common,train_data):\n",
    "    combined_results = {} #Uncomment \n",
    "    for pp_step in pp_steps:\n",
    "        if len(pp_step) == 1:\n",
    "            new_mapped_dict = get_corresponding_mapping(word_dist_dict_most_common, pp_step[0])\n",
    "        else:\n",
    "            new_mapped_dict = get_corresponding_mapping_multiple(word_dist_dict_most_common, pp_step, train_data)\n",
    "        X = train_data['comment_text'].apply(replace_words_from_a_mapping_no_check, args = [new_mapped_dict, 0])\n",
    "        vocab = set(' '.join(X.values).split())\n",
    "        vectorizer = TfidfVectorizer(ngram_range=(1,4), min_df=1, vocabulary= vocab)\n",
    "        results = []\n",
    "        k_fold_num = 0\n",
    "        cv = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=42)\n",
    "        for train_index, test_index in cv.split(X, y):\n",
    "            print (\"\\n\\n *****Processing fold \", k_fold_num, \" of \", cv.n_splits, \" ......\")\n",
    "            #print (len(train_index), len(test_index))\n",
    "            #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "            X_train_data, X_test_data = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            X_train = vectorizer.fit_transform(X_train_data)\n",
    "            X_test = vectorizer.transform(X_test_data)\n",
    "            res = call_xgboost_algorithm(xgb, vectorizer, X_train, y_train, X_test, y_test)\n",
    "            results.append(res)\n",
    "            k_fold_num += 1\n",
    "\n",
    "    #         if k_fold_num ==1:\n",
    "    #             break\n",
    "        scores = extract_combined_results(results)\n",
    "        combined_results[' '.join(pp_step)] = scores\n",
    "        import pickle\n",
    "        pickle.dump(combined_results, open(\"../data/results_xgboost_1.pkl\", \"wb\"))\n",
    "    return combined_results, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_words_dict_most_common(df):\n",
    "    # Get the Word Frequency table\n",
    "    tmp = df['comment_text'].str.cat(sep=' ')\n",
    "    words = tmp.split()\n",
    "    word_dist_dict = nltk.FreqDist(words)\n",
    "    word_dist_dict_most_common = word_dist_dict.most_common()\n",
    "    return word_dist_dict_most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformations_orig = [             \n",
    "            ['convert_to_lower'],\n",
    "            ['remove_whitespaces'], \n",
    "            ['remove_leaky'], \n",
    "            ['trim_words_len'],\n",
    "            ['strip_non_printable_chars'],\n",
    "            ['replace_abbreviation_words'],\n",
    "            ['replace_acronyms'],\n",
    "            ['remove_stopwords'],\n",
    "            ['remove_rare_words'],\n",
    "            ['remove_non_alphanumeric'],\n",
    "            ['remove_non_alphabet_words'],\n",
    "            ['remove_words_containing_non_alphabets'],\n",
    "            ['black_listed_words_regex_mapping'],\n",
    "            ['check_if_proper_name_place_or_ethnicity'],\n",
    "            ['replace_profane_words_using_fuzzy'],\n",
    "            ['replace_common_words_using_fuzzy'],\n",
    "            ['lemmatize_english_words'],\n",
    "            ['stemming_english_words'],\n",
    "            ['extract_info_from_url']\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black_listed_words_regex_mapping\n",
      "black_listed_words_regex_mapping\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "Done  500000\n"
     ]
    }
   ],
   "source": [
    "train_data_copy = train_data.copy()\n",
    "word_dist_dict_most_common_copy = word_dist_dict_most_common\n",
    "\n",
    "tr_scores = []\n",
    "transformations = transformations_orig.copy()\n",
    "pp_steps = ['black_listed_words_regex_mapping']\n",
    "max_f1 = 0.7488\n",
    "tr_scores.append((pp_steps[0], max_f1))\n",
    "transformations.remove(pp_steps)\n",
    "\n",
    "new_mapped_dict = get_corresponding_mapping_multiple(word_dist_dict_most_common, pp_steps, train_data_copy)\n",
    "X = train_data_copy['comment_text'].apply(replace_words_from_a_mapping_no_check, args = [new_mapped_dict, 0])\n",
    "train_data_copy['comment_text'] = X\n",
    "word_dist_dict_most_common_copy = get_words_dict_most_common(train_data_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert_to_lower\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7351802204349122\n",
      "Log Loss:  1.5392930230421562\n",
      "Accuracy:  0.9554330116555959\n",
      "AUC score:  0.9714555142429597\n",
      "Num of comments missclassified:  7112\n",
      "[[142596    754]\n",
      " [  6358   9872]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95732   0.99474   0.97567    143350\n",
      "          1    0.92904   0.60826   0.73518     16230\n",
      "\n",
      "avg / total    0.95444   0.95543   0.95121    159580\n",
      "\n",
      "remove_whitespaces\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7406912920931613\n",
      "Log Loss:  1.513320733501024\n",
      "Accuracy:  0.9561849855871664\n",
      "AUC score:  0.9719737794320009\n",
      "Num of comments missclassified:  6992\n",
      "[[142602    748]\n",
      " [  6244   9986]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95805   0.99478   0.97607    143350\n",
      "          1    0.93031   0.61528   0.74069     16230\n",
      "\n",
      "avg / total    0.95523   0.95618   0.95213    159580\n",
      "\n",
      "remove_leaky\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7404716001779623\n",
      "Log Loss:  1.5150522575512726\n",
      "Accuracy:  0.9561348539917283\n",
      "AUC score:  0.9721293083532178\n",
      "Num of comments missclassified:  7000\n",
      "[[142594    756]\n",
      " [  6244   9986]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95805   0.99473   0.97604    143350\n",
      "          1    0.92962   0.61528   0.74047     16230\n",
      "\n",
      "avg / total    0.95516   0.95613   0.95208    159580\n",
      "\n",
      "trim_words_len\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7400704617096235\n",
      "Log Loss:  1.5170001820227081\n",
      "Accuracy:  0.9560784559468605\n",
      "AUC score:  0.972040570014964\n",
      "Num of comments missclassified:  7009\n",
      "[[142593    757]\n",
      " [  6252   9978]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95800   0.99472   0.97601    143350\n",
      "          1    0.92948   0.61479   0.74007     16230\n",
      "\n",
      "avg / total    0.95510   0.95608   0.95202    159580\n",
      "\n",
      "strip_non_printable_chars\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7401609851997478\n",
      "Log Loss:  1.516134414986947\n",
      "Accuracy:  0.9561035217445796\n",
      "AUC score:  0.9718774066807776\n",
      "Num of comments missclassified:  7005\n",
      "[[142598    752]\n",
      " [  6253   9977]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95799   0.99475   0.97603    143350\n",
      "          1    0.92991   0.61473   0.74016     16230\n",
      "\n",
      "avg / total    0.95514   0.95610   0.95204    159580\n",
      "\n",
      "replace_abbreviation_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7398753894080997\n",
      "Log Loss:  1.5180823695222032\n",
      "Accuracy:  0.9560471236997118\n",
      "AUC score:  0.9719919413574615\n",
      "Num of comments missclassified:  7014\n",
      "[[142591    759]\n",
      " [  6255   9975]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95798   0.99471   0.97600    143350\n",
      "          1    0.92929   0.61460   0.73988     16230\n",
      "\n",
      "avg / total    0.95506   0.95605   0.95198    159580\n",
      "\n",
      "replace_acronyms\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7392753945321183\n",
      "Log Loss:  1.52327695670486\n",
      "Accuracy:  0.9558967289133977\n",
      "AUC score:  0.9719304156052868\n",
      "Num of comments missclassified:  7038\n",
      "[[142564    786]\n",
      " [  6252   9978]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95799   0.99452   0.97591    143350\n",
      "          1    0.92698   0.61479   0.73928     16230\n",
      "\n",
      "avg / total    0.95483   0.95590   0.95184    159580\n",
      "\n",
      "remove_stopwords\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.730194488248104\n",
      "Log Loss:  1.5553088789327032\n",
      "Accuracy:  0.9549692943977942\n",
      "AUC score:  0.9706088826880594\n",
      "Num of comments missclassified:  7186\n",
      "[[142670    680]\n",
      " [  6506   9724]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95639   0.99526   0.97543    143350\n",
      "          1    0.93464   0.59914   0.73019     16230\n",
      "\n",
      "avg / total    0.95418   0.95497   0.95049    159580\n",
      "\n",
      "remove_rare_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7296501881309838\n",
      "Log Loss:  1.5706765006126062\n",
      "Accuracy:  0.9545243764882817\n",
      "AUC score:  0.9681189134393305\n",
      "Num of comments missclassified:  7257\n",
      "[[142530    820]\n",
      " [  6437   9793]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95679   0.99428   0.97517    143350\n",
      "          1    0.92274   0.60339   0.72965     16230\n",
      "\n",
      "avg / total    0.95333   0.95452   0.95020    159580\n",
      "\n",
      "remove_non_alphanumeric\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7306670657338472\n",
      "Log Loss:  1.558122810950469\n",
      "Accuracy:  0.9548878305552074\n",
      "AUC score:  0.9705158304895554\n",
      "Num of comments missclassified:  7199\n",
      "[[142616    734]\n",
      " [  6465   9765]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95663   0.99488   0.97538    143350\n",
      "          1    0.93009   0.60166   0.73067     16230\n",
      "\n",
      "avg / total    0.95393   0.95489   0.95049    159580\n",
      "\n",
      "remove_non_alphabet_words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7337432457611328\n",
      "Log Loss:  1.5464354244622378\n",
      "Accuracy:  0.955226218824414\n",
      "AUC score:  0.9708618178559386\n",
      "Num of comments missclassified:  7145\n",
      "[[142590    760]\n",
      " [  6385   9845]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95714   0.99470   0.97556    143350\n",
      "          1    0.92834   0.60659   0.73374     16230\n",
      "\n",
      "avg / total    0.95421   0.95523   0.95096    159580\n",
      "\n",
      "remove_words_containing_non_alphabets\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.6577154936193533\n",
      "Log Loss:  1.8925165586461195\n",
      "Accuracy:  0.9452061661862389\n",
      "AUC score:  0.9462181083702385\n",
      "Num of comments missclassified:  8744\n",
      "[[142435    915]\n",
      " [  7829   8401]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.94790   0.99362   0.97022    143350\n",
      "          1    0.90178   0.51762   0.65772     16230\n",
      "\n",
      "avg / total    0.94321   0.94521   0.93844    159580\n",
      "\n",
      "check_if_proper_name_place_or_ethnicity\n",
      "Done  100000\n",
      "Done  200000\n",
      "Done  300000\n",
      "Done  400000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7406912920931613\n",
      "Log Loss:  1.513320733501024\n",
      "Accuracy:  0.9561849855871664\n",
      "AUC score:  0.9719737794320009\n",
      "Num of comments missclassified:  6992\n",
      "[[142602    748]\n",
      " [  6244   9986]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95805   0.99478   0.97607    143350\n",
      "          1    0.93031   0.61528   0.74069     16230\n",
      "\n",
      "avg / total    0.95523   0.95618   0.95213    159580\n",
      "\n",
      "replace_profane_words_using_fuzzy\n",
      "Done  100000\n",
      "Done  200000\n",
      "Done  300000\n",
      "Done  400000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7422004493719842\n",
      "Log Loss:  1.5148362629916723\n",
      "Accuracy:  0.9561411204411581\n",
      "AUC score:  0.9718424137587922\n",
      "Num of comments missclassified:  6999\n",
      "[[142506    844]\n",
      " [  6155  10075]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95860   0.99411   0.97603    143350\n",
      "          1    0.92270   0.62076   0.74220     16230\n",
      "\n",
      "avg / total    0.95495   0.95614   0.95225    159580\n",
      "\n",
      "replace_common_words_using_fuzzy\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7438010420900927\n",
      "Log Loss:  1.5005511344601128\n",
      "Accuracy:  0.9565547061035218\n",
      "AUC score:  0.972385085042555\n",
      "Num of comments missclassified:  6933\n",
      "[[142583    767]\n",
      " [  6166  10064]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95855   0.99465   0.97626    143350\n",
      "          1    0.92918   0.62009   0.74380     16230\n",
      "\n",
      "avg / total    0.95556   0.95655   0.95262    159580\n",
      "\n",
      "lemmatize_english_words\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7377297777120243\n",
      "Log Loss:  1.5347482784845756\n",
      "Accuracy:  0.9555646070936208\n",
      "AUC score:  0.9697942346900729\n",
      "Num of comments missclassified:  7091\n",
      "[[142516    834]\n",
      " [  6257   9973]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95794   0.99418   0.97573    143350\n",
      "          1    0.92283   0.61448   0.73773     16230\n",
      "\n",
      "avg / total    0.95437   0.95556   0.95152    159580\n",
      "\n",
      "stemming_english_words\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.732165392324252\n",
      "Log Loss:  1.5618027905996605\n",
      "Accuracy:  0.9547813009149017\n",
      "AUC score:  0.9683167557140434\n",
      "Num of comments missclassified:  7216\n",
      "[[142501    849]\n",
      " [  6367   9863]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95723   0.99408   0.97531    143350\n",
      "          1    0.92074   0.60770   0.73217     16230\n",
      "\n",
      "avg / total    0.95352   0.95478   0.95058    159580\n",
      "\n",
      "extract_info_from_url\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7396467270298354\n",
      "Log Loss:  1.5185152054390334\n",
      "Accuracy:  0.9560345908008523\n",
      "AUC score:  0.9719217294296477\n",
      "Num of comments missclassified:  7016\n",
      "[[142598    752]\n",
      " [  6264   9966]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95792   0.99475   0.97599    143350\n",
      "          1    0.92984   0.61405   0.73965     16230\n",
      "\n",
      "avg / total    0.95506   0.95603   0.95195    159580\n",
      "\n",
      "[('replace_common_words_using_fuzzy', 0.7438010420900927), ('replace_profane_words_using_fuzzy', 0.7422004493719842), ('remove_whitespaces', 0.7406912920931613), ('check_if_proper_name_place_or_ethnicity', 0.7406912920931613), ('remove_leaky', 0.7404716001779623), ('strip_non_printable_chars', 0.7401609851997478), ('trim_words_len', 0.7400704617096235), ('replace_abbreviation_words', 0.7398753894080997), ('extract_info_from_url', 0.7396467270298354), ('replace_acronyms', 0.7392753945321183), ('lemmatize_english_words', 0.7377297777120243), ('convert_to_lower', 0.7351802204349122), ('remove_non_alphabet_words', 0.7337432457611328), ('stemming_english_words', 0.732165392324252), ('remove_non_alphanumeric', 0.7306670657338472), ('remove_stopwords', 0.730194488248104), ('remove_rare_words', 0.7296501881309838), ('remove_words_containing_non_alphabets', 0.6577154936193533)]\n",
      "Any other transformation not needed\n"
     ]
    }
   ],
   "source": [
    "#Loop through all the transformations to see which one gives the maximum boost to f1_score\n",
    "while(True):\n",
    "    tr_iter_score = []\n",
    "    X_best = None\n",
    "    tr_best = None\n",
    "    max_f1_local = max_f1\n",
    "    for tr in transformations:\n",
    "        pp_steps = [tr]\n",
    "        base_res, X = call_logit_to_recursive_transformation_Addition(pp_steps, word_dist_dict_most_common_copy,train_data_copy, 'logit')\n",
    "        tr_iter_score.append((pp_steps[0][0], base_res))\n",
    "        if max_f1_local < base_res[tr[0]][0]:\n",
    "            max_f1_local = base_res[tr[0]][0]\n",
    "            X_best = X\n",
    "            tr_best = tr[0]  \n",
    "            print ('\\n\\n\\n ========= ', tr_best)\n",
    "    key_neg_f1 = []\n",
    "    for k in tr_iter_score:\n",
    "        key_neg_f1.append((k[0], k[1][k[0]][0]))\n",
    "    ordered = sorted(key_neg_f1,key=itemgetter(1), reverse=True)\n",
    "    print(ordered)\n",
    "    if max_f1 >= ordered[0][1]:\n",
    "        print ('Any other transformation not needed')\n",
    "        break\n",
    "    # Add transformation into the    \n",
    "    tr_scores.append(ordered[0])\n",
    "    max_f1 = ordered[0][1]\n",
    "    transformations.remove([ordered[0][0]])\n",
    "    train_data_copy['comment_text'] = X_best\n",
    "    word_dist_dict_most_common_copy = get_words_dict_most_common(train_data_copy)\n",
    "    print(transformations)\n",
    "    print ('*******************')\n",
    "    print (tr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Logit [('black_listed_words_regex_mapping',  0.7488 )]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace_common_words_using_fuzzy\n",
      "replace_common_words_using_fuzzy\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "Done  500000\n"
     ]
    }
   ],
   "source": [
    "train_data_copy = train_data.copy()\n",
    "word_dist_dict_most_common_copy = word_dist_dict_most_common\n",
    "\n",
    "tr_scores = []\n",
    "transformations = transformations_orig.copy()\n",
    "pp_steps = ['replace_common_words_using_fuzzy']\n",
    "max_f1 = 0.7968\n",
    "tr_scores.append((pp_steps[0], max_f1))\n",
    "transformations.remove(pp_steps)\n",
    "\n",
    "new_mapped_dict = get_corresponding_mapping_multiple(word_dist_dict_most_common, pp_steps, train_data_copy)\n",
    "X = train_data_copy['comment_text'].apply(replace_words_from_a_mapping_no_check, args = [new_mapped_dict, 0])\n",
    "train_data_copy['comment_text'] = X\n",
    "word_dist_dict_most_common_copy = get_words_dict_most_common(train_data_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert_to_lower\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7936014372581537\n",
      "Log Loss:  1.292991809051499\n",
      "Accuracy:  0.962564231106655\n",
      "AUC score:  0.9772505215294356\n",
      "Num of comments missclassified:  5974\n",
      "[[142121   1229]\n",
      " [  4745  11485]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96769   0.99143   0.97942    143350\n",
      "          1    0.90333   0.70764   0.79360     16230\n",
      "\n",
      "avg / total    0.96115   0.96256   0.96052    159580\n",
      "\n",
      "remove_whitespaces\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7957122242836528\n",
      "Log Loss:  1.2869319508861299\n",
      "Accuracy:  0.9627396916906881\n",
      "AUC score:  0.9772802173843432\n",
      "Num of comments missclassified:  5946\n",
      "[[142054   1296]\n",
      " [  4650  11580]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96830   0.99096   0.97950    143350\n",
      "          1    0.89935   0.71349   0.79571     16230\n",
      "\n",
      "avg / total    0.96129   0.96274   0.96081    159580\n",
      "\n",
      "remove_leaky\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7951310088714669\n",
      "Log Loss:  1.2895291467700398\n",
      "Accuracy:  0.962664494297531\n",
      "AUC score:  0.9773129814892779\n",
      "Num of comments missclassified:  5958\n",
      "[[142060   1290]\n",
      " [  4668  11562]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96819   0.99100   0.97946    143350\n",
      "          1    0.89963   0.71238   0.79513     16230\n",
      "\n",
      "avg / total    0.96121   0.96266   0.96071    159580\n",
      "\n",
      "trim_words_len\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7957543281121187\n",
      "Log Loss:  1.2869319659180403\n",
      "Accuracy:  0.9627396916906881\n",
      "AUC score:  0.977346799076151\n",
      "Num of comments missclassified:  5946\n",
      "[[142051   1299]\n",
      " [  4647  11583]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96832   0.99094   0.97950    143350\n",
      "          1    0.89916   0.71368   0.79575     16230\n",
      "\n",
      "avg / total    0.96129   0.96274   0.96081    159580\n",
      "\n",
      "strip_non_printable_chars\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7958762886597938\n",
      "Log Loss:  1.2856333078484432\n",
      "Accuracy:  0.9627772903872666\n",
      "AUC score:  0.97719617866727\n",
      "Num of comments missclassified:  5940\n",
      "[[142060   1290]\n",
      " [  4650  11580]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96830   0.99100   0.97952    143350\n",
      "          1    0.89977   0.71349   0.79588     16230\n",
      "\n",
      "avg / total    0.96133   0.96278   0.96084    159580\n",
      "\n",
      "replace_abbreviation_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7950523964954475\n",
      "Log Loss:  1.2910442703991023\n",
      "Accuracy:  0.9626206291515228\n",
      "AUC score:  0.9773345204884185\n",
      "Num of comments missclassified:  5965\n",
      "[[142045   1305]\n",
      " [  4660  11570]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96824   0.99090   0.97943    143350\n",
      "          1    0.89864   0.71288   0.79505     16230\n",
      "\n",
      "avg / total    0.96116   0.96262   0.96068    159580\n",
      "\n",
      "replace_acronyms\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7934344998451532\n",
      "Log Loss:  1.2992688042016736\n",
      "Accuracy:  0.9623825040731921\n",
      "AUC score:  0.9768600805348473\n",
      "Num of comments missclassified:  6003\n",
      "[[142048   1302]\n",
      " [  4701  11529]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96797   0.99092   0.97931    143350\n",
      "          1    0.89853   0.71035   0.79343     16230\n",
      "\n",
      "avg / total    0.96090   0.96238   0.96040    159580\n",
      "\n",
      "remove_stopwords\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7859629770071356\n",
      "Log Loss:  1.3438549021234292\n",
      "Accuracy:  0.961091615490663\n",
      "AUC score:  0.9733150989836757\n",
      "Num of comments missclassified:  6209\n",
      "[[141971   1379]\n",
      " [  4830  11400]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96710   0.99038   0.97860    143350\n",
      "          1    0.89209   0.70240   0.78596     16230\n",
      "\n",
      "avg / total    0.95947   0.96109   0.95901    159580\n",
      "\n",
      "remove_rare_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7848947386555489\n",
      "Log Loss:  1.3512138292306182\n",
      "Accuracy:  0.9608785562100514\n",
      "AUC score:  0.9718977587397416\n",
      "Num of comments missclassified:  6243\n",
      "[[141947   1403]\n",
      " [  4840  11390]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96703   0.99021   0.97848    143350\n",
      "          1    0.89033   0.70179   0.78489     16230\n",
      "\n",
      "avg / total    0.95923   0.96088   0.95879    159580\n",
      "\n",
      "remove_non_alphanumeric\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.788542135707111\n",
      "Log Loss:  1.321345004289366\n",
      "Accuracy:  0.9617433262313573\n",
      "AUC score:  0.9760702205241578\n",
      "Num of comments missclassified:  6105\n",
      "[[142092   1258]\n",
      " [  4847  11383]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96701   0.99122   0.97897    143350\n",
      "          1    0.90048   0.70136   0.78854     16230\n",
      "\n",
      "avg / total    0.96025   0.96174   0.95960    159580\n",
      "\n",
      "remove_non_alphabet_words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7904985499240436\n",
      "Log Loss:  1.3133370312483605\n",
      "Accuracy:  0.9619751848602581\n",
      "AUC score:  0.9762176142953759\n",
      "Num of comments missclassified:  6068\n",
      "[[142064   1286]\n",
      " [  4782  11448]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96744   0.99103   0.97909    143350\n",
      "          1    0.89901   0.70536   0.79050     16230\n",
      "\n",
      "avg / total    0.96048   0.96198   0.95991    159580\n",
      "\n",
      "remove_words_containing_non_alphabets\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7083576004659289\n",
      "Log Loss:  1.734088767184728\n",
      "Accuracy:  0.9497932071688181\n",
      "AUC score:  0.9481052246213902\n",
      "Num of comments missclassified:  8012\n",
      "[[141838   1512]\n",
      " [  6500   9730]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95618   0.98945   0.97253    143350\n",
      "          1    0.86550   0.59951   0.70836     16230\n",
      "\n",
      "avg / total    0.94696   0.94979   0.94566    159580\n",
      "\n",
      "black_listed_words_regex_mapping\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7913392581408915\n",
      "Log Loss:  1.3161511737128746\n",
      "Accuracy:  0.9618937210176713\n",
      "AUC score:  0.9775015682954804\n",
      "Num of comments missclassified:  6081\n",
      "[[141968   1382]\n",
      " [  4699  11531]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96796   0.99036   0.97903    143350\n",
      "          1    0.89298   0.71047   0.79134     16230\n",
      "\n",
      "avg / total    0.96034   0.96189   0.95994    159580\n",
      "\n",
      "check_if_proper_name_place_or_ethnicity\n",
      "Done  100000\n",
      "Done  200000\n",
      "Done  300000\n",
      "Done  400000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7957122242836528\n",
      "Log Loss:  1.2869319508861299\n",
      "Accuracy:  0.9627396916906881\n",
      "AUC score:  0.9772802178141604\n",
      "Num of comments missclassified:  5946\n",
      "[[142054   1296]\n",
      " [  4650  11580]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96830   0.99096   0.97950    143350\n",
      "          1    0.89935   0.71349   0.79571     16230\n",
      "\n",
      "avg / total    0.96129   0.96274   0.96081    159580\n",
      "\n",
      "replace_profane_words_using_fuzzy\n",
      "Done  100000\n",
      "Done  200000\n",
      "Done  300000\n",
      "Done  400000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7854951570094102\n",
      "Log Loss:  1.346885039147543\n",
      "Accuracy:  0.9610038851986464\n",
      "AUC score:  0.975301665262239\n",
      "Num of comments missclassified:  6223\n",
      "[[141963   1387]\n",
      " [  4836  11394]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96706   0.99032   0.97855    143350\n",
      "          1    0.89148   0.70203   0.78550     16230\n",
      "\n",
      "avg / total    0.95937   0.96100   0.95892    159580\n",
      "\n",
      "lemmatize_english_words\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7888168781025924\n",
      "Log Loss:  1.3258905455382075\n",
      "Accuracy:  0.9616117307933325\n",
      "AUC score:  0.9734354705778312\n",
      "Num of comments missclassified:  6126\n",
      "[[142013   1337]\n",
      " [  4789  11441]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96738   0.99067   0.97889    143350\n",
      "          1    0.89537   0.70493   0.78882     16230\n",
      "\n",
      "avg / total    0.96005   0.96161   0.95956    159580\n",
      "\n",
      "stemming_english_words\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7782328034982995\n",
      "Log Loss:  1.3830296917605813\n",
      "Accuracy:  0.9599573881438777\n",
      "AUC score:  0.9715457393188816\n",
      "Num of comments missclassified:  6390\n",
      "[[141978   1372]\n",
      " [  5018  11212]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96586   0.99043   0.97799    143350\n",
      "          1    0.89097   0.69082   0.77823     16230\n",
      "\n",
      "avg / total    0.95825   0.95996   0.95768    159580\n",
      "\n",
      "extract_info_from_url\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7952718026252491\n",
      "Log Loss:  1.2895291968764084\n",
      "Accuracy:  0.962664494297531\n",
      "AUC score:  0.9772779178623645\n",
      "Num of comments missclassified:  5958\n",
      "[[142050   1300]\n",
      " [  4658  11572]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96825   0.99093   0.97946    143350\n",
      "          1    0.89901   0.71300   0.79527     16230\n",
      "\n",
      "avg / total    0.96121   0.96266   0.96073    159580\n",
      "\n",
      "[('strip_non_printable_chars', 0.7958762886597938), ('trim_words_len', 0.7957543281121187), ('remove_whitespaces', 0.7957122242836528), ('check_if_proper_name_place_or_ethnicity', 0.7957122242836528), ('extract_info_from_url', 0.7952718026252491), ('remove_leaky', 0.7951310088714669), ('replace_abbreviation_words', 0.7950523964954475), ('convert_to_lower', 0.7936014372581537), ('replace_acronyms', 0.7934344998451532), ('black_listed_words_regex_mapping', 0.7913392581408915), ('remove_non_alphabet_words', 0.7904985499240436), ('lemmatize_english_words', 0.7888168781025924), ('remove_non_alphanumeric', 0.788542135707111), ('remove_stopwords', 0.7859629770071356), ('replace_profane_words_using_fuzzy', 0.7854951570094102), ('remove_rare_words', 0.7848947386555489), ('stemming_english_words', 0.7782328034982995), ('remove_words_containing_non_alphabets', 0.7083576004659289)]\n",
      "Any other transformation not needed\n"
     ]
    }
   ],
   "source": [
    "#Loop through all the transformations to see which one gives the maximum boost to f1_score\n",
    "while(True):\n",
    "    tr_iter_score = []\n",
    "    X_best = None\n",
    "    tr_best = None\n",
    "    max_f1_local = max_f1\n",
    "    for tr in transformations:\n",
    "        pp_steps = [tr]\n",
    "        base_res, X = call_logit_to_recursive_transformation_Addition(pp_steps, word_dist_dict_most_common_copy,train_data_copy, 'nbsvm')\n",
    "        tr_iter_score.append((pp_steps[0][0], base_res))\n",
    "        if max_f1_local < base_res[tr[0]][0]:\n",
    "            max_f1_local = base_res[tr[0]][0]\n",
    "            X_best = X\n",
    "            tr_best = tr[0]  \n",
    "            print ('\\n\\n\\n ========= ', tr_best)\n",
    "    key_neg_f1 = []\n",
    "    for k in tr_iter_score:\n",
    "        key_neg_f1.append((k[0], k[1][k[0]][0]))\n",
    "    ordered = sorted(key_neg_f1,key=itemgetter(1), reverse=True)\n",
    "    print(ordered)\n",
    "    if max_f1 >= ordered[0][1]:\n",
    "        print ('Any other transformation not needed')\n",
    "        break\n",
    "    # Add transformation into the    \n",
    "    tr_scores.append(ordered[0])\n",
    "    max_f1 = ordered[0][1]\n",
    "    transformations.remove([ordered[0][0]])\n",
    "    train_data_copy['comment_text'] = X_best\n",
    "    word_dist_dict_most_common_copy = get_words_dict_most_common(train_data_copy)\n",
    "    print(transformations)\n",
    "    print ('*******************')\n",
    "    print (tr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NBSVM [('replace_common_words_using_fuzzy',  0.7968 )]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black_listed_words_regex_mapping\n",
      "black_listed_words_regex_mapping\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "Done  500000\n"
     ]
    }
   ],
   "source": [
    "train_data_copy = train_data.copy()\n",
    "word_dist_dict_most_common_copy = word_dist_dict_most_common\n",
    "\n",
    "tr_scores = []\n",
    "transformations = transformations_orig.copy()\n",
    "pp_steps = ['black_listed_words_regex_mapping']\n",
    "max_f1 = 0.6252\n",
    "tr_scores.append((pp_steps[0], max_f1))\n",
    "transformations.remove(pp_steps)\n",
    "\n",
    "new_mapped_dict = get_corresponding_mapping_multiple(word_dist_dict_most_common, pp_steps, train_data_copy)\n",
    "X = train_data_copy['comment_text'].apply(replace_words_from_a_mapping_no_check, args = [new_mapped_dict, 0])\n",
    "train_data_copy['comment_text'] = X\n",
    "word_dist_dict_most_common_copy = get_words_dict_most_common(train_data_copy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert_to_lower\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5756802353246528\n",
      "Log Loss:  2.1230169442529148\n",
      "Accuracy:  0.9385323975435518\n",
      "AUC score:  0.9195745832761139\n",
      "Num of comments missclassified:  9809\n",
      "[[143117    233]\n",
      " [  9576   6654]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93729   0.99837   0.96687    143350\n",
      "          1    0.96617   0.40998   0.57568     16230\n",
      "\n",
      "avg / total    0.94022   0.93853   0.92708    159580\n",
      "\n",
      "remove_whitespaces\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5726540161164544\n",
      "Log Loss:  2.134920946619718\n",
      "Accuracy:  0.9381877428249153\n",
      "AUC score:  0.9196245355556603\n",
      "Num of comments missclassified:  9864\n",
      "[[143107    243]\n",
      " [  9621   6609]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93701   0.99830   0.96668    143350\n",
      "          1    0.96454   0.40721   0.57265     16230\n",
      "\n",
      "avg / total    0.93981   0.93819   0.92661    159580\n",
      "\n",
      "remove_leaky\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5734701831882552\n",
      "Log Loss:  2.1316743991531433\n",
      "Accuracy:  0.9382817395663617\n",
      "AUC score:  0.9197877034029273\n",
      "Num of comments missclassified:  9849\n",
      "[[143110    240]\n",
      " [  9609   6621]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93708   0.99833   0.96673    143350\n",
      "          1    0.96502   0.40795   0.57347     16230\n",
      "\n",
      "avg / total    0.93992   0.93828   0.92674    159580\n",
      "\n",
      "trim_words_len\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5726421636615812\n",
      "Log Loss:  2.134055169562683\n",
      "Accuracy:  0.9382128086226345\n",
      "AUC score:  0.9196741433367267\n",
      "Num of comments missclassified:  9860\n",
      "[[143114    236]\n",
      " [  9624   6606]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93699   0.99835   0.96670    143350\n",
      "          1    0.96551   0.40702   0.57264     16230\n",
      "\n",
      "avg / total    0.93989   0.93821   0.92662    159580\n",
      "\n",
      "strip_non_printable_chars\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5728638863626522\n",
      "Log Loss:  2.134704531166621\n",
      "Accuracy:  0.9381940092743452\n",
      "AUC score:  0.9197124671270438\n",
      "Num of comments missclassified:  9863\n",
      "[[143103    247]\n",
      " [  9616   6614]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93703   0.99828   0.96669    143350\n",
      "          1    0.96400   0.40752   0.57286     16230\n",
      "\n",
      "avg / total    0.93978   0.93819   0.92663    159580\n",
      "\n",
      "replace_abbreviation_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5736313236313236\n",
      "Log Loss:  2.1305922016323753\n",
      "Accuracy:  0.9383130718135104\n",
      "AUC score:  0.9201340309696182\n",
      "Num of comments missclassified:  9844\n",
      "[[143114    236]\n",
      " [  9608   6622]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93709   0.99835   0.96675    143350\n",
      "          1    0.96559   0.40801   0.57363     16230\n",
      "\n",
      "avg / total    0.93999   0.93831   0.92677    159580\n",
      "\n",
      "replace_acronyms\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5737584674461751\n",
      "Log Loss:  2.13816775463941\n",
      "Accuracy:  0.9380937460834691\n",
      "AUC score:  0.9198144683344003\n",
      "Num of comments missclassified:  9879\n",
      "[[143052    298]\n",
      " [  9581   6649]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93723   0.99792   0.96662    143350\n",
      "          1    0.95710   0.40967   0.57376     16230\n",
      "\n",
      "avg / total    0.93925   0.93809   0.92667    159580\n",
      "\n",
      "remove_stopwords\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5642543191609731\n",
      "Log Loss:  2.16716995071536\n",
      "Accuracy:  0.9372540418598821\n",
      "AUC score:  0.9007303535396842\n",
      "Num of comments missclassified:  10013\n",
      "[[143084    266]\n",
      " [  9747   6483]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93622   0.99814   0.96619    143350\n",
      "          1    0.96059   0.39945   0.56425     16230\n",
      "\n",
      "avg / total    0.93870   0.93725   0.92531    159580\n",
      "\n",
      "remove_rare_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5607623710438888\n",
      "Log Loss:  2.1747450227012557\n",
      "Accuracy:  0.9370347161298408\n",
      "AUC score:  0.9141752272282314\n",
      "Num of comments missclassified:  10048\n",
      "[[143118    232]\n",
      " [  9816   6414]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93582   0.99838   0.96609    143350\n",
      "          1    0.96509   0.39519   0.56076     16230\n",
      "\n",
      "avg / total    0.93879   0.93703   0.92486    159580\n",
      "\n",
      "remove_non_alphanumeric\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5680246967259446\n",
      "Log Loss:  2.150287836746639\n",
      "Accuracy:  0.937742824915403\n",
      "AUC score:  0.9163370701640031\n",
      "Num of comments missclassified:  9935\n",
      "[[143113    237]\n",
      " [  9698   6532]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93654   0.99835   0.96645    143350\n",
      "          1    0.96499   0.40246   0.56802     16230\n",
      "\n",
      "avg / total    0.93943   0.93774   0.92593    159580\n",
      "\n",
      "remove_non_alphabet_words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5697406715607489\n",
      "Log Loss:  2.1437947518347635\n",
      "Accuracy:  0.9379308183982955\n",
      "AUC score:  0.9164988095138317\n",
      "Num of comments missclassified:  9905\n",
      "[[143117    233]\n",
      " [  9672   6558]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93670   0.99837   0.96655    143350\n",
      "          1    0.96569   0.40407   0.56974     16230\n",
      "\n",
      "avg / total    0.93965   0.93793   0.92620    159580\n",
      "\n",
      "remove_words_containing_non_alphabets\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.48238557558945916\n",
      "Log Loss:  2.423212726179658\n",
      "Accuracy:  0.9298408321844843\n",
      "AUC score:  0.8866361176246325\n",
      "Num of comments missclassified:  11196\n",
      "[[143167    183]\n",
      " [ 11013   5217]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.92857   0.99872   0.96237    143350\n",
      "          1    0.96611   0.32144   0.48239     16230\n",
      "\n",
      "avg / total    0.93239   0.92984   0.91355    159580\n",
      "\n",
      "check_if_proper_name_place_or_ethnicity\n",
      "Done  100000\n",
      "Done  200000\n",
      "Done  300000\n",
      "Done  400000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5726540161164544\n",
      "Log Loss:  2.134920946619718\n",
      "Accuracy:  0.9381877428249153\n",
      "AUC score:  0.9196245355556603\n",
      "Num of comments missclassified:  9864\n",
      "[[143107    243]\n",
      " [  9621   6609]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93701   0.99830   0.96668    143350\n",
      "          1    0.96454   0.40721   0.57265     16230\n",
      "\n",
      "avg / total    0.93981   0.93819   0.92661    159580\n",
      "\n",
      "replace_profane_words_using_fuzzy\n",
      "Done  100000\n",
      "Done  200000\n",
      "Done  300000\n",
      "Done  400000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.6082033215903372\n",
      "Log Loss:  2.021942219169839\n",
      "Accuracy:  0.9414588294272466\n",
      "AUC score:  0.9257875596290764\n",
      "Num of comments missclassified:  9342\n",
      "[[142987    363]\n",
      " [  8979   7251]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.94091   0.99747   0.96837    143350\n",
      "          1    0.95232   0.44677   0.60820     16230\n",
      "\n",
      "avg / total    0.94207   0.94146   0.93174    159580\n",
      "\n",
      "replace_common_words_using_fuzzy\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5793965517241378\n",
      "Log Loss:  2.1119788141452482\n",
      "Accuracy:  0.9388519864644692\n",
      "AUC score:  0.9223539288837369\n",
      "Num of comments missclassified:  9758\n",
      "[[143101    249]\n",
      " [  9509   6721]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93769   0.99826   0.96703    143350\n",
      "          1    0.96428   0.41411   0.57940     16230\n",
      "\n",
      "avg / total    0.94039   0.93885   0.92761    159580\n",
      "\n",
      "lemmatize_english_words\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5721834798804523\n",
      "Log Loss:  2.1377346531588253\n",
      "Accuracy:  0.9381062789823286\n",
      "AUC score:  0.9194120032038572\n",
      "Num of comments missclassified:  9877\n",
      "[[143098    252]\n",
      " [  9625   6605]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93698   0.99824   0.96664    143350\n",
      "          1    0.96325   0.40696   0.57218     16230\n",
      "\n",
      "avg / total    0.93965   0.93811   0.92652    159580\n",
      "\n",
      "stemming_english_words\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5919133327646506\n",
      "Log Loss:  2.0708562102706716\n",
      "Accuracy:  0.9400426118561224\n",
      "AUC score:  0.9225340201382248\n",
      "Num of comments missclassified:  9568\n",
      "[[143073    277]\n",
      " [  9291   6939]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93902   0.99807   0.96764    143350\n",
      "          1    0.96161   0.42754   0.59191     16230\n",
      "\n",
      "avg / total    0.94132   0.94004   0.92943    159580\n",
      "\n",
      "extract_info_from_url\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5736051595030948\n",
      "Log Loss:  2.1321073052188906\n",
      "Accuracy:  0.9382692066675022\n",
      "AUC score:  0.9197994556795077\n",
      "Num of comments missclassified:  9851\n",
      "[[143103    247]\n",
      " [  9604   6626]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93711   0.99828   0.96673    143350\n",
      "          1    0.96406   0.40826   0.57361     16230\n",
      "\n",
      "avg / total    0.93985   0.93827   0.92674    159580\n",
      "\n",
      "[('replace_profane_words_using_fuzzy', 0.6082033215903372), ('stemming_english_words', 0.5919133327646506), ('replace_common_words_using_fuzzy', 0.5793965517241378), ('convert_to_lower', 0.5756802353246528), ('replace_acronyms', 0.5737584674461751), ('replace_abbreviation_words', 0.5736313236313236), ('extract_info_from_url', 0.5736051595030948), ('remove_leaky', 0.5734701831882552), ('strip_non_printable_chars', 0.5728638863626522), ('remove_whitespaces', 0.5726540161164544), ('check_if_proper_name_place_or_ethnicity', 0.5726540161164544), ('trim_words_len', 0.5726421636615812), ('lemmatize_english_words', 0.5721834798804523), ('remove_non_alphabet_words', 0.5697406715607489), ('remove_non_alphanumeric', 0.5680246967259446), ('remove_stopwords', 0.5642543191609731), ('remove_rare_words', 0.5607623710438888), ('remove_words_containing_non_alphabets', 0.48238557558945916)]\n",
      "Any other transformation not needed\n"
     ]
    }
   ],
   "source": [
    "#Loop through all the transformations to see which one gives the maximum boost to f1_score\n",
    "while(True):\n",
    "    tr_iter_score = []\n",
    "    for tr in transformations:\n",
    "        pp_steps = [tr]\n",
    "        base_res, X = call_xgboost_to_recursive_transformation_Addition(pp_steps, word_dist_dict_most_common_copy,train_data_copy)\n",
    "        tr_iter_score.append((pp_steps[0][0], base_res))\n",
    "    key_neg_f1 = []\n",
    "    for k in tr_iter_score:\n",
    "        key_neg_f1.append((k[0], k[1][k[0]][0]))\n",
    "    ordered = sorted(key_neg_f1,key=itemgetter(1), reverse=True)\n",
    "    print(ordered)\n",
    "    if max_f1 >= ordered[0][1]:\n",
    "        print ('Any other transformation not needed')\n",
    "        break\n",
    "    # Add transformation into the    \n",
    "    tr_scores.append(ordered[0])\n",
    "    max_f1 = ordered[0][1]\n",
    "    transformations.remove([ordered[0][0]])\n",
    "    train_data_copy['comment_text'] = X\n",
    "    word_dist_dict_most_common_copy = get_words_dict_most_common(train_data_copy)\n",
    "    print(transformations)\n",
    "    print ('*******************')\n",
    "    print (tr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NBSVM [('black_listed_words_regex_mapping',  0.6252)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def call_fasttext_to_recursive_transformation_Addition(pp_steps, word_dist_dict_most_common,train_data):\n",
    "    combined_results = {}\n",
    "    for pp_step in pp_steps:\n",
    "        if len(pp_step) == 1:\n",
    "            new_mapped_dict = get_corresponding_mapping(word_dist_dict_most_common, pp_step[0])\n",
    "        else:\n",
    "            new_mapped_dict = get_corresponding_mapping_multiple(word_dist_dict_most_common, pp_step, train_data)\n",
    "        X = train_data['comment_text'].apply(replace_words_from_a_mapping_no_check, args = [new_mapped_dict, 0])\n",
    "        results = []\n",
    "        k_fold_num = 0\n",
    "        cv = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=42)\n",
    "        for train_index, test_index in cv.split(X, y):\n",
    "            print (\"\\n\\n *****Processing fold \", k_fold_num, \" of \", cv.n_splits, \" ......\")\n",
    "            X_train_data, X_test_data = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            texts_train = X_train_data.values\n",
    "            texts_test  = X_test_data.values\n",
    "            train = X.copy()\n",
    "            X_train, X_test, embedding_matrix = preprocess_data_for_fasttext(texts_train, texts_test, train)\n",
    "            res = call_fasttext_algorithm(X_train, y_train, X_test, y_test, embedding_matrix)\n",
    "            results.append(res)\n",
    "            k_fold_num += 1\n",
    "\n",
    "    #         if k_fold_num ==1:\n",
    "    #             break\n",
    "        scores = extract_combined_results(results)\n",
    "        combined_results[' '.join(pp_step)] = scores\n",
    "        pickle.dump(combined_results, open(\"../data/individual_fasttext.pkl\", \"wb\"))\n",
    "    return combined_results, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert_to_lower\n",
      "convert_to_lower\n"
     ]
    }
   ],
   "source": [
    "train_data_copy = train_data.copy()\n",
    "word_dist_dict_most_common_copy = word_dist_dict_most_common\n",
    "\n",
    "tr_scores = []\n",
    "transformations = transformations_orig.copy()\n",
    "pp_steps = ['convert_to_lower']\n",
    "max_f1 = 0.8055\n",
    "tr_scores.append((pp_steps[0], max_f1))\n",
    "transformations.remove(pp_steps)\n",
    "\n",
    "new_mapped_dict = get_corresponding_mapping_multiple(word_dist_dict_most_common, pp_steps, train_data_copy)\n",
    "X = train_data_copy['comment_text'].apply(replace_words_from_a_mapping_no_check, args = [new_mapped_dict, 0])\n",
    "train_data_copy['comment_text'] = X\n",
    "word_dist_dict_most_common_copy = get_words_dict_most_common(train_data_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove_non_alphabet_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 179s 1ms/step - loss: 0.1247 - acc: 0.9540\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 179s 1ms/step - loss: 0.1024 - acc: 0.9617\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 179s 1ms/step - loss: 0.0969 - acc: 0.9632\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 179s 1ms/step - loss: 0.1225 - acc: 0.9539\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1012 - acc: 0.9615\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.0957 - acc: 0.9631\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 179s 1ms/step - loss: 0.1254 - acc: 0.9544\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 179s 1ms/step - loss: 0.1011 - acc: 0.9615\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 180s 1ms/step - loss: 0.0964 - acc: 0.9636\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 179s 1ms/step - loss: 0.1224 - acc: 0.9544\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 177s 1ms/step - loss: 0.1025 - acc: 0.9613\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 177s 1ms/step - loss: 0.0969 - acc: 0.9633\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 176s 1ms/step - loss: 0.1252 - acc: 0.9535\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 175s 1ms/step - loss: 0.1021 - acc: 0.9611\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 175s 1ms/step - loss: 0.0975 - acc: 0.9634\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 176s 1ms/step - loss: 0.1247 - acc: 0.9540\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 176s 1ms/step - loss: 0.1014 - acc: 0.9619\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 175s 1ms/step - loss: 0.0972 - acc: 0.9633\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 177s 1ms/step - loss: 0.1263 - acc: 0.9527\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 174s 1ms/step - loss: 0.1041 - acc: 0.9609\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 174s 1ms/step - loss: 0.0988 - acc: 0.9623\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 173s 1ms/step - loss: 0.1279 - acc: 0.9519\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 175s 1ms/step - loss: 0.1031 - acc: 0.9607\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 175s 1ms/step - loss: 0.0982 - acc: 0.9632\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 173s 1ms/step - loss: 0.1287 - acc: 0.9521\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 173s 1ms/step - loss: 0.1024 - acc: 0.9609\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 173s 1ms/step - loss: 0.0973 - acc: 0.9629\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 176s 1ms/step - loss: 0.1239 - acc: 0.9538\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 173s 1ms/step - loss: 0.1028 - acc: 0.9612\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 173s 1ms/step - loss: 0.0979 - acc: 0.9624\n",
      "F1-score:  0.801844241756039\n",
      "Log Loss:  1.2836874477593945\n",
      "Accuracy:  0.9628336884321343\n",
      "AUC score:  0.979430545087716\n",
      "Num of comments missclassified:  5931\n",
      "[[141649   1701]\n",
      " [  4230  12000]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.97100   0.98813   0.97949    143350\n",
      "          1    0.87585   0.73937   0.80184     16230\n",
      "\n",
      "avg / total    0.96133   0.96283   0.96143    159580\n",
      "\n",
      "remove_words_containing_non_alphabets\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 176s 1ms/step - loss: 0.1558 - acc: 0.9444\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 175s 1ms/step - loss: 0.1371 - acc: 0.9506\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 174s 1ms/step - loss: 0.1321 - acc: 0.9523\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 173s 1ms/step - loss: 0.1610 - acc: 0.9419\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 174s 1ms/step - loss: 0.1396 - acc: 0.9503\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 172s 1ms/step - loss: 0.1344 - acc: 0.9514\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 175s 1ms/step - loss: 0.1560 - acc: 0.9441\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 171s 1ms/step - loss: 0.1383 - acc: 0.9502\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 171s 1ms/step - loss: 0.1339 - acc: 0.9517\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 175s 1ms/step - loss: 0.1566 - acc: 0.9443\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 174s 1ms/step - loss: 0.1384 - acc: 0.9504\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 173s 1ms/step - loss: 0.1336 - acc: 0.9516\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 173s 1ms/step - loss: 0.1608 - acc: 0.9419\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 172s 1ms/step - loss: 0.1388 - acc: 0.9500\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 172s 1ms/step - loss: 0.1336 - acc: 0.9519\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 174s 1ms/step - loss: 0.1584 - acc: 0.9435\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 173s 1ms/step - loss: 0.1394 - acc: 0.9499\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 173s 1ms/step - loss: 0.1337 - acc: 0.9516\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 175s 1ms/step - loss: 0.1585 - acc: 0.9432\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 172s 1ms/step - loss: 0.1390 - acc: 0.9505\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 172s 1ms/step - loss: 0.1335 - acc: 0.9519\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 175s 1ms/step - loss: 0.1588 - acc: 0.9437\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 172s 1ms/step - loss: 0.1387 - acc: 0.9495\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 172s 1ms/step - loss: 0.1339 - acc: 0.9513\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 174s 1ms/step - loss: 0.1567 - acc: 0.9433\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 172s 1ms/step - loss: 0.1377 - acc: 0.9505\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 171s 1ms/step - loss: 0.1336 - acc: 0.9518\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 174s 1ms/step - loss: 0.1562 - acc: 0.9443\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 173s 1ms/step - loss: 0.1377 - acc: 0.9500\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 173s 1ms/step - loss: 0.1338 - acc: 0.9520\n",
      "F1-score:  0.7207078124440305\n",
      "Log Loss:  1.6875557118444517\n",
      "Accuracy:  0.951140493796215\n",
      "AUC score:  0.955053427781363\n",
      "Num of comments missclassified:  7797\n",
      "[[141723   1627]\n",
      " [  6170  10060]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95828   0.98865   0.97323    143350\n",
      "          1    0.86079   0.61984   0.72071     16230\n",
      "\n",
      "avg / total    0.94836   0.95114   0.94755    159580\n",
      "\n",
      "black_listed_words_regex_mapping\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 174s 1ms/step - loss: 0.1223 - acc: 0.9546\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1021 - acc: 0.9616\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.0971 - acc: 0.9631\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 172s 1ms/step - loss: 0.1245 - acc: 0.9542\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1029 - acc: 0.9615\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.0982 - acc: 0.9633\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 172s 1ms/step - loss: 0.1240 - acc: 0.9543\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1033 - acc: 0.9609\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.0983 - acc: 0.9628\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 172s 1ms/step - loss: 0.1254 - acc: 0.9534\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1022 - acc: 0.9613\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.0977 - acc: 0.9630\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 173s 1ms/step - loss: 0.1280 - acc: 0.9523\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 170s 1ms/step - loss: 0.1035 - acc: 0.9611\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 170s 1ms/step - loss: 0.0989 - acc: 0.9625\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 173s 1ms/step - loss: 0.1226 - acc: 0.9550\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 171s 1ms/step - loss: 0.1032 - acc: 0.9612\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.0982 - acc: 0.9635\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 172s 1ms/step - loss: 0.1218 - acc: 0.9546\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1019 - acc: 0.9616\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.0977 - acc: 0.9630\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 173s 1ms/step - loss: 0.1240 - acc: 0.9540\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1027 - acc: 0.9615\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.0977 - acc: 0.9629\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 171s 1ms/step - loss: 0.1227 - acc: 0.9545\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1022 - acc: 0.9612\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.0967 - acc: 0.9635\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 173s 1ms/step - loss: 0.1217 - acc: 0.9541\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1019 - acc: 0.9614\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.0981 - acc: 0.9627\n",
      "F1-score:  0.8046815423891782\n",
      "Log Loss:  1.2750305039441256\n",
      "Accuracy:  0.9630843464093245\n",
      "AUC score:  0.9792061934078508\n",
      "Num of comments missclassified:  5891\n",
      "[[141554   1796]\n",
      " [  4095  12135]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.97188   0.98747   0.97962    143350\n",
      "          1    0.87108   0.74769   0.80468     16230\n",
      "\n",
      "avg / total    0.96163   0.96308   0.96182    159580\n",
      "\n",
      "check_if_proper_name_place_or_ethnicity\n",
      "Done  100000\n",
      "Done  200000\n",
      "Done  300000\n",
      "Done  400000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 173s 1ms/step - loss: 0.1282 - acc: 0.9525\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1061 - acc: 0.9599\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1005 - acc: 0.9619\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 173s 1ms/step - loss: 0.1327 - acc: 0.9500\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 170s 1ms/step - loss: 0.1080 - acc: 0.9594\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 170s 1ms/step - loss: 0.1019 - acc: 0.9615\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 174s 1ms/step - loss: 0.1274 - acc: 0.9515\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 170s 1ms/step - loss: 0.1060 - acc: 0.9597\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1005 - acc: 0.9614\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 174s 1ms/step - loss: 0.1303 - acc: 0.9513\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1073 - acc: 0.9589\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 170s 1ms/step - loss: 0.1025 - acc: 0.9610\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 174s 1ms/step - loss: 0.1326 - acc: 0.9513\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1086 - acc: 0.9592\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 170s 1ms/step - loss: 0.1027 - acc: 0.9610\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 174s 1ms/step - loss: 0.1305 - acc: 0.9516\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 170s 1ms/step - loss: 0.1070 - acc: 0.9590\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 170s 1ms/step - loss: 0.1020 - acc: 0.9613\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 176s 1ms/step - loss: 0.1316 - acc: 0.9513\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 171s 1ms/step - loss: 0.1073 - acc: 0.9596\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 171s 1ms/step - loss: 0.1008 - acc: 0.9618\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 176s 1ms/step - loss: 0.1286 - acc: 0.9523\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 171s 1ms/step - loss: 0.1078 - acc: 0.9594\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 171s 1ms/step - loss: 0.1024 - acc: 0.9609\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 176s 1ms/step - loss: 0.1304 - acc: 0.9516\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 171s 1ms/step - loss: 0.1076 - acc: 0.9587\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 170s 1ms/step - loss: 0.1021 - acc: 0.9610\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 175s 1ms/step - loss: 0.1269 - acc: 0.9525\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 170s 1ms/step - loss: 0.1070 - acc: 0.9596\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1015 - acc: 0.9610\n",
      "F1-score:  0.7935718260072661\n",
      "Log Loss:  1.3650696944294287\n",
      "Accuracy:  0.9604775034465471\n",
      "AUC score:  0.9768308774653508\n",
      "Num of comments missclassified:  6307\n",
      "[[141150   2200]\n",
      " [  4107  12123]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.97173   0.98465   0.97815    143350\n",
      "          1    0.84640   0.74695   0.79357     16230\n",
      "\n",
      "avg / total    0.95898   0.96048   0.95937    159580\n",
      "\n",
      "replace_profane_words_using_fuzzy\n",
      "Done  100000\n",
      "Done  200000\n",
      "Done  300000\n",
      "Done  400000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 177s 1ms/step - loss: 0.1302 - acc: 0.9515\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 171s 1ms/step - loss: 0.1065 - acc: 0.9598\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 171s 1ms/step - loss: 0.1007 - acc: 0.9615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 174s 1ms/step - loss: 0.1295 - acc: 0.9520\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1077 - acc: 0.9593\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1023 - acc: 0.9611\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 175s 1ms/step - loss: 0.1258 - acc: 0.9529\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1054 - acc: 0.9597\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1009 - acc: 0.9613\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 176s 1ms/step - loss: 0.1248 - acc: 0.9534\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1058 - acc: 0.9599\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1009 - acc: 0.9616\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 174s 1ms/step - loss: 0.1293 - acc: 0.9515\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1072 - acc: 0.9592\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1016 - acc: 0.9614\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 174s 1ms/step - loss: 0.1318 - acc: 0.9511\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1085 - acc: 0.9594\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 167s 1ms/step - loss: 0.1030 - acc: 0.9613\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 175s 1ms/step - loss: 0.1267 - acc: 0.9527\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1074 - acc: 0.9597\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1020 - acc: 0.9611\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 175s 1ms/step - loss: 0.1258 - acc: 0.9527\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1066 - acc: 0.9596\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1016 - acc: 0.9612\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 175s 1ms/step - loss: 0.1288 - acc: 0.9521\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1068 - acc: 0.9595\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1021 - acc: 0.9609\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 176s 1ms/step - loss: 0.1273 - acc: 0.9522\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1076 - acc: 0.9590\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1023 - acc: 0.9608\n",
      "F1-score:  0.7925780861021675\n",
      "Log Loss:  1.3525152231079416\n",
      "Accuracy:  0.9608409575134729\n",
      "AUC score:  0.977410318105555\n",
      "Num of comments missclassified:  6249\n",
      "[[141392   1958]\n",
      " [  4291  11939]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.97055   0.98634   0.97838    143350\n",
      "          1    0.85911   0.73561   0.79258     16230\n",
      "\n",
      "avg / total    0.95921   0.96084   0.95948    159580\n",
      "\n",
      "replace_common_words_using_fuzzy\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 176s 1ms/step - loss: 0.1291 - acc: 0.9523\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1063 - acc: 0.9598\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1013 - acc: 0.9615\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 176s 1ms/step - loss: 0.1324 - acc: 0.9501\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1071 - acc: 0.9595\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1017 - acc: 0.9612\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 176s 1ms/step - loss: 0.1307 - acc: 0.9512\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1071 - acc: 0.9599\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1023 - acc: 0.9616\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 176s 1ms/step - loss: 0.1315 - acc: 0.9514\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1082 - acc: 0.9590\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1030 - acc: 0.9610\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 177s 1ms/step - loss: 0.1281 - acc: 0.9525\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1071 - acc: 0.9595\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1016 - acc: 0.9614\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 177s 1ms/step - loss: 0.1278 - acc: 0.9519\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1061 - acc: 0.9599\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1012 - acc: 0.9619\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1331 - acc: 0.9500\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1083 - acc: 0.9595\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1027 - acc: 0.9613\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1304 - acc: 0.9512\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1067 - acc: 0.9597\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 170s 1ms/step - loss: 0.1017 - acc: 0.9609\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1268 - acc: 0.9527\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1058 - acc: 0.9600\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1004 - acc: 0.9619\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1290 - acc: 0.9520\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 170s 1ms/step - loss: 0.1057 - acc: 0.9595\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 170s 1ms/step - loss: 0.1010 - acc: 0.9617\n",
      "F1-score:  0.7925047852513516\n",
      "Log Loss:  1.3373636911897393\n",
      "Accuracy:  0.9612796089735556\n",
      "AUC score:  0.9762342877638998\n",
      "Num of comments missclassified:  6179\n",
      "[[141601   1749]\n",
      " [  4430  11800]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96966   0.98780   0.97865    143350\n",
      "          1    0.87091   0.72705   0.79250     16230\n",
      "\n",
      "avg / total    0.95962   0.96128   0.95972    159580\n",
      "\n",
      "lemmatize_english_words\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1292 - acc: 0.9511\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1085 - acc: 0.9589\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1027 - acc: 0.9609\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143613/143613 [==============================] - 177s 1ms/step - loss: 0.1315 - acc: 0.9504\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1084 - acc: 0.9593\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1021 - acc: 0.9611\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1324 - acc: 0.9501\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1074 - acc: 0.9597\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1017 - acc: 0.9612\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1350 - acc: 0.9501\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1085 - acc: 0.9585\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1028 - acc: 0.9607\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1312 - acc: 0.9511\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1082 - acc: 0.9585\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1022 - acc: 0.9612\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 179s 1ms/step - loss: 0.1312 - acc: 0.9505\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 170s 1ms/step - loss: 0.1079 - acc: 0.9591\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 170s 1ms/step - loss: 0.1025 - acc: 0.9610\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 180s 1ms/step - loss: 0.1322 - acc: 0.9504\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 170s 1ms/step - loss: 0.1079 - acc: 0.9590\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 170s 1ms/step - loss: 0.1023 - acc: 0.9608\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 180s 1ms/step - loss: 0.1286 - acc: 0.9516\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 170s 1ms/step - loss: 0.1065 - acc: 0.9596\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 170s 1ms/step - loss: 0.1012 - acc: 0.9615\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 180s 1ms/step - loss: 0.1290 - acc: 0.9519\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 170s 1ms/step - loss: 0.1070 - acc: 0.9592\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 170s 1ms/step - loss: 0.1012 - acc: 0.9617\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 181s 1ms/step - loss: 0.1297 - acc: 0.9517\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 170s 1ms/step - loss: 0.1070 - acc: 0.9591\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 170s 1ms/step - loss: 0.1020 - acc: 0.9611\n",
      "F1-score:  0.7913798864016037\n",
      "Log Loss:  1.3514325395553968\n",
      "Accuracy:  0.9608722897606217\n",
      "AUC score:  0.977445750730528\n",
      "Num of comments missclassified:  6244\n",
      "[[141493   1857]\n",
      " [  4387  11843]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96993   0.98705   0.97841    143350\n",
      "          1    0.86445   0.72970   0.79138     16230\n",
      "\n",
      "avg / total    0.95920   0.96087   0.95939    159580\n",
      "\n",
      "stemming_english_words\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 185s 1ms/step - loss: 0.1223 - acc: 0.9550\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 172s 1ms/step - loss: 0.1019 - acc: 0.9618\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 172s 1ms/step - loss: 0.0967 - acc: 0.9635\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 180s 1ms/step - loss: 0.1249 - acc: 0.9534\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 170s 1ms/step - loss: 0.1017 - acc: 0.9615\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 170s 1ms/step - loss: 0.0968 - acc: 0.9634\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 181s 1ms/step - loss: 0.1225 - acc: 0.9543\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 170s 1ms/step - loss: 0.1009 - acc: 0.9619\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 170s 1ms/step - loss: 0.0963 - acc: 0.9629\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 198s 1ms/step - loss: 0.1238 - acc: 0.9540\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 171s 1ms/step - loss: 0.1017 - acc: 0.9616\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 170s 1ms/step - loss: 0.0966 - acc: 0.9632\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 183s 1ms/step - loss: 0.1269 - acc: 0.9527\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 171s 1ms/step - loss: 0.1030 - acc: 0.9608\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 172s 1ms/step - loss: 0.0977 - acc: 0.9629\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 182s 1ms/step - loss: 0.1269 - acc: 0.9530\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 171s 1ms/step - loss: 0.1037 - acc: 0.9611\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 171s 1ms/step - loss: 0.0981 - acc: 0.9628\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 183s 1ms/step - loss: 0.1215 - acc: 0.9548\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 172s 1ms/step - loss: 0.1021 - acc: 0.9614\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 172s 1ms/step - loss: 0.0972 - acc: 0.9631\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 184s 1ms/step - loss: 0.1267 - acc: 0.9529\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 172s 1ms/step - loss: 0.1028 - acc: 0.9613\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 172s 1ms/step - loss: 0.0977 - acc: 0.9632\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 183s 1ms/step - loss: 0.1255 - acc: 0.9537\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 171s 1ms/step - loss: 0.1036 - acc: 0.9610\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 171s 1ms/step - loss: 0.0980 - acc: 0.9629\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 183s 1ms/step - loss: 0.1261 - acc: 0.9535\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 171s 1ms/step - loss: 0.1030 - acc: 0.9614\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 171s 1ms/step - loss: 0.0979 - acc: 0.9628\n",
      "F1-score:  0.7970322187214148\n",
      "Log Loss:  1.2966726906153259\n",
      "Accuracy:  0.9624577014663491\n",
      "AUC score:  0.9792233888893546\n",
      "Num of comments missclassified:  5991\n",
      "[[141826   1524]\n",
      " [  4467  11763]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96947   0.98937   0.97932    143350\n",
      "          1    0.88530   0.72477   0.79703     16230\n",
      "\n",
      "avg / total    0.96091   0.96246   0.96078    159580\n",
      "\n",
      "extract_info_from_url\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 183s 1ms/step - loss: 0.1274 - acc: 0.9523\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 171s 1ms/step - loss: 0.1069 - acc: 0.9596\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 171s 1ms/step - loss: 0.1020 - acc: 0.9612\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 184s 1ms/step - loss: 0.1337 - acc: 0.9498\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143613/143613 [==============================] - 170s 1ms/step - loss: 0.1088 - acc: 0.9591\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 170s 1ms/step - loss: 0.1028 - acc: 0.9609\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 184s 1ms/step - loss: 0.1278 - acc: 0.9518\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 171s 1ms/step - loss: 0.1054 - acc: 0.9601\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 171s 1ms/step - loss: 0.1000 - acc: 0.9621\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 184s 1ms/step - loss: 0.1304 - acc: 0.9508\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 171s 1ms/step - loss: 0.1078 - acc: 0.9587\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 171s 1ms/step - loss: 0.1019 - acc: 0.9613\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 184s 1ms/step - loss: 0.1299 - acc: 0.9518\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 171s 1ms/step - loss: 0.1074 - acc: 0.9592\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 171s 1ms/step - loss: 0.1033 - acc: 0.9606\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 185s 1ms/step - loss: 0.1315 - acc: 0.9503\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 172s 1ms/step - loss: 0.1085 - acc: 0.9590\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 172s 1ms/step - loss: 0.1037 - acc: 0.9607\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 185s 1ms/step - loss: 0.1300 - acc: 0.9518\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 172s 1ms/step - loss: 0.1072 - acc: 0.9593\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 172s 1ms/step - loss: 0.1023 - acc: 0.9609\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 186s 1ms/step - loss: 0.1294 - acc: 0.9514\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 172s 1ms/step - loss: 0.1068 - acc: 0.9596\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 173s 1ms/step - loss: 0.1011 - acc: 0.9614\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 186s 1ms/step - loss: 0.1303 - acc: 0.9508\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 173s 1ms/step - loss: 0.1080 - acc: 0.9593\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 172s 1ms/step - loss: 0.1019 - acc: 0.9611\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 187s 1ms/step - loss: 0.1307 - acc: 0.9506\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 185s 1ms/step - loss: 0.1073 - acc: 0.9594\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1021 - acc: 0.9609\n",
      "F1-score:  0.7901652668653482\n",
      "Log Loss:  1.3410425083711792\n",
      "Accuracy:  0.9611730793332498\n",
      "AUC score:  0.9774382598765008\n",
      "Num of comments missclassified:  6196\n",
      "[[141718   1632]\n",
      " [  4564  11666]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96880   0.98862   0.97861    143350\n",
      "          1    0.87727   0.71879   0.79017     16230\n",
      "\n",
      "avg / total    0.95949   0.96117   0.95944    159580\n",
      "\n",
      "[('black_listed_words_regex_mapping', 0.8046815423891782), ('remove_non_alphabet_words', 0.801844241756039), ('stemming_english_words', 0.7970322187214148), ('check_if_proper_name_place_or_ethnicity', 0.7935718260072661), ('replace_profane_words_using_fuzzy', 0.7925780861021675), ('replace_common_words_using_fuzzy', 0.7925047852513516), ('lemmatize_english_words', 0.7913798864016037), ('extract_info_from_url', 0.7901652668653482), ('remove_words_containing_non_alphabets', 0.7207078124440305)]\n",
      "Any other transformation not needed\n"
     ]
    }
   ],
   "source": [
    "#Loop through all the transformations to see which one gives the maximum boost to f1_score\n",
    "while(True):\n",
    "    tr_iter_score = []\n",
    "    for tr in transformations:\n",
    "        pp_steps = [tr]\n",
    "        base_res, X = call_fasttext_to_recursive_transformation_Addition(pp_steps, word_dist_dict_most_common_copy,train_data_copy)\n",
    "        tr_iter_score.append((pp_steps[0][0], base_res))\n",
    "    key_neg_f1 = []\n",
    "    for k in tr_iter_score:\n",
    "        key_neg_f1.append((k[0], k[1][k[0]][0]))\n",
    "    ordered = sorted(key_neg_f1,key=itemgetter(1), reverse=True)\n",
    "    print(ordered)\n",
    "    if max_f1 >= ordered[0][1]:\n",
    "        print ('Any other transformation not needed')\n",
    "        break\n",
    "    # Add transformation into the    \n",
    "    tr_scores.append(ordered[0])\n",
    "    max_f1 = ordered[0][1]\n",
    "    transformations.remove([ordered[0][0]])\n",
    "    train_data_copy['comment_text'] = X\n",
    "    word_dist_dict_most_common_copy = get_words_dict_most_common(train_data_copy)\n",
    "    print(transformations)\n",
    "    print ('*******************')\n",
    "    print (tr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#FastText\n",
    "[('convert_to_lower', 0.8055), \n",
    "('remove_whitespaces', 0.7924943340887881), \n",
    "('remove_leaky', 0.78793867120954), \n",
    "('trim_words_len', 0.7891367342812858), \n",
    "('strip_non_printable_chars', 0.7888652984194385), \n",
    "('replace_abbreviation_words', 0.7891574399135836), \n",
    "('replace_acronyms', 0.7905618424982578), \n",
    "('remove_stopwords', 0.7878088514797718), \n",
    "('remove_rare_words', 0.7775245739940819), \n",
    "('remove_non_alphanumeric', 0.7985856382802947), \n",
    "('remove_non_alphabet_words', 0.801844241756039), \n",
    "('remove_words_containing_non_alphabets', 0.7207078124440305), \n",
    "('black_listed_words_regex_mapping', 0.8046815423891782), \n",
    "('check_if_proper_name_place_or_ethnicity', 0.7935718260072661), \n",
    "('replace_profane_words_using_fuzzy', 0.7925780861021675), \n",
    "('replace_common_words_using_fuzzy', 0.7925047852513516), \n",
    "('lemmatize_english_words', 0.7913798864016037), \n",
    "('stemming_english_words', 0.7970322187214148), \n",
    "('extract_info_from_url', 0.7901652668653482)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
