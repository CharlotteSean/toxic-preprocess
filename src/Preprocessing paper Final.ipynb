{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/fmohamm/anaconda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame, read_csv, concat, read_table, Series\n",
    "from operator import itemgetter\n",
    "import importlib\n",
    "import re \n",
    "import string\n",
    "import nltk\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import model_helper_functions\n",
    "importlib.reload(model_helper_functions)\n",
    "from model_helper_functions import *\n",
    "import preprocess_helper_functions\n",
    "importlib.reload(preprocess_helper_functions)\n",
    "from preprocess_helper_functions import *\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "from urlextract import URLExtract\n",
    "extractor = URLExtract()\n",
    "rare_word_thresh = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbrev_words_dict = pickle.load(open('../data/abbreviated_words_map.csv', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def list_to_dict(mylist):\n",
    "    mylist = [str(x).lower() for x in mylist]\n",
    "    ret_dict = dict(zip(mylist, [1]*len(mylist))) #make dictionary for efficient search\n",
    "    return ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_badlist = read_table('../data/profane_list.txt', header=None, comment='#')\n",
    "all_badlist = all_badlist.values.flatten().tolist()\n",
    "all_badlist = sorted(set([x.lower() for x in all_badlist]))\n",
    "all_badlist = [strip_non_printable_chars(str(x)).strip() for x in all_badlist]\n",
    "#all_badlist_dict = dict(zip(all_badlist, [1] * len(all_badlist)))\n",
    "\n",
    "#Read compiled acronyms and see if any acronyms are there\n",
    "acronyms = read_csv('../data/compiled_acronyms_final.csv', encoding = 'latin-1')\n",
    "acronyms = acronyms.apply(lambda x: x.astype(str).str.lower())\n",
    "acronyms = acronyms.dropna()\n",
    "acronyms = acronyms.drop_duplicates().reset_index(drop=True)\n",
    "global acronyms_dict \n",
    "acronyms_dict = dict(acronyms.values)\n",
    "\n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import wordnet\n",
    "proper_words = words.words()\n",
    "proper_words = sorted(set([x.lower() for x in proper_words]))\n",
    "global proper_words_dict\n",
    "proper_words_dict = list_to_dict(proper_words)\n",
    "\n",
    "proper_words.extend(all_badlist)\n",
    "global proper_words_with_profane_dict\n",
    "proper_words_with_profane_dict = list_to_dict(proper_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_profane = read_csv('../data/profane_x_common.csv', header=None)\n",
    "extreme_profane = extreme_profane.values.flatten().tolist()\n",
    "extreme_profane = [x.lower() for x in extreme_profane]\n",
    "\n",
    "badlist3 = read_csv('../data/profane_list_common.csv', encoding='latin-1')\n",
    "badlist_common = badlist3.values.flatten().tolist()\n",
    "badlist_common = [x.lower() for x in badlist_common]\n",
    "\n",
    "all_badlist_combined = sorted(set(all_badlist + badlist_common + extreme_profane))\n",
    "all_badlist_combined_dict = dict(zip(all_badlist_combined, [1] * len(all_badlist_combined)))\n",
    "\n",
    "profane_list_map = read_csv('../data/profane_list_common_mapping.csv', header=None)\n",
    "profane_list_map = profane_list_map.apply(lambda x: x.astype(str).str.lower())\n",
    "profane_list_map = dict(profane_list_map.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "citynames = read_table('../data/citynames.txt', sep='\\t', header=None, encoding='utf-8')\n",
    "citynames = citynames.iloc[:, 1].str.lower().values\n",
    "citynames = list_to_dict(citynames)\n",
    "\n",
    "#Look for countries\n",
    "countries = read_table('../data/countries.txt', header=None).values.flatten()\n",
    "countries = list_to_dict(countries)\n",
    "\n",
    "#Look for nationalities\n",
    "nationalities = read_table('../data/nationalities.txt', header=None).values.flatten()\n",
    "nationalities = list_to_dict(nationalities)\n",
    "\n",
    "ethnicities = read_table('../data/ethnicities.txt', header=None).values.flatten()\n",
    "ethnicities = list_to_dict(ethnicities)\n",
    "\n",
    "#Look for persons name\n",
    "person_names = []\n",
    "for fn in ['../data/names.first.female.txt', \n",
    "           '../data/names.first.male.txt',\n",
    "           '../data/names.last.txt',\n",
    "           '../data/muslim_names.txt',\n",
    "           '../data/englishnames.txt',\n",
    "          ]:\n",
    "    with open(fn, 'r') as ofd:\n",
    "        for line in ofd.readlines():\n",
    "            person_names.append(line.rstrip('\\n').lower())\n",
    "\n",
    "spanishnames = read_csv('../data/spanishnames.csv', encoding='utf-8')['nombre'].str.lower().str.split(' ')\n",
    "spanishnames = list(set(spanishnames.apply(Series).unstack().values))\n",
    "person_names.extend(spanishnames)\n",
    "\n",
    "person_names_dict = list_to_dict(person_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_csv(\"../data/train.csv\")\n",
    "train_data.head()\n",
    "train_data.fillna('NULL', inplace= True)\n",
    "train_data['profane'] = train_data[classes].any(axis = 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_data['profane'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get word frequency table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Word Frequency table\n",
    "tmp = train_data['comment_text'].str.cat(sep=' ')\n",
    "words = tmp.split()\n",
    "word_dist_dict = nltk.FreqDist(words)\n",
    "word_dist_dict_most_common = word_dist_dict.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dist_dict_df = DataFrame(word_dist_dict_most_common, columns=['raw_word', 'freq'])\n",
    "word_dist_dict_df.to_csv('../data/word_dist_train.csv', index=False)\n",
    "pickle.dump(word_dist_dict, open('../data/word_dist_train.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_steps = [\n",
    "#             ['raw'],  \n",
    "#             ['convert_to_lower'],\n",
    "#             ['remove_whitespaces'], \n",
    "#             ['remove_leaky'], \n",
    "#             ['trim_words_len'],\n",
    "#             ['replace_abbreviation_words'],\n",
    "#             ['strip_non_printable_chars'],\n",
    "#             ['replace_acronyms'],\n",
    "#             ['remove_stopwords'],\n",
    "#             ['remove_rare_words'],\n",
    "#             ['remove_non_alphanumeric'],\n",
    "#             ['remove_non_alphabet_words'],\n",
    "#             ['remove_words_containing_non_alphabets'],\n",
    "#             ['black_listed_words_regex_mapping'],\n",
    "#             ['check_if_proper_name_place_or_ethnicity'],\n",
    "#             ['replace_profane_words_using_fuzzy'],\n",
    "#             ['replace_common_words_using_fuzzy'],\n",
    "#             ['lemmatize_english_words'],\n",
    "#             ['stemming_english_words'],\n",
    "#             ['extract_info_from_url'],\n",
    "       \n",
    "#             ['remove_whitespaces', 'remove_leaky', 'replace_abbreviation_words', 'replace_acronyms' ], \n",
    "    \n",
    "            ['remove_whitespaces', 'remove_leaky', 'replace_abbreviation_words', 'replace_acronyms', \n",
    "             'remove_stopwords',   'remove_rare_words'],\n",
    "    \n",
    "#             ['remove_whitespaces', 'remove_leaky', 'replace_abbreviation_words', 'replace_acronyms',\n",
    "#             'black_listed_words_regex_mapping', 'replace_profane_words_using_fuzzy', \n",
    "#              'replace_common_words_using_fuzzy'],\n",
    "    \n",
    "#          ['remove_whitespaces', 'remove_leaky', 'convert_to_lower', 'remove_stopwords',   'remove_rare_words'],\n",
    "    \n",
    "            \n",
    "#     ['remove_whitespaces', 'strip_non_printable_chars', 'replace_abbreviation_words', 'replace_acronyms', 'remove_leaky',  'extract_info_from_url', \n",
    "#      'convert_to_lower',  'black_listed_words_regex_mapping', 'replace_profane_words_using_fuzzy', \n",
    "#     'replace_common_words_using_fuzzy', 'check_if_proper_name_place_or_ethnicity', 'lemmatize_english_words',\n",
    "#     'stemming_english_words', 'remove_non_alphabet_words', 'remove_stopwords'],\n",
    "            \n",
    "#     ['remove_whitespaces', 'convert_to_lower', 'remove_non_alphabet_words',  'black_listed_words_regex_mapping', \n",
    "#      'replace_common_words_using_fuzzy', 'stemming_english_words']\n",
    "    \n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 30\n",
    "\n",
    "def get_corresponding_mapping(word_dist_dict_most_common, op_type):\n",
    "    print(op_type)\n",
    "    if op_type == 'raw':\n",
    "        new_dict = dict([(x[0], x[0]) for x in word_dist_dict_most_common])\n",
    "    elif op_type ==  'convert_to_lower': # remove white spaces \n",
    "        new_dict = convert_to_lower_from_dict(word_dist_dict_most_common)\n",
    "    elif op_type ==  'remove_whitespaces': # remove white spaces \n",
    "        new_dict = remove_white_spaces_from_dict(word_dist_dict_most_common)\n",
    "    elif op_type == 'remove_leaky':\n",
    "        new_dict = remove_leaky_information_from_dict(word_dist_dict_most_common)\n",
    "    elif op_type == 'extract_info_from_url':\n",
    "        new_dict = extract_info_from_url(word_dist_dict_most_common, extractor)\n",
    "    elif op_type == 'trim_words_len':\n",
    "        new_dict = trim_words_len(word_dist_dict_most_common, maxlen)\n",
    "    elif op_type == 'replace_abbreviation_words':\n",
    "        new_dict = replace_abbreviation_words_from_dict(word_dist_dict_most_common, abbrev_words_dict)\n",
    "    elif op_type == 'strip_non_printable_chars':\n",
    "        new_dict = strip_non_printable_chars_from_dict(word_dist_dict_most_common)\n",
    "    elif op_type == 'replace_acronyms':\n",
    "        new_dict = replace_acronyms_from_dict(word_dist_dict_most_common, acronyms_dict, proper_words_with_profane_dict)\n",
    "    elif op_type == 'remove_stopwords':\n",
    "        new_dict = remove_stopwords_from_dict(word_dist_dict_most_common, stop_words_dict)\n",
    "    elif op_type == 'remove_rare_words':\n",
    "        new_dict = remove_rare_words_from_dict(word_dist_dict_most_common, word_dist_dict, rare_word_thresh)\n",
    "    elif op_type == 'remove_non_alphanumeric':\n",
    "        new_dict = remove_non_alphanumeric_from_dict(word_dist_dict_most_common)    \n",
    "    elif op_type == 'remove_non_alphabet_words':\n",
    "        new_dict = remove_non_alphabet_words(word_dist_dict_most_common)    \n",
    "    elif op_type == 'remove_words_containing_non_alphabets':\n",
    "        new_dict = remove_words_containing_non_alphabets_from_dict(word_dist_dict_most_common)    \n",
    "    elif op_type == 'black_listed_words_regex_mapping':\n",
    "        new_dict = black_listed_words_regex_mapping_from_dict(word_dist_dict_most_common, all_badlist, profane_list_map, extreme_profane)\n",
    "    elif op_type == 'replace_profane_words_using_fuzzy':\n",
    "        new_dict = replace_profane_words_using_fuzzy(word_dist_dict_most_common, proper_words_dict, extreme_profane, profane_list_map, badlist_common)\n",
    "    elif op_type == 'check_if_proper_name_place_or_ethnicity':\n",
    "        new_dict = check_if_proper_name_place_or_ethnicity_from_dict(word_dist_dict_most_common, proper_words_dict, citynames, countries, nationalities, \\\n",
    "                                              ethnicities, person_names_dict)\n",
    "    elif op_type == 'replace_common_words_using_fuzzy':\n",
    "        new_dict = replace_common_words_using_fuzzy(word_dist_dict_most_common, word_dist_dict_most_common, wordnet_lemmatizer, proper_words_dict)\n",
    "    elif op_type == 'lemmatize_english_words':\n",
    "        new_dict = lemmatize_english_words(word_dist_dict_most_common, wordnet_lemmatizer)\n",
    "    elif op_type == 'stemming_english_words':\n",
    "        new_dict = stemming_english_words(word_dist_dict_most_common, stemmer)\n",
    "    else:\n",
    "        print (\"Error......\")\n",
    "        new_dict = 'Error .......'\n",
    "    return new_dict\n",
    "\n",
    "def get_new_distribution(X):\n",
    "    tmp = X.str.cat(sep=' ')\n",
    "    words = tmp.split()\n",
    "    w_d_dict = nltk.FreqDist(words) #Word distribution dict\n",
    "    w_d_most_common = w_d_dict.most_common()\n",
    "    return w_d_most_common\n",
    "\n",
    "# def get_corresponding_mapping_multiple(word_dist_dict_most_common, op_types):\n",
    "#     curr_list = word_dist_dict_most_common.copy()\n",
    "#     new_dict = {}\n",
    "#     for op_type in op_types:\n",
    "#         print (op_type)\n",
    "#         tmp_map = get_corresponding_mapping(curr_list, op_type)\n",
    "#         if not new_dict:\n",
    "#             new_dict = tmp_map\n",
    "#         else: \n",
    "#             new_dict = update_dict_with_next_level_val(new_dict, tmp_map)\n",
    "#         curr_list = [(new_dict[x], 1) for x in new_dict]\n",
    "#     return new_dict\n",
    "\n",
    "def get_corresponding_mapping_multiple(word_dist_dict_most_common, op_types, train_data):\n",
    "    curr_word_dist_dict_most_common = word_dist_dict_most_common.copy()\n",
    "    comment_data = train_data['comment_text']\n",
    "    for op_type in op_types:\n",
    "        print (op_type)\n",
    "        new_mapped_dict = get_corresponding_mapping(curr_word_dist_dict_most_common, op_type)\n",
    "        comment_data = comment_data.apply(replace_words_from_a_mapping_no_check, args = [new_mapped_dict, 0])\n",
    "        curr_word_dist_dict_most_common = get_new_distribution(comment_data)\n",
    "    return comment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words_dict = dict(zip(stop_words, [1] * len(stop_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling NB SVM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove_whitespaces\n",
      "remove_whitespaces\n",
      "remove_leaky\n",
      "remove_leaky\n",
      "replace_abbreviation_words\n",
      "replace_abbreviation_words\n",
      "replace_acronyms\n",
      "replace_acronyms\n",
      "remove_stopwords\n",
      "remove_stopwords\n",
      "remove_rare_words\n",
      "remove_rare_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  1  ......\n",
      "F1-score:  0.769711705453\n",
      "Log Loss:  1.43497475186\n",
      "Accuracy:  0.958453440281\n",
      "AUC score:  0.966798727999\n",
      "Num of comments missclassified:  663\n",
      "[[14187   148]\n",
      " [  515  1108]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96497   0.98968   0.97717     14335\n",
      "          1    0.88217   0.68269   0.76971      1623\n",
      "\n",
      "avg / total    0.95655   0.95845   0.95607     15958\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Add the preprocessing step here \n",
    "import pickle\n",
    "combined_results = {} #Uncomment \n",
    "for pp_step in pp_steps:\n",
    "    if len(pp_step) == 1:\n",
    "        new_mapped_dict = get_corresponding_mapping(word_dist_dict_most_common, pp_step[0])\n",
    "        X = train_data['comment_text'].apply(replace_words_from_a_mapping_no_check, args = [new_mapped_dict, 0])\n",
    "    else:\n",
    "        X = get_corresponding_mapping_multiple(word_dist_dict_most_common, pp_step, train_data)\n",
    "    vocab = set(' '.join(X.values).split())\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,4), min_df=1, vocabulary= vocab)\n",
    "    results = []\n",
    "    k_fold_num = 0\n",
    "    cv = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42)\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        print (\"\\n\\n *****Processing fold \", k_fold_num, \" of \", cv.n_splits, \" ......\")\n",
    "        X_train_data, X_test_data = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        X_train = vectorizer.fit_transform(X_train_data)\n",
    "        X_test = vectorizer.transform(X_test_data)\n",
    "        res = call_NB_SVM_algorithm(X_train, y_train, X_test, y_test)\n",
    "        results.append(res)\n",
    "        k_fold_num += 1\n",
    "#         if k_fold_num ==2:\n",
    "#             break\n",
    "    scores = extract_combined_results(results)\n",
    "    combined_results[' '.join(pp_step)] = scores\n",
    "    pickle.dump(combined_results, open(\"../data/results_nbsvm.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove_whitespaces\n",
      "remove_whitespaces\n",
      "remove_leaky\n",
      "remove_leaky\n",
      "replace_abbreviation_words\n",
      "replace_abbreviation_words\n",
      "replace_acronyms\n",
      "replace_acronyms\n",
      "remove_stopwords\n",
      "remove_stopwords\n",
      "remove_rare_words\n",
      "remove_rare_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  1  ......\n",
      "F1-score:  0.709507703871\n",
      "Log Loss:  1.67305109133\n",
      "Accuracy:  0.951560345908\n",
      "AUC score:  0.966128771941\n",
      "Num of comments missclassified:  773\n",
      "[[14241    94]\n",
      " [  679   944]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95449   0.99344   0.97358     14335\n",
      "          1    0.90944   0.58164   0.70951      1623\n",
      "\n",
      "avg / total    0.94991   0.95156   0.94672     15958\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Add the preprocessing step here \n",
    "combined_results = {} #Uncomment \n",
    "for pp_step in pp_steps:\n",
    "    if len(pp_step) == 1:\n",
    "        new_mapped_dict = get_corresponding_mapping(word_dist_dict_most_common, pp_step[0])\n",
    "        X = train_data['comment_text'].apply(replace_words_from_a_mapping_no_check, args = [new_mapped_dict, 0])\n",
    "    else:\n",
    "        X = get_corresponding_mapping_multiple(word_dist_dict_most_common, pp_step, train_data)\n",
    "    vocab = set(' '.join(X.values).split())\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,4), min_df=1, vocabulary= vocab)\n",
    "    results = []\n",
    "    k_fold_num = 0\n",
    "    cv = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42)\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        print (\"\\n\\n *****Processing fold \", k_fold_num, \" of \", cv.n_splits, \" ......\")\n",
    "        X_train_data, X_test_data = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        X_train = vectorizer.fit_transform(X_train_data)\n",
    "        X_test = vectorizer.transform(X_test_data)\n",
    "        res = call_logreg_algorithm(X_train, y_train, X_test, y_test)\n",
    "        results.append(res)\n",
    "        k_fold_num += 1\n",
    "\n",
    "#         if k_fold_num ==1:\n",
    "#             break\n",
    "    scores = extract_combined_results(results)\n",
    "    combined_results[' '.join(pp_step)] = scores\n",
    "    pickle.dump(combined_results, open(\"../data/results_logit.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call XGBoost Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove_whitespaces\n",
      "remove_whitespaces\n",
      "remove_leaky\n",
      "remove_leaky\n",
      "replace_abbreviation_words\n",
      "replace_abbreviation_words\n",
      "replace_acronyms\n",
      "replace_acronyms\n",
      "remove_stopwords\n",
      "remove_stopwords\n",
      "remove_rare_words\n",
      "remove_rare_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-765c52c1fa25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_xgboost_algorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mk_fold_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/kaggle/toxic/toxic_text/code/model_helper_functions.py\u001b[0m in \u001b[0;36mcall_xgboost_algorithm\u001b[0;34m(xgb, vectorizer, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'colsample_bytree'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_round\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0md_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mp_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/xgboost-0.7-py3.6.egg/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/xgboost-0.7-py3.6.egg/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/xgboost-0.7-py3.6.egg/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m--> 898\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m    899\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Add the preprocessing step here \n",
    "combined_results = {} #Uncomment \n",
    "for pp_step in pp_steps:\n",
    "    if len(pp_step) == 1:\n",
    "        new_mapped_dict = get_corresponding_mapping(word_dist_dict_most_common, pp_step[0])\n",
    "        X = train_data['comment_text'].apply(replace_words_from_a_mapping_no_check, args = [new_mapped_dict, 0])\n",
    "    else:\n",
    "        X = get_corresponding_mapping_multiple(word_dist_dict_most_common, pp_step, train_data)\n",
    "    vocab = set(' '.join(X.values).split())\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,4), min_df=1, vocabulary= vocab)\n",
    "    results = []\n",
    "    k_fold_num = 0\n",
    "    cv = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=42)\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        print (\"\\n\\n *****Processing fold \", k_fold_num, \" of \", cv.n_splits, \" ......\")\n",
    "        X_train_data, X_test_data = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        X_train = vectorizer.fit_transform(X_train_data)\n",
    "        X_test = vectorizer.transform(X_test_data)\n",
    "        res = call_xgboost_algorithm(xgb, vectorizer, X_train, y_train, X_test, y_test)\n",
    "        results.append(res)\n",
    "        k_fold_num += 1\n",
    "\n",
    "#         if k_fold_num ==1:\n",
    "#             break\n",
    "    scores = extract_combined_results(results)\n",
    "    combined_results[' '.join(pp_step)] = scores\n",
    "    pickle.dump(combined_results, open(\"../data/results_xgboost_1.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fasttext Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  2  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 185s 1ms/step - loss: 0.1288 - acc: 0.9525\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 193s 1ms/step - loss: 0.1067 - acc: 0.9597\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 189s 1ms/step - loss: 0.1013 - acc: 0.9614\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  2  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 182s 1ms/step - loss: 0.1272 - acc: 0.9527\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 183s 1ms/step - loss: 0.1056 - acc: 0.9601\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 191s 1ms/step - loss: 0.1003 - acc: 0.9620\n",
      "F1-score:  0.7984254551418731\n",
      "Log Loss:  1.3300065679118198\n",
      "Accuracy:  0.9614926682541672\n",
      "AUC score:  0.9785360254503356\n",
      "Num of comments missclassified:  1229\n",
      "[[28253   417]\n",
      " [  812  2434]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.97206   0.98546   0.97871     28670\n",
      "          1    0.85374   0.74985   0.79843      3246\n",
      "\n",
      "avg / total    0.96003   0.96149   0.96038     31916\n",
      "\n",
      "convert_to_lower\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  2  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 175s 1ms/step - loss: 0.1259 - acc: 0.9534\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1025 - acc: 0.9615\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 174s 1ms/step - loss: 0.0976 - acc: 0.9633\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  2  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 173s 1ms/step - loss: 0.1243 - acc: 0.9547\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1037 - acc: 0.9613\n",
      "Epoch 3/3\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0980 - acc: 0.9629"
     ]
    }
   ],
   "source": [
    "combined_results = {}\n",
    "for pp_step in pp_steps:\n",
    "    if len(pp_step) == 1:\n",
    "        new_mapped_dict = get_corresponding_mapping(word_dist_dict_most_common, pp_step[0])\n",
    "        X = train_data['comment_text'].apply(replace_words_from_a_mapping_no_check, args = [new_mapped_dict, 0])\n",
    "    else:\n",
    "        X = get_corresponding_mapping_multiple(word_dist_dict_most_common, pp_step, train_data)\n",
    "    results = []\n",
    "    k_fold_num = 0\n",
    "    cv = StratifiedShuffleSplit(n_splits=2, test_size=0.1, random_state=42)\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        print (\"\\n\\n *****Processing fold \", k_fold_num, \" of \", cv.n_splits, \" ......\")\n",
    "        X_train_data, X_test_data = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        texts_train = X_train_data.values\n",
    "        texts_test  = X_test_data.values\n",
    "        train = X.copy()\n",
    "        X_train, X_test, embedding_matrix = preprocess_data_for_fasttext(texts_train, texts_test, train)\n",
    "        res = call_fasttext_algorithm(X_train, y_train, X_test, y_test, embedding_matrix)\n",
    "        results.append(res)\n",
    "        k_fold_num += 1\n",
    "\n",
    "#         if k_fold_num ==1:\n",
    "#             break\n",
    "    scores = extract_combined_results(results)\n",
    "    combined_results[' '.join(pp_step)] = scores\n",
    "    pickle.dump(combined_results, open(\"../data/individual_fasttext.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# <font color = 'red' > Greedy to select the best transformation sequence  </color>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add the preprocessing step here\n",
    "def call_logit_to_recursive_transformation_Addition(pp_steps, word_dist_dict_most_common,train_data):\n",
    "    combined_results = {} #Uncomment \n",
    "    for pp_step in pp_steps:\n",
    "        if len(pp_step) == 1:\n",
    "            new_mapped_dict = get_corresponding_mapping(word_dist_dict_most_common, pp_step[0])\n",
    "        else:\n",
    "            new_mapped_dict = get_corresponding_mapping_multiple(word_dist_dict_most_common, pp_step)\n",
    "        X = train_data['comment_text'].apply(replace_words_from_a_mapping_no_check, args = [new_mapped_dict, 0])\n",
    "        vocab = set(' '.join(X.values).split())\n",
    "        vectorizer = TfidfVectorizer(ngram_range=(1,4), min_df=1, vocabulary= vocab)\n",
    "        results = []\n",
    "        k_fold_num = 0\n",
    "        cv = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=42)\n",
    "        for train_index, test_index in cv.split(X, y):\n",
    "            print (\"\\n\\n *****Processing fold \", k_fold_num, \" of \", cv.n_splits, \" ......\")\n",
    "            X_train_data, X_test_data = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            X_train = vectorizer.fit_transform(X_train_data)\n",
    "            X_test = vectorizer.transform(X_test_data)\n",
    "#             res = call_NB_SVM_algorithm(X_train, y_train, X_test, y_test)\n",
    "            res = call_logreg_algorithm(X_train, y_train, X_test, y_test)\n",
    "            results.append(res)\n",
    "            k_fold_num += 1\n",
    "\n",
    "#             if k_fold_num ==1:\n",
    "#                 break\n",
    "        scores = extract_combined_results(results)\n",
    "        combined_results[' '.join(pp_step)] = scores\n",
    "        import pickle\n",
    "        pickle.dump(combined_results, open(\"../data/results_logit.pkl\", \"wb\"))\n",
    "    return combined_results, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add the preprocessing step here \n",
    "#Add the preprocessing step here\n",
    "def call_xgboost_to_recursive_transformation_Addition(pp_steps, word_dist_dict_most_common,train_data):\n",
    "    combined_results = {} #Uncomment \n",
    "    for pp_step in pp_steps:\n",
    "        if len(pp_step) == 1:\n",
    "            new_mapped_dict = get_corresponding_mapping(word_dist_dict_most_common, pp_step[0])\n",
    "        else:\n",
    "            new_mapped_dict = get_corresponding_mapping_multiple(word_dist_dict_most_common, pp_step)\n",
    "        X = train_data['comment_text'].apply(replace_words_from_a_mapping_no_check, args = [new_mapped_dict, 0])\n",
    "        vocab = set(' '.join(X.values).split())\n",
    "        vectorizer = TfidfVectorizer(ngram_range=(1,4), min_df=1, vocabulary= vocab)\n",
    "        results = []\n",
    "        k_fold_num = 0\n",
    "        cv = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=42)\n",
    "        for train_index, test_index in cv.split(X, y):\n",
    "            print (\"\\n\\n *****Processing fold \", k_fold_num, \" of \", cv.n_splits, \" ......\")\n",
    "            #print (len(train_index), len(test_index))\n",
    "            #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "            X_train_data, X_test_data = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            X_train = vectorizer.fit_transform(X_train_data)\n",
    "            X_test = vectorizer.transform(X_test_data)\n",
    "            res = call_xgboost_algorithm(xgb, vectorizer, X_train, y_train, X_test, y_test)\n",
    "            results.append(res)\n",
    "            k_fold_num += 1\n",
    "\n",
    "    #         if k_fold_num ==1:\n",
    "    #             break\n",
    "        scores = extract_combined_results(results)\n",
    "        combined_results[' '.join(pp_step)] = scores\n",
    "        import pickle\n",
    "        pickle.dump(combined_results, open(\"../data/results_xgboost_1.pkl\", \"wb\"))\n",
    "    return combined_results, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformations = [ ['raw'],  \n",
    "                    ['convert_to_lower'],\n",
    "                    ['remove_whitespaces'], \n",
    "                    ['remove_leaky'], \n",
    "                    ['replace_abbreviation_words'],\n",
    "                    ['strip_non_printable_chars'],\n",
    "                    ['replace_acronyms'],\n",
    "                    ['remove_stopwords'],\n",
    "                    ['remove_rare_words'],\n",
    "                    ['remove_non_alphanumeric'],\n",
    "                    ['remove_non_alphabet_words'],\n",
    "                    ['remove_words_containing_non_alphabets'],\n",
    "                    ['black_listed_words_regex_mapping'],\n",
    "                    ['check_if_proper_name_place_or_ethnicity'],\n",
    "                    ['replace_profane_words_using_fuzzy'],\n",
    "                    ['replace_common_words_using_fuzzy'],\n",
    "                    ['lemmatize_english_words'],\n",
    "                    ['stemming_english_words'],\n",
    "                    ['extract_info_from_url']\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7406912920931613\n",
      "Log Loss:  1.513320733501024\n",
      "Accuracy:  0.9561849855871664\n",
      "AUC score:  0.9719737794320009\n",
      "Num of comments missclassified:  6992\n",
      "[[142602    748]\n",
      " [  6244   9986]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95805   0.99478   0.97607    143350\n",
      "          1    0.93031   0.61528   0.74069     16230\n",
      "\n",
      "avg / total    0.95523   0.95618   0.95213    159580\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pp_steps = [transformations[0]]\n",
    "base_res, X = call_logit_to_recursive_transformation_Addition(pp_steps, word_dist_dict_most_common,train_data)\n",
    "#Get the f1_score\n",
    "tr_scores = []\n",
    "tr_scores.append((transformations[0][0], base_res[transformations[0][0]][0]))\n",
    "max_f1 = base_res[transformations[0][0]][0]\n",
    "#remove the raw transformation\n",
    "transformations.remove(pp_steps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_copy = train_data.copy()\n",
    "word_dist_dict_most_common_copy = word_dist_dict_most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_words_dict_most_common(df):\n",
    "    # Get the Word Frequency table\n",
    "    tmp = df['comment_text'].str.cat(sep=' ')\n",
    "    words = tmp.split()\n",
    "    word_dist_dict = nltk.FreqDist(words)\n",
    "    word_dist_dict_most_common = word_dist_dict.most_common()\n",
    "    return word_dist_dict_most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert_to_lower\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7351802204349122\n",
      "Log Loss:  1.5392930230421562\n",
      "Accuracy:  0.9554330116555959\n",
      "AUC score:  0.9714555142429597\n",
      "Num of comments missclassified:  7112\n",
      "[[142596    754]\n",
      " [  6358   9872]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95732   0.99474   0.97567    143350\n",
      "          1    0.92904   0.60826   0.73518     16230\n",
      "\n",
      "avg / total    0.95444   0.95543   0.95121    159580\n",
      "\n",
      "remove_whitespaces\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7406912920931613\n",
      "Log Loss:  1.513320733501024\n",
      "Accuracy:  0.9561849855871664\n",
      "AUC score:  0.9719737794320009\n",
      "Num of comments missclassified:  6992\n",
      "[[142602    748]\n",
      " [  6244   9986]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95805   0.99478   0.97607    143350\n",
      "          1    0.93031   0.61528   0.74069     16230\n",
      "\n",
      "avg / total    0.95523   0.95618   0.95213    159580\n",
      "\n",
      "remove_leaky\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7404716001779623\n",
      "Log Loss:  1.5150522575512726\n",
      "Accuracy:  0.9561348539917283\n",
      "AUC score:  0.9721293083532178\n",
      "Num of comments missclassified:  7000\n",
      "[[142594    756]\n",
      " [  6244   9986]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95805   0.99473   0.97604    143350\n",
      "          1    0.92962   0.61528   0.74047     16230\n",
      "\n",
      "avg / total    0.95516   0.95613   0.95208    159580\n",
      "\n",
      "replace_abbreviation_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7403232982352069\n",
      "Log Loss:  1.5159180095551237\n",
      "Accuracy:  0.9561097881940093\n",
      "AUC score:  0.97205030838309\n",
      "Num of comments missclassified:  7004\n",
      "[[142592    758]\n",
      " [  6246   9984]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95803   0.99471   0.97603    143350\n",
      "          1    0.92944   0.61516   0.74032     16230\n",
      "\n",
      "avg / total    0.95513   0.95611   0.95206    159580\n",
      "\n",
      "strip_non_printable_chars\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7401609851997478\n",
      "Log Loss:  1.516134414986947\n",
      "Accuracy:  0.9561035217445796\n",
      "AUC score:  0.9718774066807776\n",
      "Num of comments missclassified:  7005\n",
      "[[142598    752]\n",
      " [  6253   9977]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95799   0.99475   0.97603    143350\n",
      "          1    0.92991   0.61473   0.74016     16230\n",
      "\n",
      "avg / total    0.95514   0.95610   0.95204    159580\n",
      "\n",
      "replace_acronyms\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.6868893433310611\n",
      "Log Loss:  1.7894942247617298\n",
      "Accuracy:  0.9481889961148013\n",
      "AUC score:  0.9469503849120412\n",
      "Num of comments missclassified:  8268\n",
      "[[142243   1107]\n",
      " [  7161   9069]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95207   0.99228   0.97176    143350\n",
      "          1    0.89121   0.55878   0.68689     16230\n",
      "\n",
      "avg / total    0.94588   0.94819   0.94279    159580\n",
      "\n",
      "remove_stopwords\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.730194488248104\n",
      "Log Loss:  1.5553088789327032\n",
      "Accuracy:  0.9549692943977942\n",
      "AUC score:  0.9706087262346015\n",
      "Num of comments missclassified:  7186\n",
      "[[142670    680]\n",
      " [  6506   9724]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95639   0.99526   0.97543    143350\n",
      "          1    0.93464   0.59914   0.73019     16230\n",
      "\n",
      "avg / total    0.95418   0.95497   0.95049    159580\n",
      "\n",
      "remove_rare_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7296501881309838\n",
      "Log Loss:  1.5706765006126062\n",
      "Accuracy:  0.9545243764882817\n",
      "AUC score:  0.9681189134393305\n",
      "Num of comments missclassified:  7257\n",
      "[[142530    820]\n",
      " [  6437   9793]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95679   0.99428   0.97517    143350\n",
      "          1    0.92274   0.60339   0.72965     16230\n",
      "\n",
      "avg / total    0.95333   0.95452   0.95020    159580\n",
      "\n",
      "remove_non_alphanumeric\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7306670657338472\n",
      "Log Loss:  1.558122810950469\n",
      "Accuracy:  0.9548878305552074\n",
      "AUC score:  0.9705158304895554\n",
      "Num of comments missclassified:  7199\n",
      "[[142616    734]\n",
      " [  6465   9765]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95663   0.99488   0.97538    143350\n",
      "          1    0.93009   0.60166   0.73067     16230\n",
      "\n",
      "avg / total    0.95393   0.95489   0.95049    159580\n",
      "\n",
      "remove_non_alphabet_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7337432457611328\n",
      "Log Loss:  1.5464354244622378\n",
      "Accuracy:  0.955226218824414\n",
      "AUC score:  0.9708618178559386\n",
      "Num of comments missclassified:  7145\n",
      "[[142590    760]\n",
      " [  6385   9845]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95714   0.99470   0.97556    143350\n",
      "          1    0.92834   0.60659   0.73374     16230\n",
      "\n",
      "avg / total    0.95421   0.95523   0.95096    159580\n",
      "\n",
      "remove_words_containing_non_alphabets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.6577154936193533\n",
      "Log Loss:  1.8925165586461195\n",
      "Accuracy:  0.9452061661862389\n",
      "AUC score:  0.9462181083702385\n",
      "Num of comments missclassified:  8744\n",
      "[[142435    915]\n",
      " [  7829   8401]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.94790   0.99362   0.97022    143350\n",
      "          1    0.90178   0.51762   0.65772     16230\n",
      "\n",
      "avg / total    0.94321   0.94521   0.93844    159580\n",
      "\n",
      "black_listed_words_regex_mapping\n",
      "Done  100000\n",
      "Done  200000\n",
      "Done  300000\n",
      "Done  400000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7499725325032045\n",
      "Log Loss:  1.477609317655765\n",
      "Accuracy:  0.9572189497430755\n",
      "AUC score:  0.9738760890761744\n",
      "Num of comments missclassified:  6827\n",
      "[[142514    836]\n",
      " [  5991  10239]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95966   0.99417   0.97661    143350\n",
      "          1    0.92451   0.63087   0.74997     16230\n",
      "\n",
      "avg / total    0.95608   0.95722   0.95356    159580\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " =========  black_listed_words_regex_mapping\n",
      "check_if_proper_name_place_or_ethnicity\n",
      "Done  100000\n",
      "Done  200000\n",
      "Done  300000\n",
      "Done  400000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7382958975310933\n",
      "Log Loss:  1.5256576269016626\n",
      "Accuracy:  0.9558277979696704\n",
      "AUC score:  0.9719120733715141\n",
      "Num of comments missclassified:  7049\n",
      "[[142588    762]\n",
      " [  6287   9943]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95777   0.99468   0.97588    143350\n",
      "          1    0.92882   0.61263   0.73830     16230\n",
      "\n",
      "avg / total    0.95483   0.95583   0.95171    159580\n",
      "\n",
      "replace_profane_words_using_fuzzy\n",
      "Done  100000\n",
      "Done  200000\n",
      "Done  300000\n",
      "Done  400000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7458547322083638\n",
      "Log Loss:  1.499469443013667\n",
      "Accuracy:  0.9565860383506705\n",
      "AUC score:  0.9728894972234883\n",
      "Num of comments missclassified:  6928\n",
      "[[142486    864]\n",
      " [  6064  10166]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95918   0.99397   0.97627    143350\n",
      "          1    0.92167   0.62637   0.74585     16230\n",
      "\n",
      "avg / total    0.95536   0.95659   0.95283    159580\n",
      "\n",
      "replace_common_words_using_fuzzy\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7432292437472251\n",
      "Log Loss:  1.5020661177913435\n",
      "Accuracy:  0.9565108409575135\n",
      "AUC score:  0.9730506864073107\n",
      "Num of comments missclassified:  6940\n",
      "[[142596    754]\n",
      " [  6186  10044]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95842   0.99474   0.97624    143350\n",
      "          1    0.93017   0.61885   0.74323     16230\n",
      "\n",
      "avg / total    0.95555   0.95651   0.95255    159580\n",
      "\n",
      "lemmatize_english_words\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7384808815915983\n",
      "Log Loss:  1.5306359689928766\n",
      "Accuracy:  0.9556836696327861\n",
      "AUC score:  0.970596424221832\n",
      "Num of comments missclassified:  7072\n",
      "[[142523    827]\n",
      " [  6245   9985]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95802   0.99423   0.97579    143350\n",
      "          1    0.92351   0.61522   0.73848     16230\n",
      "\n",
      "avg / total    0.95451   0.95568   0.95166    159580\n",
      "\n",
      "stemming_english_words\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7441056387243904\n",
      "Log Loss:  1.5057459621533398\n",
      "Accuracy:  0.9564043113172077\n",
      "AUC score:  0.9726305951184371\n",
      "Num of comments missclassified:  6957\n",
      "[[142508    842]\n",
      " [  6115  10115]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95886   0.99413   0.97617    143350\n",
      "          1    0.92315   0.62323   0.74411     16230\n",
      "\n",
      "avg / total    0.95522   0.95640   0.95257    159580\n",
      "\n",
      "extract_info_from_url\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7390303660256886\n",
      "Log Loss:  1.5215453123993268\n",
      "Accuracy:  0.9559468605088357\n",
      "AUC score:  0.9719310109020983\n",
      "Num of comments missclassified:  7030\n",
      "[[142596    754]\n",
      " [  6276   9954]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95784   0.99474   0.97594    143350\n",
      "          1    0.92959   0.61331   0.73903     16230\n",
      "\n",
      "avg / total    0.95497   0.95595   0.95185    159580\n",
      "\n",
      "[('black_listed_words_regex_mapping', 0.7499725325032045), ('replace_profane_words_using_fuzzy', 0.7458547322083638), ('stemming_english_words', 0.7441056387243904), ('replace_common_words_using_fuzzy', 0.7432292437472251), ('remove_whitespaces', 0.7406912920931613), ('remove_leaky', 0.7404716001779623), ('replace_abbreviation_words', 0.7403232982352069), ('strip_non_printable_chars', 0.7401609851997478), ('extract_info_from_url', 0.7390303660256886), ('lemmatize_english_words', 0.7384808815915983), ('check_if_proper_name_place_or_ethnicity', 0.7382958975310933), ('convert_to_lower', 0.7351802204349122), ('remove_non_alphabet_words', 0.7337432457611328), ('remove_non_alphanumeric', 0.7306670657338472), ('remove_stopwords', 0.730194488248104), ('remove_rare_words', 0.7296501881309838), ('replace_acronyms', 0.6868893433310611), ('remove_words_containing_non_alphabets', 0.6577154936193533)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['convert_to_lower'], ['remove_whitespaces'], ['remove_leaky'], ['replace_abbreviation_words'], ['strip_non_printable_chars'], ['replace_acronyms'], ['remove_stopwords'], ['remove_rare_words'], ['remove_non_alphanumeric'], ['remove_non_alphabet_words'], ['remove_words_containing_non_alphabets'], ['check_if_proper_name_place_or_ethnicity'], ['replace_profane_words_using_fuzzy'], ['replace_common_words_using_fuzzy'], ['lemmatize_english_words'], ['stemming_english_words'], ['extract_info_from_url']]\n",
      "*******************\n",
      "[('raw', 0.7406912920931613), ('black_listed_words_regex_mapping', 0.7499725325032045)]\n",
      "convert_to_lower\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7482368498383779\n",
      "Log Loss:  1.483452940750965\n",
      "Accuracy:  0.9570497556084723\n",
      "AUC score:  0.9734784305912931\n",
      "Num of comments missclassified:  6854\n",
      "[[142541    809]\n",
      " [  6045  10185]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95932   0.99436   0.97652    143350\n",
      "          1    0.92641   0.62754   0.74824     16230\n",
      "\n",
      "avg / total    0.95597   0.95705   0.95330    159580\n",
      "\n",
      "remove_whitespaces\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7499725325032045\n",
      "Log Loss:  1.477609317655765\n",
      "Accuracy:  0.9572189497430755\n",
      "AUC score:  0.9738760890761744\n",
      "Num of comments missclassified:  6827\n",
      "[[142514    836]\n",
      " [  5991  10239]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95966   0.99417   0.97661    143350\n",
      "          1    0.92451   0.63087   0.74997     16230\n",
      "\n",
      "avg / total    0.95608   0.95722   0.95356    159580\n",
      "\n",
      "remove_leaky\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7504940349849961\n",
      "Log Loss:  1.4756614282587879\n",
      "Accuracy:  0.9572753477879433\n",
      "AUC score:  0.9739957020429855\n",
      "Num of comments missclassified:  6818\n",
      "[[142508    842]\n",
      " [  5976  10254]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95975   0.99413   0.97664    143350\n",
      "          1    0.92412   0.63179   0.75049     16230\n",
      "\n",
      "avg / total    0.95613   0.95728   0.95364    159580\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " =========  remove_leaky\n",
      "replace_abbreviation_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7504485700684757\n",
      "Log Loss:  1.4750120716654864\n",
      "Accuracy:  0.9572941471362326\n",
      "AUC score:  0.9739245204475858\n",
      "Num of comments missclassified:  6815\n",
      "[[142518    832]\n",
      " [  5983  10247]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95971   0.99420   0.97665    143350\n",
      "          1    0.92490   0.63136   0.75045     16230\n",
      "\n",
      "avg / total    0.95617   0.95729   0.95364    159580\n",
      "\n",
      "strip_non_printable_chars\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7495696128346947\n",
      "Log Loss:  1.4797736876441183\n",
      "Accuracy:  0.957156285248778\n",
      "AUC score:  0.9737789323383925\n",
      "Num of comments missclassified:  6837\n",
      "[[142511    839]\n",
      " [  5998  10232]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95961   0.99415   0.97657    143350\n",
      "          1    0.92422   0.63044   0.74957     16230\n",
      "\n",
      "avg / total    0.95601   0.95716   0.95349    159580\n",
      "\n",
      "replace_acronyms\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7394124936219841\n",
      "Log Loss:  1.5475191251740645\n",
      "Accuracy:  0.9551948865772654\n",
      "AUC score:  0.9633283680851278\n",
      "Num of comments missclassified:  7150\n",
      "[[142286   1064]\n",
      " [  6086  10144]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95898   0.99258   0.97549    143350\n",
      "          1    0.90507   0.62502   0.73941     16230\n",
      "\n",
      "avg / total    0.95350   0.95519   0.95148    159580\n",
      "\n",
      "remove_stopwords\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7406476415791808\n",
      "Log Loss:  1.5185154659921503\n",
      "Accuracy:  0.9560345908008523\n",
      "AUC score:  0.9722225159306369\n",
      "Num of comments missclassified:  7016\n",
      "[[142546    804]\n",
      " [  6212  10018]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95824   0.99439   0.97598    143350\n",
      "          1    0.92571   0.61725   0.74065     16230\n",
      "\n",
      "avg / total    0.95493   0.95603   0.95205    159580\n",
      "\n",
      "remove_rare_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7492875411033979\n",
      "Log Loss:  1.4851848105351573\n",
      "Accuracy:  0.9569996240130342\n",
      "AUC score:  0.972405761828408\n",
      "Num of comments missclassified:  6862\n",
      "[[142464    886]\n",
      " [  5976  10254]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95974   0.99382   0.97648    143350\n",
      "          1    0.92047   0.63179   0.74929     16230\n",
      "\n",
      "avg / total    0.95575   0.95700   0.95338    159580\n",
      "\n",
      "remove_non_alphanumeric\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7443384762676288\n",
      "Log Loss:  1.5027157549803094\n",
      "Accuracy:  0.9564920416092242\n",
      "AUC score:  0.9726558939434674\n",
      "Num of comments missclassified:  6943\n",
      "[[142530    820]\n",
      " [  6123  10107]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95881   0.99428   0.97622    143350\n",
      "          1    0.92496   0.62274   0.74434     16230\n",
      "\n",
      "avg / total    0.95537   0.95649   0.95264    159580\n",
      "\n",
      "remove_non_alphabet_words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.745866098331741\n",
      "Log Loss:  1.4968720717574673\n",
      "Accuracy:  0.9566612357438276\n",
      "AUC score:  0.9728205487433111\n",
      "Num of comments missclassified:  6916\n",
      "[[142515    835]\n",
      " [  6081  10149]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95908   0.99418   0.97631    143350\n",
      "          1    0.92398   0.62532   0.74587     16230\n",
      "\n",
      "avg / total    0.95551   0.95666   0.95287    159580\n",
      "\n",
      "remove_words_containing_non_alphabets\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.6803680981595093\n",
      "Log Loss:  1.804211192093385\n",
      "Accuracy:  0.9477628775535781\n",
      "AUC score:  0.9516060873719494\n",
      "Num of comments missclassified:  8336\n",
      "[[142372    978]\n",
      " [  7358   8872]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95086   0.99318   0.97156    143350\n",
      "          1    0.90071   0.54664   0.68037     16230\n",
      "\n",
      "avg / total    0.94576   0.94776   0.94194    159580\n",
      "\n",
      "check_if_proper_name_place_or_ethnicity\n",
      "Done  100000\n",
      "Done  200000\n",
      "Done  300000\n",
      "Done  400000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.749019751548243\n",
      "Log Loss:  1.4823709135918492\n",
      "Accuracy:  0.957081087855621\n",
      "AUC score:  0.9738013503136913\n",
      "Num of comments missclassified:  6849\n",
      "[[142511    839]\n",
      " [  6010  10220]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95953   0.99415   0.97653    143350\n",
      "          1    0.92413   0.62970   0.74902     16230\n",
      "\n",
      "avg / total    0.95593   0.95708   0.95339    159580\n",
      "\n",
      "replace_profane_words_using_fuzzy\n",
      "Done  100000\n",
      "Done  200000\n",
      "Done  300000\n",
      "Done  400000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7492883731114517\n",
      "Log Loss:  1.4869163947130484\n",
      "Accuracy:  0.9569494924175962\n",
      "AUC score:  0.9738197969930419\n",
      "Num of comments missclassified:  6870\n",
      "[[142444    906]\n",
      " [  5964  10266]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95981   0.99368   0.97645    143350\n",
      "          1    0.91890   0.63253   0.74929     16230\n",
      "\n",
      "avg / total    0.95565   0.95695   0.95335    159580\n",
      "\n",
      "replace_common_words_using_fuzzy\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7502287952557015\n",
      "Log Loss:  1.476743595715735\n",
      "Accuracy:  0.9572440155407946\n",
      "AUC score:  0.974385616726422\n",
      "Num of comments missclassified:  6823\n",
      "[[142510    840]\n",
      " [  5983  10247]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95971   0.99414   0.97662    143350\n",
      "          1    0.92424   0.63136   0.75023     16230\n",
      "\n",
      "avg / total    0.95610   0.95724   0.95360    159580\n",
      "\n",
      "lemmatize_english_words\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7471050228310503\n",
      "Log Loss:  1.4983875411204732\n",
      "Accuracy:  0.9566173705978193\n",
      "AUC score:  0.9725375248676109\n",
      "Num of comments missclassified:  6923\n",
      "[[142431    919]\n",
      " [  6004  10226]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95955   0.99359   0.97627    143350\n",
      "          1    0.91754   0.63007   0.74711     16230\n",
      "\n",
      "avg / total    0.95528   0.95662   0.95297    159580\n",
      "\n",
      "stemming_english_words\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7514657150140199\n",
      "Log Loss:  1.4771768324835148\n",
      "Accuracy:  0.957231482641935\n",
      "AUC score:  0.9738381216043099\n",
      "Num of comments missclassified:  6825\n",
      "[[142437    913]\n",
      " [  5912  10318]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96015   0.99363   0.97660    143350\n",
      "          1    0.91871   0.63574   0.75147     16230\n",
      "\n",
      "avg / total    0.95593   0.95723   0.95371    159580\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " =========  stemming_english_words\n",
      "extract_info_from_url\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7494594891714611\n",
      "Log Loss:  1.479773657580297\n",
      "Accuracy:  0.957156285248778\n",
      "AUC score:  0.9738537304156483\n",
      "Num of comments missclassified:  6837\n",
      "[[142517    833]\n",
      " [  6004  10226]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95957   0.99419   0.97658    143350\n",
      "          1    0.92468   0.63007   0.74946     16230\n",
      "\n",
      "avg / total    0.95603   0.95716   0.95348    159580\n",
      "\n",
      "[('stemming_english_words', 0.7514657150140199), ('remove_leaky', 0.7504940349849961), ('replace_abbreviation_words', 0.7504485700684757), ('replace_common_words_using_fuzzy', 0.7502287952557015), ('remove_whitespaces', 0.7499725325032045), ('strip_non_printable_chars', 0.7495696128346947), ('extract_info_from_url', 0.7494594891714611), ('replace_profane_words_using_fuzzy', 0.7492883731114517), ('remove_rare_words', 0.7492875411033979), ('check_if_proper_name_place_or_ethnicity', 0.749019751548243), ('convert_to_lower', 0.7482368498383779), ('lemmatize_english_words', 0.7471050228310503), ('remove_non_alphabet_words', 0.745866098331741), ('remove_non_alphanumeric', 0.7443384762676288), ('remove_stopwords', 0.7406476415791808), ('replace_acronyms', 0.7394124936219841), ('remove_words_containing_non_alphabets', 0.6803680981595093)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['convert_to_lower'], ['remove_whitespaces'], ['remove_leaky'], ['replace_abbreviation_words'], ['strip_non_printable_chars'], ['replace_acronyms'], ['remove_stopwords'], ['remove_rare_words'], ['remove_non_alphanumeric'], ['remove_non_alphabet_words'], ['remove_words_containing_non_alphabets'], ['check_if_proper_name_place_or_ethnicity'], ['replace_profane_words_using_fuzzy'], ['replace_common_words_using_fuzzy'], ['lemmatize_english_words'], ['extract_info_from_url']]\n",
      "*******************\n",
      "[('raw', 0.7406912920931613), ('black_listed_words_regex_mapping', 0.7499725325032045), ('stemming_english_words', 0.7514657150140199)]\n",
      "convert_to_lower\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7514657150140199\n",
      "Log Loss:  1.4771768324835148\n",
      "Accuracy:  0.957231482641935\n",
      "AUC score:  0.9738381216043099\n",
      "Num of comments missclassified:  6825\n",
      "[[142437    913]\n",
      " [  5912  10318]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96015   0.99363   0.97660    143350\n",
      "          1    0.91871   0.63574   0.75147     16230\n",
      "\n",
      "avg / total    0.95593   0.95723   0.95371    159580\n",
      "\n",
      "remove_whitespaces\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7514657150140199\n",
      "Log Loss:  1.4771768324835148\n",
      "Accuracy:  0.957231482641935\n",
      "AUC score:  0.9738381216043099\n",
      "Num of comments missclassified:  6825\n",
      "[[142437    913]\n",
      " [  5912  10318]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96015   0.99363   0.97660    143350\n",
      "          1    0.91871   0.63574   0.75147     16230\n",
      "\n",
      "avg / total    0.95593   0.95723   0.95371    159580\n",
      "\n",
      "remove_leaky\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7514657150140199\n",
      "Log Loss:  1.4771768324835148\n",
      "Accuracy:  0.957231482641935\n",
      "AUC score:  0.9738381216043099\n",
      "Num of comments missclassified:  6825\n",
      "[[142437    913]\n",
      " [  5912  10318]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96015   0.99363   0.97660    143350\n",
      "          1    0.91871   0.63574   0.75147     16230\n",
      "\n",
      "avg / total    0.95593   0.95723   0.95371    159580\n",
      "\n",
      "replace_abbreviation_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7514383511761707\n",
      "Log Loss:  1.4773932729897958\n",
      "Accuracy:  0.9572252161925053\n",
      "AUC score:  0.9738387388217981\n",
      "Num of comments missclassified:  6826\n",
      "[[142436    914]\n",
      " [  5912  10318]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96015   0.99362   0.97660    143350\n",
      "          1    0.91863   0.63574   0.75144     16230\n",
      "\n",
      "avg / total    0.95592   0.95723   0.95370    159580\n",
      "\n",
      "strip_non_printable_chars\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7514657150140199\n",
      "Log Loss:  1.4771768324835148\n",
      "Accuracy:  0.957231482641935\n",
      "AUC score:  0.9738381216043099\n",
      "Num of comments missclassified:  6825\n",
      "[[142437    913]\n",
      " [  5912  10318]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96015   0.99363   0.97660    143350\n",
      "          1    0.91871   0.63574   0.75147     16230\n",
      "\n",
      "avg / total    0.95593   0.95723   0.95371    159580\n",
      "\n",
      "replace_acronyms\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7466802488449085\n",
      "Log Loss:  1.507045341754645\n",
      "Accuracy:  0.9563667126206291\n",
      "AUC score:  0.9728219503771753\n",
      "Num of comments missclassified:  6963\n",
      "[[142355    995]\n",
      " [  5968  10262]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95976   0.99306   0.97613    143350\n",
      "          1    0.91161   0.63229   0.74668     16230\n",
      "\n",
      "avg / total    0.95487   0.95637   0.95279    159580\n",
      "\n",
      "remove_stopwords\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7446052390547718\n",
      "Log Loss:  1.508776364741208\n",
      "Accuracy:  0.9563165810251911\n",
      "AUC score:  0.9717588779278341\n",
      "Num of comments missclassified:  6971\n",
      "[[142447    903]\n",
      " [  6068  10162]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95914   0.99370   0.97612    143350\n",
      "          1    0.91839   0.62612   0.74461     16230\n",
      "\n",
      "avg / total    0.95500   0.95632   0.95257    159580\n",
      "\n",
      "remove_rare_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.752326934264107\n",
      "Log Loss:  1.4743632461996923\n",
      "Accuracy:  0.9573129464845219\n",
      "AUC score:  0.9735321132542512\n",
      "Num of comments missclassified:  6812\n",
      "[[142422    928]\n",
      " [  5884  10346]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96033   0.99353   0.97664    143350\n",
      "          1    0.91769   0.63746   0.75233     16230\n",
      "\n",
      "avg / total    0.95599   0.95731   0.95383    159580\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " =========  remove_rare_words\n",
      "remove_non_alphanumeric\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.75047369188165\n",
      "Log Loss:  1.4821548639152438\n",
      "Accuracy:  0.9570873543050508\n",
      "AUC score:  0.9737794257685293\n",
      "Num of comments missclassified:  6848\n",
      "[[142434    916]\n",
      " [  5932  10298]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96002   0.99361   0.97653    143350\n",
      "          1    0.91832   0.63450   0.75047     16230\n",
      "\n",
      "avg / total    0.95578   0.95709   0.95353    159580\n",
      "\n",
      "remove_non_alphabet_words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.75047369188165\n",
      "Log Loss:  1.4821548639152438\n",
      "Accuracy:  0.9570873543050508\n",
      "AUC score:  0.9737794257685293\n",
      "Num of comments missclassified:  6848\n",
      "[[142434    916]\n",
      " [  5932  10298]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96002   0.99361   0.97653    143350\n",
      "          1    0.91832   0.63450   0.75047     16230\n",
      "\n",
      "avg / total    0.95578   0.95709   0.95353    159580\n",
      "\n",
      "remove_words_containing_non_alphabets\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.6865977814921744\n",
      "Log Loss:  1.7855981353082906\n",
      "Accuracy:  0.9483017922045369\n",
      "AUC score:  0.9540274911076195\n",
      "Num of comments missclassified:  8250\n",
      "[[142293   1057]\n",
      " [  7193   9037]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95188   0.99263   0.97183    143350\n",
      "          1    0.89528   0.55681   0.68660     16230\n",
      "\n",
      "avg / total    0.94613   0.94830   0.94282    159580\n",
      "\n",
      "check_if_proper_name_place_or_ethnicity\n",
      "Done  100000\n",
      "Done  200000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7513562716184234\n",
      "Log Loss:  1.4780425945086393\n",
      "Accuracy:  0.957206416844216\n",
      "AUC score:  0.9738382329269627\n",
      "Num of comments missclassified:  6829\n",
      "[[142433    917]\n",
      " [  5912  10318]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96015   0.99360   0.97659    143350\n",
      "          1    0.91838   0.63574   0.75136     16230\n",
      "\n",
      "avg / total    0.95590   0.95721   0.95368    159580\n",
      "\n",
      "replace_profane_words_using_fuzzy\n",
      "Done  100000\n",
      "Done  200000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7519976754322243\n",
      "Log Loss:  1.4778263243640113\n",
      "Accuracy:  0.9572126832936458\n",
      "AUC score:  0.9741190827873044\n",
      "Num of comments missclassified:  6828\n",
      "[[142400    950]\n",
      " [  5878  10352]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96036   0.99337   0.97659    143350\n",
      "          1    0.91594   0.63783   0.75200     16230\n",
      "\n",
      "avg / total    0.95584   0.95721   0.95374    159580\n",
      "\n",
      "replace_common_words_using_fuzzy\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7523716061498201\n",
      "Log Loss:  1.4745797067485211\n",
      "Accuracy:  0.9573066800350921\n",
      "AUC score:  0.9740172055822078\n",
      "Num of comments missclassified:  6813\n",
      "[[142417    933]\n",
      " [  5880  10350]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96035   0.99349   0.97664    143350\n",
      "          1    0.91731   0.63771   0.75237     16230\n",
      "\n",
      "avg / total    0.95597   0.95731   0.95383    159580\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " =========  replace_common_words_using_fuzzy\n",
      "lemmatize_english_words\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7508460390815472\n",
      "Log Loss:  1.4819385186110627\n",
      "Accuracy:  0.9570936207544805\n",
      "AUC score:  0.973877276016351\n",
      "Num of comments missclassified:  6847\n",
      "[[142416    934]\n",
      " [  5913  10317]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96014   0.99348   0.97653    143350\n",
      "          1    0.91699   0.63567   0.75085     16230\n",
      "\n",
      "avg / total    0.95575   0.95709   0.95357    159580\n",
      "\n",
      "extract_info_from_url\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7514657150140199\n",
      "Log Loss:  1.4771768324835148\n",
      "Accuracy:  0.957231482641935\n",
      "AUC score:  0.9738381216043099\n",
      "Num of comments missclassified:  6825\n",
      "[[142437    913]\n",
      " [  5912  10318]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96015   0.99363   0.97660    143350\n",
      "          1    0.91871   0.63574   0.75147     16230\n",
      "\n",
      "avg / total    0.95593   0.95723   0.95371    159580\n",
      "\n",
      "[('replace_common_words_using_fuzzy', 0.7523716061498201), ('remove_rare_words', 0.752326934264107), ('replace_profane_words_using_fuzzy', 0.7519976754322243), ('convert_to_lower', 0.7514657150140199), ('remove_whitespaces', 0.7514657150140199), ('remove_leaky', 0.7514657150140199), ('strip_non_printable_chars', 0.7514657150140199), ('extract_info_from_url', 0.7514657150140199), ('replace_abbreviation_words', 0.7514383511761707), ('check_if_proper_name_place_or_ethnicity', 0.7513562716184234), ('lemmatize_english_words', 0.7508460390815472), ('remove_non_alphanumeric', 0.75047369188165), ('remove_non_alphabet_words', 0.75047369188165), ('replace_acronyms', 0.7466802488449085), ('remove_stopwords', 0.7446052390547718), ('remove_words_containing_non_alphabets', 0.6865977814921744)]\n",
      "[['convert_to_lower'], ['remove_whitespaces'], ['remove_leaky'], ['replace_abbreviation_words'], ['strip_non_printable_chars'], ['replace_acronyms'], ['remove_stopwords'], ['remove_rare_words'], ['remove_non_alphanumeric'], ['remove_non_alphabet_words'], ['remove_words_containing_non_alphabets'], ['check_if_proper_name_place_or_ethnicity'], ['replace_profane_words_using_fuzzy'], ['lemmatize_english_words'], ['extract_info_from_url']]\n",
      "*******************\n",
      "[('raw', 0.7406912920931613), ('black_listed_words_regex_mapping', 0.7499725325032045), ('stemming_english_words', 0.7514657150140199), ('replace_common_words_using_fuzzy', 0.7523716061498201)]\n",
      "convert_to_lower\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score:  0.7523716061498201\n",
      "Log Loss:  1.4745797067485211\n",
      "Accuracy:  0.9573066800350921\n",
      "AUC score:  0.9740172055822078\n",
      "Num of comments missclassified:  6813\n",
      "[[142417    933]\n",
      " [  5880  10350]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96035   0.99349   0.97664    143350\n",
      "          1    0.91731   0.63771   0.75237     16230\n",
      "\n",
      "avg / total    0.95597   0.95731   0.95383    159580\n",
      "\n",
      "remove_whitespaces\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7523716061498201\n",
      "Log Loss:  1.4745797067485211\n",
      "Accuracy:  0.9573066800350921\n",
      "AUC score:  0.9740172055822078\n",
      "Num of comments missclassified:  6813\n",
      "[[142417    933]\n",
      " [  5880  10350]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96035   0.99349   0.97664    143350\n",
      "          1    0.91731   0.63771   0.75237     16230\n",
      "\n",
      "avg / total    0.95597   0.95731   0.95383    159580\n",
      "\n",
      "remove_leaky\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7523716061498201\n",
      "Log Loss:  1.4745797067485211\n",
      "Accuracy:  0.9573066800350921\n",
      "AUC score:  0.9740172055822078\n",
      "Num of comments missclassified:  6813\n",
      "[[142417    933]\n",
      " [  5880  10350]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96035   0.99349   0.97664    143350\n",
      "          1    0.91731   0.63771   0.75237     16230\n",
      "\n",
      "avg / total    0.95597   0.95731   0.95383    159580\n",
      "\n",
      "replace_abbreviation_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7523442611034382\n",
      "Log Loss:  1.4747961472548021\n",
      "Accuracy:  0.9573004135856623\n",
      "AUC score:  0.9740172545813677\n",
      "Num of comments missclassified:  6814\n",
      "[[142416    934]\n",
      " [  5880  10350]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96035   0.99348   0.97664    143350\n",
      "          1    0.91723   0.63771   0.75234     16230\n",
      "\n",
      "avg / total    0.95596   0.95730   0.95382    159580\n",
      "\n",
      "strip_non_printable_chars\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7523716061498201\n",
      "Log Loss:  1.4745797067485211\n",
      "Accuracy:  0.9573066800350921\n",
      "AUC score:  0.9740172055822078\n",
      "Num of comments missclassified:  6813\n",
      "[[142417    933]\n",
      " [  5880  10350]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96035   0.99349   0.97664    143350\n",
      "          1    0.91731   0.63771   0.75237     16230\n",
      "\n",
      "avg / total    0.95597   0.95731   0.95383    159580\n",
      "\n",
      "replace_acronyms\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7482207697893972\n",
      "Log Loss:  1.5007687725086036\n",
      "Accuracy:  0.956548439654092\n",
      "AUC score:  0.9730643687779933\n",
      "Num of comments missclassified:  6934\n",
      "[[142343   1007]\n",
      " [  5927  10303]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96003   0.99298   0.97622    143350\n",
      "          1    0.91096   0.63481   0.74822     16230\n",
      "\n",
      "avg / total    0.95504   0.95655   0.95303    159580\n",
      "\n",
      "remove_stopwords\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7457441367721196\n",
      "Log Loss:  1.5063957446507743\n",
      "Accuracy:  0.9563855119689184\n",
      "AUC score:  0.9718846084827433\n",
      "Num of comments missclassified:  6960\n",
      "[[142413    937]\n",
      " [  6023  10207]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95942   0.99346   0.97615    143350\n",
      "          1    0.91592   0.62890   0.74574     16230\n",
      "\n",
      "avg / total    0.95500   0.95639   0.95271    159580\n",
      "\n",
      "remove_rare_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7529052876234746\n",
      "Log Loss:  1.4726318223621806\n",
      "Accuracy:  0.9573630780799599\n",
      "AUC score:  0.9737032153119796\n",
      "Num of comments missclassified:  6804\n",
      "[[142410    940]\n",
      " [  5864  10366]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96045   0.99344   0.97667    143350\n",
      "          1    0.91686   0.63869   0.75291     16230\n",
      "\n",
      "avg / total    0.95602   0.95736   0.95391    159580\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " =========  remove_rare_words\n",
      "remove_non_alphanumeric\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7514547570555717\n",
      "Log Loss:  1.479124862178324\n",
      "Accuracy:  0.9571750845970673\n",
      "AUC score:  0.9739456680981728\n",
      "Num of comments missclassified:  6834\n",
      "[[142415    935]\n",
      " [  5899  10331]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96023   0.99348   0.97657    143350\n",
      "          1    0.91701   0.63654   0.75145     16230\n",
      "\n",
      "avg / total    0.95583   0.95718   0.95367    159580\n",
      "\n",
      "remove_non_alphabet_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7514093471540281\n",
      "Log Loss:  1.4793412976739684\n",
      "Accuracy:  0.9571688181476375\n",
      "AUC score:  0.9739457059220857\n",
      "Num of comments missclassified:  6835\n",
      "[[142415    935]\n",
      " [  5900  10330]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96022   0.99348   0.97657    143350\n",
      "          1    0.91700   0.63648   0.75141     16230\n",
      "\n",
      "avg / total    0.95582   0.95717   0.95367    159580\n",
      "\n",
      "remove_words_containing_non_alphabets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.688047310360514\n",
      "Log Loss:  1.7810530750805875\n",
      "Accuracy:  0.9484333876425617\n",
      "AUC score:  0.9541818040759995\n",
      "Num of comments missclassified:  8229\n",
      "[[142276   1074]\n",
      " [  7155   9075]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95212   0.99251   0.97189    143350\n",
      "          1    0.89418   0.55915   0.68805     16230\n",
      "\n",
      "avg / total    0.94623   0.94843   0.94303    159580\n",
      "\n",
      "check_if_proper_name_place_or_ethnicity\n",
      "Done  100000\n",
      "Done  200000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7521535274233998\n",
      "Log Loss:  1.475878334754297\n",
      "Accuracy:  0.9572690813385136\n",
      "AUC score:  0.9740168118696598\n",
      "Num of comments missclassified:  6819\n",
      "[[142414    936]\n",
      " [  5883  10347]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96033   0.99347   0.97662    143350\n",
      "          1    0.91704   0.63752   0.75215     16230\n",
      "\n",
      "avg / total    0.95593   0.95727   0.95379    159580\n",
      "\n",
      "replace_profane_words_using_fuzzy\n",
      "Done  100000\n",
      "Done  200000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7534003119219469\n",
      "Log Loss:  1.4715497200435121\n",
      "Accuracy:  0.9573944103271087\n",
      "AUC score:  0.9742105880737333\n",
      "Num of comments missclassified:  6799\n",
      "[[142395    955]\n",
      " [  5844  10386]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96058   0.99334   0.97668    143350\n",
      "          1    0.91579   0.63993   0.75340     16230\n",
      "\n",
      "avg / total    0.95602   0.95739   0.95397    159580\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " =========  replace_profane_words_using_fuzzy\n",
      "lemmatize_english_words\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7525702037999055\n",
      "Log Loss:  1.4741468658210533\n",
      "Accuracy:  0.9573192129339516\n",
      "AUC score:  0.9740894223923152\n",
      "Num of comments missclassified:  6811\n",
      "[[142411    939]\n",
      " [  5872  10358]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96040   0.99345   0.97665    143350\n",
      "          1    0.91688   0.63820   0.75257     16230\n",
      "\n",
      "avg / total    0.95597   0.95732   0.95386    159580\n",
      "\n",
      "extract_info_from_url\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7523716061498201\n",
      "Log Loss:  1.4745797067485211\n",
      "Accuracy:  0.9573066800350921\n",
      "AUC score:  0.9740172055822078\n",
      "Num of comments missclassified:  6813\n",
      "[[142417    933]\n",
      " [  5880  10350]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96035   0.99349   0.97664    143350\n",
      "          1    0.91731   0.63771   0.75237     16230\n",
      "\n",
      "avg / total    0.95597   0.95731   0.95383    159580\n",
      "\n",
      "[('replace_profane_words_using_fuzzy', 0.7534003119219469), ('remove_rare_words', 0.7529052876234746), ('lemmatize_english_words', 0.7525702037999055), ('convert_to_lower', 0.7523716061498201), ('remove_whitespaces', 0.7523716061498201), ('remove_leaky', 0.7523716061498201), ('strip_non_printable_chars', 0.7523716061498201), ('extract_info_from_url', 0.7523716061498201), ('replace_abbreviation_words', 0.7523442611034382), ('check_if_proper_name_place_or_ethnicity', 0.7521535274233998), ('remove_non_alphanumeric', 0.7514547570555717), ('remove_non_alphabet_words', 0.7514093471540281), ('replace_acronyms', 0.7482207697893972), ('remove_stopwords', 0.7457441367721196), ('remove_words_containing_non_alphabets', 0.688047310360514)]\n",
      "[['convert_to_lower'], ['remove_whitespaces'], ['remove_leaky'], ['replace_abbreviation_words'], ['strip_non_printable_chars'], ['replace_acronyms'], ['remove_stopwords'], ['remove_rare_words'], ['remove_non_alphanumeric'], ['remove_non_alphabet_words'], ['remove_words_containing_non_alphabets'], ['check_if_proper_name_place_or_ethnicity'], ['lemmatize_english_words'], ['extract_info_from_url']]\n",
      "*******************\n",
      "[('raw', 0.7406912920931613), ('black_listed_words_regex_mapping', 0.7499725325032045), ('stemming_english_words', 0.7514657150140199), ('replace_common_words_using_fuzzy', 0.7523716061498201), ('replace_profane_words_using_fuzzy', 0.7534003119219469)]\n",
      "convert_to_lower\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7534003119219469\n",
      "Log Loss:  1.4715497200435121\n",
      "Accuracy:  0.9573944103271087\n",
      "AUC score:  0.9742105880737333\n",
      "Num of comments missclassified:  6799\n",
      "[[142395    955]\n",
      " [  5844  10386]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96058   0.99334   0.97668    143350\n",
      "          1    0.91579   0.63993   0.75340     16230\n",
      "\n",
      "avg / total    0.95602   0.95739   0.95397    159580\n",
      "\n",
      "remove_whitespaces\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7534003119219469\n",
      "Log Loss:  1.4715497200435121\n",
      "Accuracy:  0.9573944103271087\n",
      "AUC score:  0.9742105880737333\n",
      "Num of comments missclassified:  6799\n",
      "[[142395    955]\n",
      " [  5844  10386]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96058   0.99334   0.97668    143350\n",
      "          1    0.91579   0.63993   0.75340     16230\n",
      "\n",
      "avg / total    0.95602   0.95739   0.95397    159580\n",
      "\n",
      "remove_leaky\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7534003119219469\n",
      "Log Loss:  1.4715497200435121\n",
      "Accuracy:  0.9573944103271087\n",
      "AUC score:  0.9742105880737333\n",
      "Num of comments missclassified:  6799\n",
      "[[142395    955]\n",
      " [  5844  10386]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96058   0.99334   0.97668    143350\n",
      "          1    0.91579   0.63993   0.75340     16230\n",
      "\n",
      "avg / total    0.95602   0.95739   0.95397    159580\n",
      "\n",
      "replace_abbreviation_words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7533824222859009\n",
      "Log Loss:  1.4715497150328753\n",
      "Accuracy:  0.9573944103271087\n",
      "AUC score:  0.9742113123157025\n",
      "Num of comments missclassified:  6799\n",
      "[[142396    954]\n",
      " [  5845  10385]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96057   0.99334   0.97668    143350\n",
      "          1    0.91587   0.63986   0.75338     16230\n",
      "\n",
      "avg / total    0.95602   0.95739   0.95397    159580\n",
      "\n",
      "strip_non_printable_chars\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7534003119219469\n",
      "Log Loss:  1.4715497200435121\n",
      "Accuracy:  0.9573944103271087\n",
      "AUC score:  0.9742105880737333\n",
      "Num of comments missclassified:  6799\n",
      "[[142395    955]\n",
      " [  5844  10386]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96058   0.99334   0.97668    143350\n",
      "          1    0.91579   0.63993   0.75340     16230\n",
      "\n",
      "avg / total    0.95602   0.95739   0.95397    159580\n",
      "\n",
      "replace_acronyms\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7489296857992889\n",
      "Log Loss:  1.497738695612132\n",
      "Accuracy:  0.9566361699461086\n",
      "AUC score:  0.9732850046882311\n",
      "Num of comments missclassified:  6920\n",
      "[[142339   1011]\n",
      " [  5909  10321]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96014   0.99295   0.97627    143350\n",
      "          1    0.91078   0.63592   0.74893     16230\n",
      "\n",
      "avg / total    0.95512   0.95664   0.95315    159580\n",
      "\n",
      "remove_stopwords\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7449505095145915\n",
      "Log Loss:  1.5113738311995082\n",
      "Accuracy:  0.956241383632034\n",
      "AUC score:  0.9719564240585016\n",
      "Num of comments missclassified:  6983\n",
      "[[142399    951]\n",
      " [  6032  10198]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95936   0.99337   0.97607    143350\n",
      "          1    0.91470   0.62834   0.74495     16230\n",
      "\n",
      "avg / total    0.95482   0.95624   0.95256    159580\n",
      "\n",
      "remove_rare_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7552609656271506\n",
      "Log Loss:  1.4624594192051796\n",
      "Accuracy:  0.9576576012031582\n",
      "AUC score:  0.9741068480409254\n",
      "Num of comments missclassified:  6757\n",
      "[[142397    953]\n",
      " [  5804  10426]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96084   0.99335   0.97682    143350\n",
      "          1    0.91625   0.64239   0.75526     16230\n",
      "\n",
      "avg / total    0.95630   0.95766   0.95429    159580\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " =========  remove_rare_words\n",
      "remove_non_alphanumeric\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7525679648651592\n",
      "Log Loss:  1.475445553954472\n",
      "Accuracy:  0.9572816142373731\n",
      "AUC score:  0.9742419333521163\n",
      "Num of comments missclassified:  6817\n",
      "[[142396    954]\n",
      " [  5863  10367]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96045   0.99334   0.97662    143350\n",
      "          1    0.91573   0.63876   0.75257     16230\n",
      "\n",
      "avg / total    0.95591   0.95728   0.95384    159580\n",
      "\n",
      "remove_non_alphabet_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7526132404181185\n",
      "Log Loss:  1.4752291184588278\n",
      "Accuracy:  0.9572878806868028\n",
      "AUC score:  0.9742431162090295\n",
      "Num of comments missclassified:  6816\n",
      "[[142396    954]\n",
      " [  5862  10368]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96046   0.99334   0.97663    143350\n",
      "          1    0.91574   0.63882   0.75261     16230\n",
      "\n",
      "avg / total    0.95591   0.95729   0.95384    159580\n",
      "\n",
      "remove_words_containing_non_alphabets\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7096485002428\n",
      "Log Loss:  1.6823583287264263\n",
      "Accuracy:  0.9512908885825292\n",
      "AUC score:  0.9599842323712091\n",
      "Num of comments missclassified:  7773\n",
      "[[142308   1042]\n",
      " [  6731   9499]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95484   0.99273   0.97342    143350\n",
      "          1    0.90115   0.58527   0.70965     16230\n",
      "\n",
      "avg / total    0.94938   0.95129   0.94659    159580\n",
      "\n",
      "check_if_proper_name_place_or_ethnicity\n",
      "Done  100000\n",
      "Done  200000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7534276387377584\n",
      "Log Loss:  1.4713332795372311\n",
      "Accuracy:  0.9574006767765384\n",
      "AUC score:  0.9742107638689652\n",
      "Num of comments missclassified:  6798\n",
      "[[142396    954]\n",
      " [  5844  10386]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96058   0.99334   0.97669    143350\n",
      "          1    0.91587   0.63993   0.75343     16230\n",
      "\n",
      "avg / total    0.95603   0.95740   0.95398    159580\n",
      "\n",
      "lemmatize_english_words\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7538500561655253\n",
      "Log Loss:  1.470251157176015\n",
      "Accuracy:  0.9574320090236872\n",
      "AUC score:  0.9743350238043507\n",
      "Num of comments missclassified:  6793\n",
      "[[142385    965]\n",
      " [  5828  10402]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96068   0.99327   0.97670    143350\n",
      "          1    0.91511   0.64091   0.75385     16230\n",
      "\n",
      "avg / total    0.95604   0.95743   0.95404    159580\n",
      "\n",
      "extract_info_from_url\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7534003119219469\n",
      "Log Loss:  1.4715497200435121\n",
      "Accuracy:  0.9573944103271087\n",
      "AUC score:  0.9742105880737333\n",
      "Num of comments missclassified:  6799\n",
      "[[142395    955]\n",
      " [  5844  10386]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96058   0.99334   0.97668    143350\n",
      "          1    0.91579   0.63993   0.75340     16230\n",
      "\n",
      "avg / total    0.95602   0.95739   0.95397    159580\n",
      "\n",
      "[('remove_rare_words', 0.7552609656271506), ('lemmatize_english_words', 0.7538500561655253), ('check_if_proper_name_place_or_ethnicity', 0.7534276387377584), ('convert_to_lower', 0.7534003119219469), ('remove_whitespaces', 0.7534003119219469), ('remove_leaky', 0.7534003119219469), ('strip_non_printable_chars', 0.7534003119219469), ('extract_info_from_url', 0.7534003119219469), ('replace_abbreviation_words', 0.7533824222859009), ('remove_non_alphabet_words', 0.7526132404181185), ('remove_non_alphanumeric', 0.7525679648651592), ('replace_acronyms', 0.7489296857992889), ('remove_stopwords', 0.7449505095145915), ('remove_words_containing_non_alphabets', 0.7096485002428)]\n",
      "[['convert_to_lower'], ['remove_whitespaces'], ['remove_leaky'], ['replace_abbreviation_words'], ['strip_non_printable_chars'], ['replace_acronyms'], ['remove_stopwords'], ['remove_non_alphanumeric'], ['remove_non_alphabet_words'], ['remove_words_containing_non_alphabets'], ['check_if_proper_name_place_or_ethnicity'], ['lemmatize_english_words'], ['extract_info_from_url']]\n",
      "*******************\n",
      "[('raw', 0.7406912920931613), ('black_listed_words_regex_mapping', 0.7499725325032045), ('stemming_english_words', 0.7514657150140199), ('replace_common_words_using_fuzzy', 0.7523716061498201), ('replace_profane_words_using_fuzzy', 0.7534003119219469), ('remove_rare_words', 0.7552609656271506)]\n",
      "convert_to_lower\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7552609656271506\n",
      "Log Loss:  1.4624594192051796\n",
      "Accuracy:  0.9576576012031582\n",
      "AUC score:  0.9741068480409254\n",
      "Num of comments missclassified:  6757\n",
      "[[142397    953]\n",
      " [  5804  10426]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96084   0.99335   0.97682    143350\n",
      "          1    0.91625   0.64239   0.75526     16230\n",
      "\n",
      "avg / total    0.95630   0.95766   0.95429    159580\n",
      "\n",
      "remove_whitespaces\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7552609656271506\n",
      "Log Loss:  1.4624594192051796\n",
      "Accuracy:  0.9576576012031582\n",
      "AUC score:  0.9741068480409254\n",
      "Num of comments missclassified:  6757\n",
      "[[142397    953]\n",
      " [  5804  10426]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96084   0.99335   0.97682    143350\n",
      "          1    0.91625   0.64239   0.75526     16230\n",
      "\n",
      "avg / total    0.95630   0.95766   0.95429    159580\n",
      "\n",
      "remove_leaky\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7552609656271506\n",
      "Log Loss:  1.4624594192051796\n",
      "Accuracy:  0.9576576012031582\n",
      "AUC score:  0.9741068480409254\n",
      "Num of comments missclassified:  6757\n",
      "[[142397    953]\n",
      " [  5804  10426]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96084   0.99335   0.97682    143350\n",
      "          1    0.91625   0.64239   0.75526     16230\n",
      "\n",
      "avg / total    0.95630   0.95766   0.95429    159580\n",
      "\n",
      "replace_abbreviation_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7552609656271506\n",
      "Log Loss:  1.4624594192051796\n",
      "Accuracy:  0.9576576012031582\n",
      "AUC score:  0.9741051631575317\n",
      "Num of comments missclassified:  6757\n",
      "[[142397    953]\n",
      " [  5804  10426]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96084   0.99335   0.97682    143350\n",
      "          1    0.91625   0.64239   0.75526     16230\n",
      "\n",
      "avg / total    0.95630   0.95766   0.95429    159580\n",
      "\n",
      "strip_non_printable_chars\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7552609656271506\n",
      "Log Loss:  1.4624594192051796\n",
      "Accuracy:  0.9576576012031582\n",
      "AUC score:  0.9741068480409254\n",
      "Num of comments missclassified:  6757\n",
      "[[142397    953]\n",
      " [  5804  10426]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96084   0.99335   0.97682    143350\n",
      "          1    0.91625   0.64239   0.75526     16230\n",
      "\n",
      "avg / total    0.95630   0.95766   0.95429    159580\n",
      "\n",
      "replace_acronyms\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.750913762530308\n",
      "Log Loss:  1.4897306674541206\n",
      "Accuracy:  0.9568680285750094\n",
      "AUC score:  0.9731945412786761\n",
      "Num of comments missclassified:  6883\n",
      "[[142322   1028]\n",
      " [  5855  10375]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96049   0.99283   0.97639    143350\n",
      "          1    0.90985   0.63925   0.75091     16230\n",
      "\n",
      "avg / total    0.95534   0.95687   0.95346    159580\n",
      "\n",
      "remove_stopwords\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7450894487039066\n",
      "Log Loss:  1.5111574207570486\n",
      "Accuracy:  0.9562476500814638\n",
      "AUC score:  0.9717271627917573\n",
      "Num of comments missclassified:  6982\n",
      "[[142394    956]\n",
      " [  6026  10204]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95940   0.99333   0.97607    143350\n",
      "          1    0.91434   0.62871   0.74509     16230\n",
      "\n",
      "avg / total    0.95482   0.95625   0.95258    159580\n",
      "\n",
      "remove_non_alphanumeric\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7542314522851655\n",
      "Log Loss:  1.4676538861325528\n",
      "Accuracy:  0.9575072064168442\n",
      "AUC score:  0.9741217581844177\n",
      "Num of comments missclassified:  6781\n",
      "[[142394    956]\n",
      " [  5825  10405]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96070   0.99333   0.97674    143350\n",
      "          1    0.91585   0.64110   0.75423     16230\n",
      "\n",
      "avg / total    0.95614   0.95751   0.95411    159580\n",
      "\n",
      "remove_non_alphabet_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7542314522851655\n",
      "Log Loss:  1.4676538861325528\n",
      "Accuracy:  0.9575072064168442\n",
      "AUC score:  0.9741220848454839\n",
      "Num of comments missclassified:  6781\n",
      "[[142394    956]\n",
      " [  5825  10405]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96070   0.99333   0.97674    143350\n",
      "          1    0.91585   0.64110   0.75423     16230\n",
      "\n",
      "avg / total    0.95614   0.95751   0.95411    159580\n",
      "\n",
      "remove_words_containing_non_alphabets\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7119779647137646\n",
      "Log Loss:  1.6747832366979831\n",
      "Accuracy:  0.9515102143125705\n",
      "AUC score:  0.9600317336182161\n",
      "Num of comments missclassified:  7738\n",
      "[[142278   1072]\n",
      " [  6666   9564]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95524   0.99252   0.97353    143350\n",
      "          1    0.89921   0.58928   0.71198     16230\n",
      "\n",
      "avg / total    0.94955   0.95151   0.94693    159580\n",
      "\n",
      "check_if_proper_name_place_or_ethnicity\n",
      "Done  100000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7551530519833364\n",
      "Log Loss:  1.4628922851858315\n",
      "Accuracy:  0.9576450683042987\n",
      "AUC score:  0.9740988667654816\n",
      "Num of comments missclassified:  6759\n",
      "[[142398    952]\n",
      " [  5807  10423]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96082   0.99336   0.97682    143350\n",
      "          1    0.91631   0.64221   0.75515     16230\n",
      "\n",
      "avg / total    0.95629   0.95765   0.95427    159580\n",
      "\n",
      "lemmatize_english_words\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7553657388975352\n",
      "Log Loss:  1.4628923453134737\n",
      "Accuracy:  0.9576450683042987\n",
      "AUC score:  0.9742261822712873\n",
      "Num of comments missclassified:  6759\n",
      "[[142386    964]\n",
      " [  5795  10435]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96089   0.99328   0.97682    143350\n",
      "          1    0.91543   0.64295   0.75537     16230\n",
      "\n",
      "avg / total    0.95627   0.95765   0.95429    159580\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " =========  lemmatize_english_words\n",
      "extract_info_from_url\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7552609656271506\n",
      "Log Loss:  1.4624594192051796\n",
      "Accuracy:  0.9576576012031582\n",
      "AUC score:  0.9741068480409254\n",
      "Num of comments missclassified:  6757\n",
      "[[142397    953]\n",
      " [  5804  10426]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96084   0.99335   0.97682    143350\n",
      "          1    0.91625   0.64239   0.75526     16230\n",
      "\n",
      "avg / total    0.95630   0.95766   0.95429    159580\n",
      "\n",
      "[('lemmatize_english_words', 0.7553657388975352), ('convert_to_lower', 0.7552609656271506), ('remove_whitespaces', 0.7552609656271506), ('remove_leaky', 0.7552609656271506), ('replace_abbreviation_words', 0.7552609656271506), ('strip_non_printable_chars', 0.7552609656271506), ('extract_info_from_url', 0.7552609656271506), ('check_if_proper_name_place_or_ethnicity', 0.7551530519833364), ('remove_non_alphanumeric', 0.7542314522851655), ('remove_non_alphabet_words', 0.7542314522851655), ('replace_acronyms', 0.750913762530308), ('remove_stopwords', 0.7450894487039066), ('remove_words_containing_non_alphabets', 0.7119779647137646)]\n",
      "[['convert_to_lower'], ['remove_whitespaces'], ['remove_leaky'], ['replace_abbreviation_words'], ['strip_non_printable_chars'], ['replace_acronyms'], ['remove_stopwords'], ['remove_non_alphanumeric'], ['remove_non_alphabet_words'], ['remove_words_containing_non_alphabets'], ['check_if_proper_name_place_or_ethnicity'], ['extract_info_from_url']]\n",
      "*******************\n",
      "[('raw', 0.7406912920931613), ('black_listed_words_regex_mapping', 0.7499725325032045), ('stemming_english_words', 0.7514657150140199), ('replace_common_words_using_fuzzy', 0.7523716061498201), ('replace_profane_words_using_fuzzy', 0.7534003119219469), ('remove_rare_words', 0.7552609656271506), ('lemmatize_english_words', 0.7553657388975352)]\n",
      "convert_to_lower\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7553657388975352\n",
      "Log Loss:  1.4628923453134737\n",
      "Accuracy:  0.9576450683042987\n",
      "AUC score:  0.9742261822712873\n",
      "Num of comments missclassified:  6759\n",
      "[[142386    964]\n",
      " [  5795  10435]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96089   0.99328   0.97682    143350\n",
      "          1    0.91543   0.64295   0.75537     16230\n",
      "\n",
      "avg / total    0.95627   0.95765   0.95429    159580\n",
      "\n",
      "remove_whitespaces\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7553657388975352\n",
      "Log Loss:  1.4628923453134737\n",
      "Accuracy:  0.9576450683042987\n",
      "AUC score:  0.9742261822712873\n",
      "Num of comments missclassified:  6759\n",
      "[[142386    964]\n",
      " [  5795  10435]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96089   0.99328   0.97682    143350\n",
      "          1    0.91543   0.64295   0.75537     16230\n",
      "\n",
      "avg / total    0.95627   0.95765   0.95429    159580\n",
      "\n",
      "remove_leaky\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7553657388975352\n",
      "Log Loss:  1.4628923453134737\n",
      "Accuracy:  0.9576450683042987\n",
      "AUC score:  0.9742261822712873\n",
      "Num of comments missclassified:  6759\n",
      "[[142386    964]\n",
      " [  5795  10435]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96089   0.99328   0.97682    143350\n",
      "          1    0.91543   0.64295   0.75537     16230\n",
      "\n",
      "avg / total    0.95627   0.95765   0.95429    159580\n",
      "\n",
      "replace_abbreviation_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7553384002895402\n",
      "Log Loss:  1.4631087858197547\n",
      "Accuracy:  0.957638801854869\n",
      "AUC score:  0.9742254726431029\n",
      "Num of comments missclassified:  6760\n",
      "[[142385    965]\n",
      " [  5795  10435]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96089   0.99327   0.97681    143350\n",
      "          1    0.91535   0.64295   0.75534     16230\n",
      "\n",
      "avg / total    0.95626   0.95764   0.95429    159580\n",
      "\n",
      "strip_non_printable_chars\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7553657388975352\n",
      "Log Loss:  1.4628923453134737\n",
      "Accuracy:  0.9576450683042987\n",
      "AUC score:  0.9742261822712873\n",
      "Num of comments missclassified:  6759\n",
      "[[142386    964]\n",
      " [  5795  10435]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96089   0.99328   0.97682    143350\n",
      "          1    0.91543   0.64295   0.75537     16230\n",
      "\n",
      "avg / total    0.95627   0.95765   0.95429    159580\n",
      "\n",
      "replace_acronyms\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.751680763391889\n",
      "Log Loss:  1.486917056117114\n",
      "Accuracy:  0.9569494924175962\n",
      "AUC score:  0.9732775997976422\n",
      "Num of comments missclassified:  6870\n",
      "[[142312   1038]\n",
      " [  5832  10398]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96063   0.99276   0.97643    143350\n",
      "          1    0.90923   0.64067   0.75168     16230\n",
      "\n",
      "avg / total    0.95541   0.95695   0.95357    159580\n",
      "\n",
      "remove_stopwords\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7398865092440052\n",
      "Log Loss:  1.5377791069765767\n",
      "Accuracy:  0.9554768768016042\n",
      "AUC score:  0.9703040107746574\n",
      "Num of comments missclassified:  7105\n",
      "[[142370    980]\n",
      " [  6125  10105]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95875   0.99316   0.97565    143350\n",
      "          1    0.91159   0.62261   0.73989     16230\n",
      "\n",
      "avg / total    0.95396   0.95548   0.95168    159580\n",
      "\n",
      "remove_non_alphanumeric\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7546623212022451\n",
      "Log Loss:  1.466355318254419\n",
      "Accuracy:  0.9575448051134228\n",
      "AUC score:  0.9742471158729125\n",
      "Num of comments missclassified:  6775\n",
      "[[142385    965]\n",
      " [  5810  10420]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96079   0.99327   0.97676    143350\n",
      "          1    0.91524   0.64202   0.75466     16230\n",
      "\n",
      "avg / total    0.95616   0.95754   0.95417    159580\n",
      "\n",
      "remove_non_alphabet_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7546623212022451\n",
      "Log Loss:  1.466355318254419\n",
      "Accuracy:  0.9575448051134228\n",
      "AUC score:  0.9742471158729125\n",
      "Num of comments missclassified:  6775\n",
      "[[142385    965]\n",
      " [  5810  10420]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96079   0.99327   0.97676    143350\n",
      "          1    0.91524   0.64202   0.75466     16230\n",
      "\n",
      "avg / total    0.95616   0.95754   0.95417    159580\n",
      "\n",
      "remove_words_containing_non_alphabets\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7122481659404909\n",
      "Log Loss:  1.672402386118254\n",
      "Accuracy:  0.9515791452562978\n",
      "AUC score:  0.9600674486330846\n",
      "Num of comments missclassified:  7727\n",
      "[[142290   1060]\n",
      " [  6667   9563]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.95524   0.99261   0.97357    143350\n",
      "          1    0.90022   0.58922   0.71225     16230\n",
      "\n",
      "avg / total    0.94965   0.95158   0.94699    159580\n",
      "\n",
      "check_if_proper_name_place_or_ethnicity\n",
      "Done  100000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7553561088592936\n",
      "Log Loss:  1.4631087908303917\n",
      "Accuracy:  0.957638801854869\n",
      "AUC score:  0.9742200040789651\n",
      "Num of comments missclassified:  6760\n",
      "[[142384    966]\n",
      " [  5794  10436]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96090   0.99326   0.97681    143350\n",
      "          1    0.91528   0.64301   0.75536     16230\n",
      "\n",
      "avg / total    0.95626   0.95764   0.95429    159580\n",
      "\n",
      "extract_info_from_url\n",
      "Done  50000\n",
      "Done  100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done  150000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.7553657388975352\n",
      "Log Loss:  1.4628923453134737\n",
      "Accuracy:  0.9576450683042987\n",
      "AUC score:  0.9742261822712873\n",
      "Num of comments missclassified:  6759\n",
      "[[142386    964]\n",
      " [  5795  10435]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96089   0.99328   0.97682    143350\n",
      "          1    0.91543   0.64295   0.75537     16230\n",
      "\n",
      "avg / total    0.95627   0.95765   0.95429    159580\n",
      "\n",
      "[('convert_to_lower', 0.7553657388975352), ('remove_whitespaces', 0.7553657388975352), ('remove_leaky', 0.7553657388975352), ('strip_non_printable_chars', 0.7553657388975352), ('extract_info_from_url', 0.7553657388975352), ('check_if_proper_name_place_or_ethnicity', 0.7553561088592936), ('replace_abbreviation_words', 0.7553384002895402), ('remove_non_alphanumeric', 0.7546623212022451), ('remove_non_alphabet_words', 0.7546623212022451), ('replace_acronyms', 0.751680763391889), ('remove_stopwords', 0.7398865092440052), ('remove_words_containing_non_alphabets', 0.7122481659404909)]\n",
      "Any other transformation not needed\n"
     ]
    }
   ],
   "source": [
    "#Loop through all the transformations to see which one gives the maximum boost to f1_score\n",
    "while(True):\n",
    "    tr_iter_score = []\n",
    "    X_best = None\n",
    "    tr_best = None\n",
    "    max_f1_local = max_f1\n",
    "    for tr in transformations:\n",
    "        pp_steps = [tr]\n",
    "        base_res, X = call_logit_to_recursive_transformation_Addition(pp_steps, word_dist_dict_most_common_copy,train_data_copy)\n",
    "        tr_iter_score.append((pp_steps[0][0], base_res))\n",
    "        if max_f1_local < base_res[tr[0]][0]:\n",
    "            max_f1_local = base_res[tr[0]][0]\n",
    "            X_best = X\n",
    "            tr_best = tr[0]  \n",
    "            print ('\\n\\n\\n ========= ', tr_best)\n",
    "    key_neg_f1 = []\n",
    "    for k in tr_iter_score:\n",
    "        key_neg_f1.append((k[0], k[1][k[0]][0]))\n",
    "    ordered = sorted(key_neg_f1,key=itemgetter(1), reverse=True)\n",
    "    print(ordered)\n",
    "    if max_f1 >= ordered[0][1]:\n",
    "        print ('Any other transformation not needed')\n",
    "        break\n",
    "    # Add transformation into the    \n",
    "    tr_scores.append(ordered[0])\n",
    "    max_f1 = ordered[0][1]\n",
    "    transformations.remove([ordered[0][0]])\n",
    "    train_data_copy['comment_text'] = X_best\n",
    "    word_dist_dict_most_common_copy = get_words_dict_most_common(train_data_copy)\n",
    "    print(transformations)\n",
    "    print ('*******************')\n",
    "    print (tr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NBSVM\n",
    "[('raw', 0.7957122242836528), ('replace_common_words_using_fuzzy', 0.7963421342134214)]\n",
    "\n",
    "#Regex\n",
    "\n",
    "[('raw', 0.7406912920931613), ('black_listed_words_regex_mapping', 0.7499725325032045),\n",
    " ('stemming_english_words', 0.7514657150140199), ('replace_common_words_using_fuzzy', 0.7523716061498201),\n",
    " ('replace_profane_words_using_fuzzy', 0.7534003119219469), ('remove_rare_words', 0.7552609656271506), \n",
    " ('lemmatize_english_words', 0.7553657388975352)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformations = [ ['raw'],  \n",
    "                    ['convert_to_lower'],\n",
    "                    ['remove_whitespaces'], \n",
    "                    ['remove_leaky'], \n",
    "                    ['replace_abbreviation_words'],\n",
    "                    ['strip_non_printable_chars'],\n",
    "                    ['replace_acronyms'],\n",
    "                    ['remove_stopwords'],\n",
    "                    ['remove_rare_words'],\n",
    "                    ['remove_non_alphanumeric'],\n",
    "                    ['remove_non_alphabet_words'],\n",
    "                    ['remove_words_containing_non_alphabets'],\n",
    "                    ['black_listed_words_regex_mapping'],\n",
    "                    ['check_if_proper_name_place_or_ethnicity'],\n",
    "                    ['replace_profane_words_using_fuzzy'],\n",
    "                    ['replace_common_words_using_fuzzy'],\n",
    "                    ['lemmatize_english_words'],\n",
    "                    ['stemming_english_words'],\n",
    "                    ['extract_info_from_url']\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5726540161164544\n",
      "Log Loss:  2.134920946619718\n",
      "Accuracy:  0.9381877428249153\n",
      "AUC score:  0.9196245355556603\n",
      "Num of comments missclassified:  9864\n",
      "[[143107    243]\n",
      " [  9621   6609]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93701   0.99830   0.96668    143350\n",
      "          1    0.96454   0.40721   0.57265     16230\n",
      "\n",
      "avg / total    0.93981   0.93819   0.92661    159580\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pp_steps = [transformations[0]]\n",
    "base_res, X = call_xgboost_to_recursive_transformation_Addition(pp_steps, word_dist_dict_most_common,train_data)\n",
    "#Get the f1_score\n",
    "tr_scores = []\n",
    "tr_scores.append((transformations[0][0], base_res[transformations[0][0]][0]))\n",
    "max_f1 = base_res[transformations[0][0]][0]\n",
    "#remove the raw transformation\n",
    "transformations.remove(pp_steps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_copy = train_data.copy()\n",
    "word_dist_dict_most_common_copy = word_dist_dict_most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert_to_lower\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5756802353246528\n",
      "Log Loss:  2.1230169442529148\n",
      "Accuracy:  0.9385323975435518\n",
      "AUC score:  0.9195745832761139\n",
      "Num of comments missclassified:  9809\n",
      "[[143117    233]\n",
      " [  9576   6654]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93729   0.99837   0.96687    143350\n",
      "          1    0.96617   0.40998   0.57568     16230\n",
      "\n",
      "avg / total    0.94022   0.93853   0.92708    159580\n",
      "\n",
      "remove_whitespaces\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5726540161164544\n",
      "Log Loss:  2.134920946619718\n",
      "Accuracy:  0.9381877428249153\n",
      "AUC score:  0.9196245355556603\n",
      "Num of comments missclassified:  9864\n",
      "[[143107    243]\n",
      " [  9621   6609]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93701   0.99830   0.96668    143350\n",
      "          1    0.96454   0.40721   0.57265     16230\n",
      "\n",
      "avg / total    0.93981   0.93819   0.92661    159580\n",
      "\n",
      "remove_leaky\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5734701831882552\n",
      "Log Loss:  2.1316743991531433\n",
      "Accuracy:  0.9382817395663617\n",
      "AUC score:  0.9197877034029273\n",
      "Num of comments missclassified:  9849\n",
      "[[143110    240]\n",
      " [  9609   6621]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93708   0.99833   0.96673    143350\n",
      "          1    0.96502   0.40795   0.57347     16230\n",
      "\n",
      "avg / total    0.93992   0.93828   0.92674    159580\n",
      "\n",
      "replace_abbreviation_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.574792243767313\n",
      "Log Loss:  2.1262634816982158\n",
      "Accuracy:  0.9384384008021055\n",
      "AUC score:  0.920157638893814\n",
      "Num of comments missclassified:  9824\n",
      "[[143116    234]\n",
      " [  9590   6640]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93720   0.99837   0.96682    143350\n",
      "          1    0.96596   0.40912   0.57479     16230\n",
      "\n",
      "avg / total    0.94012   0.93844   0.92695    159580\n",
      "\n",
      "strip_non_printable_chars\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5728638863626522\n",
      "Log Loss:  2.134704531166621\n",
      "Accuracy:  0.9381940092743452\n",
      "AUC score:  0.9197124671270438\n",
      "Num of comments missclassified:  9863\n",
      "[[143103    247]\n",
      " [  9616   6614]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93703   0.99828   0.96669    143350\n",
      "          1    0.96400   0.40752   0.57286     16230\n",
      "\n",
      "avg / total    0.93978   0.93819   0.92663    159580\n",
      "\n",
      "replace_acronyms\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5764353041988004\n",
      "Log Loss:  2.1396832290130523\n",
      "Accuracy:  0.9380498809374609\n",
      "AUC score:  0.9138121750447707\n",
      "Num of comments missclassified:  9886\n",
      "[[142967    383]\n",
      " [  9503   6727]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93767   0.99733   0.96658    143350\n",
      "          1    0.94613   0.41448   0.57644     16230\n",
      "\n",
      "avg / total    0.93853   0.93805   0.92690    159580\n",
      "\n",
      "remove_stopwords\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5642543191609731\n",
      "Log Loss:  2.16716995071536\n",
      "Accuracy:  0.9372540418598821\n",
      "AUC score:  0.9007303535396842\n",
      "Num of comments missclassified:  10013\n",
      "[[143084    266]\n",
      " [  9747   6483]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93622   0.99814   0.96619    143350\n",
      "          1    0.96059   0.39945   0.56425     16230\n",
      "\n",
      "avg / total    0.93870   0.93725   0.92531    159580\n",
      "\n",
      "remove_rare_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5607623710438888\n",
      "Log Loss:  2.1747450227012557\n",
      "Accuracy:  0.9370347161298408\n",
      "AUC score:  0.9141752272282314\n",
      "Num of comments missclassified:  10048\n",
      "[[143118    232]\n",
      " [  9816   6414]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93582   0.99838   0.96609    143350\n",
      "          1    0.96509   0.39519   0.56076     16230\n",
      "\n",
      "avg / total    0.93879   0.93703   0.92486    159580\n",
      "\n",
      "remove_non_alphanumeric\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5680246967259446\n",
      "Log Loss:  2.150287836746639\n",
      "Accuracy:  0.937742824915403\n",
      "AUC score:  0.9163370701640031\n",
      "Num of comments missclassified:  9935\n",
      "[[143113    237]\n",
      " [  9698   6532]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93654   0.99835   0.96645    143350\n",
      "          1    0.96499   0.40246   0.56802     16230\n",
      "\n",
      "avg / total    0.93943   0.93774   0.92593    159580\n",
      "\n",
      "remove_non_alphabet_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5697406715607489\n",
      "Log Loss:  2.1437947518347635\n",
      "Accuracy:  0.9379308183982955\n",
      "AUC score:  0.9164988095138317\n",
      "Num of comments missclassified:  9905\n",
      "[[143117    233]\n",
      " [  9672   6558]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93670   0.99837   0.96655    143350\n",
      "          1    0.96569   0.40407   0.56974     16230\n",
      "\n",
      "avg / total    0.93965   0.93793   0.92620    159580\n",
      "\n",
      "remove_words_containing_non_alphabets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.48238557558945916\n",
      "Log Loss:  2.423212726179658\n",
      "Accuracy:  0.9298408321844843\n",
      "AUC score:  0.8866361176246325\n",
      "Num of comments missclassified:  11196\n",
      "[[143167    183]\n",
      " [ 11013   5217]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.92857   0.99872   0.96237    143350\n",
      "          1    0.96611   0.32144   0.48239     16230\n",
      "\n",
      "avg / total    0.93239   0.92984   0.91355    159580\n",
      "\n",
      "black_listed_words_regex_mapping\n",
      "Done  100000\n",
      "Done  200000\n",
      "Done  300000\n",
      "Done  400000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.6275640497569817\n",
      "Log Loss:  1.9570119061892313\n",
      "Accuracy:  0.9433387642561725\n",
      "AUC score:  0.9306084552348617\n",
      "Num of comments missclassified:  9042\n",
      "[[142920    430]\n",
      " [  8612   7618]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.94317   0.99700   0.96934    143350\n",
      "          1    0.94657   0.46938   0.62756     16230\n",
      "\n",
      "avg / total    0.94351   0.94334   0.93458    159580\n",
      "\n",
      "check_if_proper_name_place_or_ethnicity\n",
      "Done  100000\n",
      "Done  200000\n",
      "Done  300000\n",
      "Done  400000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5731369150779895\n",
      "Log Loss:  2.132323685597529\n",
      "Accuracy:  0.9382629402180724\n",
      "AUC score:  0.919734374049701\n",
      "Num of comments missclassified:  9852\n",
      "[[143114    236]\n",
      " [  9616   6614]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93704   0.99835   0.96673    143350\n",
      "          1    0.96555   0.40752   0.57314     16230\n",
      "\n",
      "avg / total    0.93994   0.93826   0.92670    159580\n",
      "\n",
      "replace_profane_words_using_fuzzy\n",
      "Done  100000\n",
      "Done  200000\n",
      "Done  300000\n",
      "Done  400000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.6113056528264132\n",
      "Log Loss:  2.018046695918364\n",
      "Accuracy:  0.941571625516982\n",
      "AUC score:  0.9277242123116407\n",
      "Num of comments missclassified:  9324\n",
      "[[142924    426]\n",
      " [  8898   7332]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.94139   0.99703   0.96841    143350\n",
      "          1    0.94509   0.45176   0.61131     16230\n",
      "\n",
      "avg / total    0.94177   0.94157   0.93209    159580\n",
      "\n",
      "replace_common_words_using_fuzzy\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5823286255597658\n",
      "Log Loss:  2.0994254702170547\n",
      "Accuracy:  0.9392154405313949\n",
      "AUC score:  0.9242564424761682\n",
      "Num of comments missclassified:  9700\n",
      "[[143118    232]\n",
      " [  9468   6762]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93795   0.99838   0.96722    143350\n",
      "          1    0.96683   0.41664   0.58233     16230\n",
      "\n",
      "avg / total    0.94089   0.93922   0.92808    159580\n",
      "\n",
      "lemmatize_english_words\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5758845638743681\n",
      "Log Loss:  2.1247485234201697\n",
      "Accuracy:  0.9384822659481138\n",
      "AUC score:  0.9192099895532932\n",
      "Num of comments missclassified:  9817\n",
      "[[143098    252]\n",
      " [  9565   6665]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93735   0.99824   0.96684    143350\n",
      "          1    0.96357   0.41066   0.57588     16230\n",
      "\n",
      "avg / total    0.94001   0.93848   0.92707    159580\n",
      "\n",
      "stemming_english_words\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.597755865351921\n",
      "Log Loss:  2.0483468636066626\n",
      "Accuracy:  0.9406943225968166\n",
      "AUC score:  0.9263240084493465\n",
      "Num of comments missclassified:  9464\n",
      "[[143084    266]\n",
      " [  9198   7032]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93960   0.99814   0.96799    143350\n",
      "          1    0.96355   0.43327   0.59776     16230\n",
      "\n",
      "avg / total    0.94204   0.94069   0.93033    159580\n",
      "\n",
      "extract_info_from_url\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.572790294627383\n",
      "Log Loss:  2.13405518960523\n",
      "Accuracy:  0.9382128086226345\n",
      "AUC score:  0.9197569645966026\n",
      "Num of comments missclassified:  9860\n",
      "[[143110    240]\n",
      " [  9620   6610]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93701   0.99833   0.96670    143350\n",
      "          1    0.96496   0.40727   0.57279     16230\n",
      "\n",
      "avg / total    0.93986   0.93821   0.92664    159580\n",
      "\n",
      "[('black_listed_words_regex_mapping', 0.6275640497569817), ('replace_profane_words_using_fuzzy', 0.6113056528264132), ('stemming_english_words', 0.597755865351921), ('replace_common_words_using_fuzzy', 0.5823286255597658), ('replace_acronyms', 0.5764353041988004), ('lemmatize_english_words', 0.5758845638743681), ('convert_to_lower', 0.5756802353246528), ('replace_abbreviation_words', 0.574792243767313), ('remove_leaky', 0.5734701831882552), ('check_if_proper_name_place_or_ethnicity', 0.5731369150779895), ('strip_non_printable_chars', 0.5728638863626522), ('extract_info_from_url', 0.572790294627383), ('remove_whitespaces', 0.5726540161164544), ('remove_non_alphabet_words', 0.5697406715607489), ('remove_non_alphanumeric', 0.5680246967259446), ('remove_stopwords', 0.5642543191609731), ('remove_rare_words', 0.5607623710438888), ('remove_words_containing_non_alphabets', 0.48238557558945916)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['convert_to_lower'], ['remove_whitespaces'], ['remove_leaky'], ['replace_abbreviation_words'], ['strip_non_printable_chars'], ['replace_acronyms'], ['remove_stopwords'], ['remove_rare_words'], ['remove_non_alphanumeric'], ['remove_non_alphabet_words'], ['remove_words_containing_non_alphabets'], ['check_if_proper_name_place_or_ethnicity'], ['replace_profane_words_using_fuzzy'], ['replace_common_words_using_fuzzy'], ['lemmatize_english_words'], ['stemming_english_words'], ['extract_info_from_url']]\n",
      "*******************\n",
      "[('raw', 0.5726540161164544), ('black_listed_words_regex_mapping', 0.6275640497569817)]\n",
      "convert_to_lower\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5748409710502401\n",
      "Log Loss:  2.1264799322257706\n",
      "Accuracy:  0.9384321343526758\n",
      "AUC score:  0.9196984393982474\n",
      "Num of comments missclassified:  9825\n",
      "[[143113    237]\n",
      " [  9588   6642]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93721   0.99835   0.96681    143350\n",
      "          1    0.96555   0.40924   0.57484     16230\n",
      "\n",
      "avg / total    0.94009   0.93843   0.92695    159580\n",
      "\n",
      "remove_whitespaces\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.572790294627383\n",
      "Log Loss:  2.13405518960523\n",
      "Accuracy:  0.9382128086226345\n",
      "AUC score:  0.9197569645966026\n",
      "Num of comments missclassified:  9860\n",
      "[[143110    240]\n",
      " [  9620   6610]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93701   0.99833   0.96670    143350\n",
      "          1    0.96496   0.40727   0.57279     16230\n",
      "\n",
      "avg / total    0.93986   0.93821   0.92664    159580\n",
      "\n",
      "remove_leaky\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5740003462004502\n",
      "Log Loss:  2.1305922517387437\n",
      "Accuracy:  0.9383130718135104\n",
      "AUC score:  0.919643210897757\n",
      "Num of comments missclassified:  9844\n",
      "[[143104    246]\n",
      " [  9598   6632]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93715   0.99828   0.96675    143350\n",
      "          1    0.96423   0.40863   0.57400     16230\n",
      "\n",
      "avg / total    0.93990   0.93831   0.92680    159580\n",
      "\n",
      "replace_abbreviation_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5743216928469428\n",
      "Log Loss:  2.129077188237323\n",
      "Accuracy:  0.9383569369595187\n",
      "AUC score:  0.9199904438743636\n",
      "Num of comments missclassified:  9837\n",
      "[[143107    243]\n",
      " [  9594   6636]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93717   0.99830   0.96677    143350\n",
      "          1    0.96468   0.40887   0.57432     16230\n",
      "\n",
      "avg / total    0.93997   0.93836   0.92686    159580\n",
      "\n",
      "strip_non_printable_chars\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.572381818969626\n",
      "Log Loss:  2.136003129108576\n",
      "Accuracy:  0.9381564105777667\n",
      "AUC score:  0.9195976507051902\n",
      "Num of comments missclassified:  9869\n",
      "[[143106    244]\n",
      " [  9625   6605]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93698   0.99830   0.96667    143350\n",
      "          1    0.96437   0.40696   0.57238     16230\n",
      "\n",
      "avg / total    0.93977   0.93816   0.92657    159580\n",
      "\n",
      "replace_acronyms\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5750064327986962\n",
      "Log Loss:  2.1448776859191514\n",
      "Accuracy:  0.9378994861511467\n",
      "AUC score:  0.9137294573708383\n",
      "Num of comments missclassified:  9910\n",
      "[[142966    384]\n",
      " [  9526   6704]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93753   0.99732   0.96650    143350\n",
      "          1    0.94582   0.41306   0.57501     16230\n",
      "\n",
      "avg / total    0.93837   0.93790   0.92669    159580\n",
      "\n",
      "remove_stopwords\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5651417637850061\n",
      "Log Loss:  2.1643562992932583\n",
      "Accuracy:  0.9373355057024689\n",
      "AUC score:  0.9005220628388437\n",
      "Num of comments missclassified:  10000\n",
      "[[143082    268]\n",
      " [  9732   6498]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93631   0.99813   0.96623    143350\n",
      "          1    0.96039   0.40037   0.56514     16230\n",
      "\n",
      "avg / total    0.93876   0.93734   0.92544    159580\n",
      "\n",
      "remove_rare_words\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5624863590728534\n",
      "Log Loss:  2.1693341553526966\n",
      "Accuracy:  0.9371913773655847\n",
      "AUC score:  0.9143566199691778\n",
      "Num of comments missclassified:  10023\n",
      "[[143114    236]\n",
      " [  9787   6443]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93599   0.99835   0.96617    143350\n",
      "          1    0.96467   0.39698   0.56249     16230\n",
      "\n",
      "avg / total    0.93891   0.93719   0.92511    159580\n",
      "\n",
      "remove_non_alphanumeric\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5677885033481173\n",
      "Log Loss:  2.1513700242461335\n",
      "Accuracy:  0.9377114926682542\n",
      "AUC score:  0.9162161340049657\n",
      "Num of comments missclassified:  9940\n",
      "[[143111    239]\n",
      " [  9701   6529]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93652   0.99833   0.96644    143350\n",
      "          1    0.96469   0.40228   0.56779     16230\n",
      "\n",
      "avg / total    0.93938   0.93771   0.92589    159580\n",
      "\n",
      "remove_non_alphabet_words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5701133452034568\n",
      "Log Loss:  2.142496138860898\n",
      "Accuracy:  0.937968417094874\n",
      "AUC score:  0.9167192788699073\n",
      "Num of comments missclassified:  9899\n",
      "[[143117    233]\n",
      " [  9666   6564]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93673   0.99837   0.96657    143350\n",
      "          1    0.96572   0.40444   0.57011     16230\n",
      "\n",
      "avg / total    0.93968   0.93797   0.92625    159580\n",
      "\n",
      "remove_words_containing_non_alphabets\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.4844204403822186\n",
      "Log Loss:  2.4173689828291742\n",
      "Accuracy:  0.9300100263190876\n",
      "AUC score:  0.8868072635237143\n",
      "Num of comments missclassified:  11169\n",
      "[[143164    186]\n",
      " [ 10983   5247]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.92875   0.99870   0.96246    143350\n",
      "          1    0.96576   0.32329   0.48442     16230\n",
      "\n",
      "avg / total    0.93251   0.93001   0.91384    159580\n",
      "\n",
      "check_if_proper_name_place_or_ethnicity\n",
      "Done  100000\n",
      "Done  200000\n",
      "Done  300000\n",
      "Done  400000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5748150711597526\n",
      "Log Loss:  2.1273457042721686\n",
      "Accuracy:  0.9384070685549568\n",
      "AUC score:  0.9197675458362427\n",
      "Num of comments missclassified:  9829\n",
      "[[143107    243]\n",
      " [  9586   6644]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93722   0.99830   0.96680    143350\n",
      "          1    0.96472   0.40937   0.57482     16230\n",
      "\n",
      "avg / total    0.94002   0.93841   0.92693    159580\n",
      "\n",
      "replace_profane_words_using_fuzzy\n",
      "Done  100000\n",
      "Done  200000\n",
      "Done  300000\n",
      "Done  400000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.6114585939454592\n",
      "Log Loss:  2.0167480528806774\n",
      "Accuracy:  0.9416092242135606\n",
      "AUC score:  0.9274253950181179\n",
      "Num of comments missclassified:  9318\n",
      "[[142930    420]\n",
      " [  8898   7332]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.94139   0.99707   0.96843    143350\n",
      "          1    0.94582   0.45176   0.61146     16230\n",
      "\n",
      "avg / total    0.94184   0.94161   0.93213    159580\n",
      "\n",
      "replace_common_words_using_fuzzy\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5803113276702169\n",
      "Log Loss:  2.1065678415733147\n",
      "Accuracy:  0.9390086477002131\n",
      "AUC score:  0.9243471323993836\n",
      "Num of comments missclassified:  9733\n",
      "[[143118    232]\n",
      " [  9501   6729]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93775   0.99838   0.96711    143350\n",
      "          1    0.96667   0.41460   0.58031     16230\n",
      "\n",
      "avg / total    0.94069   0.93901   0.92778    159580\n",
      "\n",
      "lemmatize_english_words\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5756540540540541\n",
      "Log Loss:  2.1238827162993137\n",
      "Accuracy:  0.9385073317458328\n",
      "AUC score:  0.919228671342648\n",
      "Num of comments missclassified:  9813\n",
      "[[143111    239]\n",
      " [  9574   6656]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93730   0.99833   0.96685    143350\n",
      "          1    0.96534   0.41010   0.57565     16230\n",
      "\n",
      "avg / total    0.94015   0.93851   0.92707    159580\n",
      "\n",
      "stemming_english_words\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.5981649817347718\n",
      "Log Loss:  2.04748114667727\n",
      "Accuracy:  0.9407193883945356\n",
      "AUC score:  0.9267197740193129\n",
      "Num of comments missclassified:  9460\n",
      "[[143079    271]\n",
      " [  9189   7041]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93965   0.99811   0.96800    143350\n",
      "          1    0.96294   0.43383   0.59816     16230\n",
      "\n",
      "avg / total    0.94202   0.94072   0.93039    159580\n",
      "\n",
      "extract_info_from_url\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "Done  350000\n",
      "Done  400000\n",
      "Done  450000\n",
      "Done  500000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "F1-score:  0.572790294627383\n",
      "Log Loss:  2.13405518960523\n",
      "Accuracy:  0.9382128086226345\n",
      "AUC score:  0.9197569645966026\n",
      "Num of comments missclassified:  9860\n",
      "[[143110    240]\n",
      " [  9620   6610]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93701   0.99833   0.96670    143350\n",
      "          1    0.96496   0.40727   0.57279     16230\n",
      "\n",
      "avg / total    0.93986   0.93821   0.92664    159580\n",
      "\n",
      "[('replace_profane_words_using_fuzzy', 0.6114585939454592), ('stemming_english_words', 0.5981649817347718), ('replace_common_words_using_fuzzy', 0.5803113276702169), ('lemmatize_english_words', 0.5756540540540541), ('replace_acronyms', 0.5750064327986962), ('convert_to_lower', 0.5748409710502401), ('check_if_proper_name_place_or_ethnicity', 0.5748150711597526), ('replace_abbreviation_words', 0.5743216928469428), ('remove_leaky', 0.5740003462004502), ('remove_whitespaces', 0.572790294627383), ('extract_info_from_url', 0.572790294627383), ('strip_non_printable_chars', 0.572381818969626), ('remove_non_alphabet_words', 0.5701133452034568), ('remove_non_alphanumeric', 0.5677885033481173), ('remove_stopwords', 0.5651417637850061), ('remove_rare_words', 0.5624863590728534), ('remove_words_containing_non_alphabets', 0.4844204403822186)]\n",
      "Any other transformation not needed\n"
     ]
    }
   ],
   "source": [
    "#Loop through all the transformations to see which one gives the maximum boost to f1_score\n",
    "while(True):\n",
    "    tr_iter_score = []\n",
    "    for tr in transformations:\n",
    "        pp_steps = [tr]\n",
    "        base_res, X = call_xgboost_to_recursive_transformation_Addition(pp_steps, word_dist_dict_most_common_copy,train_data_copy)\n",
    "        tr_iter_score.append((pp_steps[0][0], base_res))\n",
    "    key_neg_f1 = []\n",
    "    for k in tr_iter_score:\n",
    "        key_neg_f1.append((k[0], k[1][k[0]][0]))\n",
    "    ordered = sorted(key_neg_f1,key=itemgetter(1), reverse=True)\n",
    "    print(ordered)\n",
    "    if max_f1 >= ordered[0][1]:\n",
    "        print ('Any other transformation not needed')\n",
    "        break\n",
    "    # Add transformation into the    \n",
    "    tr_scores.append(ordered[0])\n",
    "    max_f1 = ordered[0][1]\n",
    "    transformations.remove([ordered[0][0]])\n",
    "    train_data_copy['comment_text'] = X\n",
    "    word_dist_dict_most_common_copy = get_words_dict_most_common(train_data_copy)\n",
    "    print(transformations)\n",
    "    print ('*******************')\n",
    "    print (tr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#XGBoost\n",
    "#[('raw', 0.5726540161164544), ('black_listed_words_regex_mapping', 0.6275640497569817)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def call_fasttext_to_recursive_transformation_Addition(pp_steps, word_dist_dict_most_common,train_data):\n",
    "    combined_results = {}\n",
    "    for pp_step in pp_steps:\n",
    "        if len(pp_step) == 1:\n",
    "            new_mapped_dict = get_corresponding_mapping(word_dist_dict_most_common, pp_step[0])\n",
    "        else:\n",
    "            new_mapped_dict = get_corresponding_mapping_multiple(word_dist_dict_most_common, pp_step)\n",
    "        X = train_data['comment_text'].apply(replace_words_from_a_mapping_no_check, args = [new_mapped_dict, 0])\n",
    "        results = []\n",
    "        k_fold_num = 0\n",
    "        cv = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=42)\n",
    "        for train_index, test_index in cv.split(X, y):\n",
    "            print (\"\\n\\n *****Processing fold \", k_fold_num, \" of \", cv.n_splits, \" ......\")\n",
    "            X_train_data, X_test_data = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            texts_train = X_train_data.values\n",
    "            texts_test  = X_test_data.values\n",
    "            train = X.copy()\n",
    "            X_train, X_test, embedding_matrix = preprocess_data_for_fasttext(texts_train, texts_test, train)\n",
    "            res = call_fasttext_algorithm(X_train, y_train, X_test, y_test, embedding_matrix)\n",
    "            results.append(res)\n",
    "            k_fold_num += 1\n",
    "\n",
    "    #         if k_fold_num ==1:\n",
    "    #             break\n",
    "        scores = extract_combined_results(results)\n",
    "        combined_results[' '.join(pp_step)] = scores\n",
    "        pickle.dump(combined_results, open(\"../data/individual_fasttext.pkl\", \"wb\"))\n",
    "    return combined_results, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformations = [ \n",
    "                    ['raw'],  \n",
    "#                     ['convert_to_lower'],\n",
    "#                     ['remove_whitespaces'], \n",
    "#                     ['remove_leaky'], \n",
    "#                     ['replace_abbreviation_words'],\n",
    "#                     ['strip_non_printable_chars'],\n",
    "#                     ['replace_acronyms'],\n",
    "#                     ['remove_stopwords'],\n",
    "#                     ['remove_rare_words'],\n",
    "#                     ['remove_non_alphanumeric'],\n",
    "#                     ['remove_non_alphabet_words'],\n",
    "#                     ['remove_words_containing_non_alphabets'],\n",
    "#                     ['black_listed_words_regex_mapping'],\n",
    "#                     ['check_if_proper_name_place_or_ethnicity'],\n",
    "#                     ['replace_profane_words_using_fuzzy'],\n",
    "#                     ['replace_common_words_using_fuzzy'],\n",
    "#                     ['lemmatize_english_words'],\n",
    "#                     ['stemming_english_words'],\n",
    "#                     ['extract_info_from_url']\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8134880205081013"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tr_scores = [\n",
    "# ('raw', 0.7889988850221306), \n",
    "# ('convert_to_lower', 0.796382849014428), \n",
    "# ('remove_whitespaces',  0.788676182101062), \n",
    "# ('remove_leaky', 0.7953629698130656), \n",
    "# ('replace_abbreviation_words', 0.7906082380325877), \n",
    "# ('strip_non_printable_chars',  0.7873755274261603), \n",
    "# ('replace_acronyms', 0.7863236197365726), \n",
    "# ('remove_stopwords', 0.780157298015049), \n",
    "# ('remove_rare_words', 0.7765953852910374), \n",
    "# ('remove_non_alphanumeric',  0.7963456157502613), \n",
    "# ('remove_non_alphabet_words', 0.8008337816030123), \n",
    "# ('remove_words_containing_non_alphabets', 0.7182936479389972),\n",
    "# ('black_listed_words_regex_mapping', 0.8001469753148278),\n",
    "# ('check_if_proper_name_place_or_ethnicity', 0.8040536079751767), \n",
    "# ('replace_profane_words_using_fuzzy', 0.8038622842094997), \n",
    "# ('replace_common_words_using_fuzzy', 0.8066558387749014), \n",
    "# ('lemmatize_english_words',0.7952955287532485),\n",
    "# ('stemming_english_words',0.806138554014574),\n",
    "# ('extract_info_from_url',  0.7914496380978151)\n",
    "# ]\n",
    "\n",
    "\n",
    "tr_scores = [\n",
    " ('remove_non_alphabet_words', 0.8134880205081013),\n",
    " ('remove_non_alphanumeric', 0.8120045300113249),\n",
    " ('convert_to_lower', 0.8080052927555409),\n",
    " ('stemming_english_words', 0.806609947643979),\n",
    " ('remove_whitespaces', 0.8063916018869177),\n",
    " ('remove_leaky', 0.8051792030968432),\n",
    " ('replace_profane_words_using_fuzzy', 0.805108455942859),\n",
    " ('lemmatize_english_words', 0.8043908825405351),\n",
    " ('remove_stopwords', 0.8040699191234021),\n",
    " ('extract_info_from_url', 0.8032797858099063),\n",
    " ('black_listed_words_regex_mapping', 0.8031000563044414),\n",
    " ('strip_non_printable_chars', 0.8030237724213388),\n",
    " ('replace_abbreviation_words', 0.8023512123438649),\n",
    " ('replace_acronyms', 0.8018030139935414),\n",
    " ('check_if_proper_name_place_or_ethnicity', 0.801067907995619),\n",
    " ('remove_rare_words', 0.7990749557883281),\n",
    " ('remove_words_containing_non_alphabets', 0.7437213819897321)]\n",
    "\n",
    "max_f1 = max( [x[1] for x in tr_scores])\n",
    "max_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 180s 1ms/step - loss: 0.1302 - acc: 0.9510\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 179s 1ms/step - loss: 0.1073 - acc: 0.9594\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 179s 1ms/step - loss: 0.1020 - acc: 0.9611\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 180s 1ms/step - loss: 0.1301 - acc: 0.9514\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1064 - acc: 0.9597\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1013 - acc: 0.9616\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1274 - acc: 0.9522\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 177s 1ms/step - loss: 0.1063 - acc: 0.9591\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1015 - acc: 0.9612\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1285 - acc: 0.9523\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 176s 1ms/step - loss: 0.1067 - acc: 0.9596\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 176s 1ms/step - loss: 0.1016 - acc: 0.9610\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1310 - acc: 0.9503\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1084 - acc: 0.9586\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1031 - acc: 0.9608\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 177s 1ms/step - loss: 0.1288 - acc: 0.9521\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 177s 1ms/step - loss: 0.1068 - acc: 0.9593\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 177s 1ms/step - loss: 0.1016 - acc: 0.9616\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1310 - acc: 0.9515\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1085 - acc: 0.9592\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1021 - acc: 0.9615\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1298 - acc: 0.9513\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 177s 1ms/step - loss: 0.1077 - acc: 0.9591\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 177s 1ms/step - loss: 0.1020 - acc: 0.9611\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 179s 1ms/step - loss: 0.1278 - acc: 0.9516\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 176s 1ms/step - loss: 0.1064 - acc: 0.9594\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 177s 1ms/step - loss: 0.1006 - acc: 0.9613\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1261 - acc: 0.9529\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 177s 1ms/step - loss: 0.1061 - acc: 0.9597\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 177s 1ms/step - loss: 0.1010 - acc: 0.9611\n",
      "F1-score:  0.7825343051705849\n",
      "Log Loss:  1.3754553864021253\n",
      "Accuracy:  0.960176713873919\n",
      "AUC score:  0.9776388035522672\n",
      "Num of comments missclassified:  6355\n",
      "[[141791   1559]\n",
      " [  4796  11434]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96728   0.98912   0.97808    143350\n",
      "          1    0.88001   0.70450   0.78253     16230\n",
      "\n",
      "avg / total    0.95841   0.96018   0.95819    159580\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pp_steps = [transformations[0]]\n",
    "base_res, X = call_fasttext_to_recursive_transformation_Addition(pp_steps, word_dist_dict_most_common,train_data)\n",
    "#Get the f1_score\n",
    "tr_scores = []\n",
    "tr_scores.append((transformations[0][0], base_res[transformations[0][0]][0]))\n",
    "max_f1 = base_res[transformations[0][0]][0]\n",
    "#remove the raw transformation\n",
    "transformations.remove(pp_steps[0])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_copy = train_data.copy()\n",
    "word_dist_dict_most_common_copy = word_dist_dict_most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pp_steps = ['replace_common_words_using_fuzzy']\n",
    "# new_mapped_dict = get_corresponding_mapping_multiple(word_dist_dict_most_common, pp_steps)\n",
    "# X = train_data_copy['comment_text'].apply(replace_words_from_a_mapping_no_check, args = [new_mapped_dict, 0])\n",
    "# train_data_copy['comment_text'] = X\n",
    "# word_dist_dict_most_common_copy = get_words_dict_most_common(train_data_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black_listed_words_regex_mapping\n",
      "Done  100000\n",
      "Done  200000\n",
      "Done  300000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 179s 1ms/step - loss: 0.1228 - acc: 0.9548\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1027 - acc: 0.9613\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.0970 - acc: 0.9637\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 180s 1ms/step - loss: 0.1264 - acc: 0.9542\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 179s 1ms/step - loss: 0.1045 - acc: 0.9607\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 180s 1ms/step - loss: 0.0990 - acc: 0.9628\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1291 - acc: 0.9526\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 177s 1ms/step - loss: 0.1041 - acc: 0.9612\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 177s 1ms/step - loss: 0.0985 - acc: 0.9633\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 176s 1ms/step - loss: 0.1255 - acc: 0.9542\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 176s 1ms/step - loss: 0.1035 - acc: 0.9610\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 176s 1ms/step - loss: 0.0990 - acc: 0.9625\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 175s 1ms/step - loss: 0.1257 - acc: 0.9541\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 174s 1ms/step - loss: 0.1035 - acc: 0.9612\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 174s 1ms/step - loss: 0.0984 - acc: 0.9633\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 175s 1ms/step - loss: 0.1272 - acc: 0.9533\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 174s 1ms/step - loss: 0.1049 - acc: 0.9612\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 175s 1ms/step - loss: 0.0995 - acc: 0.9626\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 176s 1ms/step - loss: 0.1286 - acc: 0.9526\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 175s 1ms/step - loss: 0.1047 - acc: 0.9610\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 175s 1ms/step - loss: 0.1003 - acc: 0.9626\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 176s 1ms/step - loss: 0.1287 - acc: 0.9529\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 175s 1ms/step - loss: 0.1057 - acc: 0.9604\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 175s 1ms/step - loss: 0.1008 - acc: 0.9621\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 175s 1ms/step - loss: 0.1286 - acc: 0.9525\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 174s 1ms/step - loss: 0.1035 - acc: 0.9611\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 175s 1ms/step - loss: 0.0985 - acc: 0.9630\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 175s 1ms/step - loss: 0.1271 - acc: 0.9534\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 174s 1ms/step - loss: 0.1032 - acc: 0.9620\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 173s 1ms/step - loss: 0.0988 - acc: 0.9633\n",
      "F1-score:  0.8031000563044414\n",
      "Log Loss:  1.2867182361663008\n",
      "Accuracy:  0.9627459581401178\n",
      "AUC score:  0.9783840910902978\n",
      "Num of comments missclassified:  5945\n",
      "[[141511   1839]\n",
      " [  4106  12124]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.97180   0.98717   0.97943    143350\n",
      "          1    0.86829   0.74701   0.80310     16230\n",
      "\n",
      "avg / total    0.96128   0.96275   0.96149    159580\n",
      "\n",
      "check_if_proper_name_place_or_ethnicity\n",
      "Done  100000\n",
      "Done  200000\n",
      "Done  300000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 177s 1ms/step - loss: 0.1237 - acc: 0.9553\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 175s 1ms/step - loss: 0.1014 - acc: 0.9622\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 177s 1ms/step - loss: 0.0964 - acc: 0.9636\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 179s 1ms/step - loss: 0.1240 - acc: 0.9544\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1019 - acc: 0.9622\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 177s 1ms/step - loss: 0.0970 - acc: 0.9640\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1263 - acc: 0.9546\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 176s 1ms/step - loss: 0.1004 - acc: 0.9626\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 177s 1ms/step - loss: 0.0953 - acc: 0.9642\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1263 - acc: 0.9541\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 176s 1ms/step - loss: 0.1032 - acc: 0.9619\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 176s 1ms/step - loss: 0.0977 - acc: 0.9631\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 179s 1ms/step - loss: 0.1269 - acc: 0.9541\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 176s 1ms/step - loss: 0.1028 - acc: 0.9618\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 177s 1ms/step - loss: 0.0984 - acc: 0.9634\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1223 - acc: 0.9555\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 177s 1ms/step - loss: 0.1016 - acc: 0.9624\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 177s 1ms/step - loss: 0.0967 - acc: 0.9638\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 179s 1ms/step - loss: 0.1308 - acc: 0.9528\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 177s 1ms/step - loss: 0.1029 - acc: 0.9616\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 177s 1ms/step - loss: 0.0981 - acc: 0.9635\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 182s 1ms/step - loss: 0.1241 - acc: 0.9549\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 180s 1ms/step - loss: 0.1024 - acc: 0.9618\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.0976 - acc: 0.9632\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 179s 1ms/step - loss: 0.1239 - acc: 0.9550\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 177s 1ms/step - loss: 0.1018 - acc: 0.9619\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 179s 1ms/step - loss: 0.0974 - acc: 0.9633\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 180s 1ms/step - loss: 0.1246 - acc: 0.9550\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 177s 1ms/step - loss: 0.1013 - acc: 0.9624\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 177s 1ms/step - loss: 0.0972 - acc: 0.9634\n",
      "F1-score:  0.801067907995619\n",
      "Log Loss:  1.2579295343421568\n",
      "Accuracy:  0.963579395914275\n",
      "AUC score:  0.9787735948684985\n",
      "Num of comments missclassified:  5812\n",
      "[[142066   1284]\n",
      " [  4528  11702]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.96911   0.99104   0.97995    143350\n",
      "          1    0.90112   0.72101   0.80107     16230\n",
      "\n",
      "avg / total    0.96220   0.96358   0.96176    159580\n",
      "\n",
      "replace_profane_words_using_fuzzy\n",
      "Done  100000\n",
      "Done  200000\n",
      "Done  300000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 180s 1ms/step - loss: 0.1305 - acc: 0.9519\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 170s 1ms/step - loss: 0.1055 - acc: 0.9607\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 170s 1ms/step - loss: 0.0996 - acc: 0.9627\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 172s 1ms/step - loss: 0.1246 - acc: 0.9546\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 171s 1ms/step - loss: 0.1036 - acc: 0.9612\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.0987 - acc: 0.9627\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 171s 1ms/step - loss: 0.1226 - acc: 0.9550\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1037 - acc: 0.9612\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.0991 - acc: 0.9629\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 171s 1ms/step - loss: 0.1270 - acc: 0.9534\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 167s 1ms/step - loss: 0.1049 - acc: 0.9608\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 167s 1ms/step - loss: 0.1002 - acc: 0.9624\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 172s 1ms/step - loss: 0.1322 - acc: 0.9511\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1046 - acc: 0.9606\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.0997 - acc: 0.9627\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 172s 1ms/step - loss: 0.1233 - acc: 0.9549\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1030 - acc: 0.9614\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.0981 - acc: 0.9629\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 172s 1ms/step - loss: 0.1256 - acc: 0.9537\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1034 - acc: 0.9612\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.0987 - acc: 0.9626\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 171s 1ms/step - loss: 0.1305 - acc: 0.9524\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 167s 1ms/step - loss: 0.1068 - acc: 0.9604\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 167s 1ms/step - loss: 0.1022 - acc: 0.9618\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 172s 1ms/step - loss: 0.1333 - acc: 0.9510\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 167s 1ms/step - loss: 0.1051 - acc: 0.9607\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 167s 1ms/step - loss: 0.0999 - acc: 0.9624\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 172s 1ms/step - loss: 0.1281 - acc: 0.9532\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1043 - acc: 0.9613\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.0996 - acc: 0.9626\n",
      "F1-score:  0.805108455942859\n",
      "Log Loss:  1.2815241951430607\n",
      "Accuracy:  0.9628963529264318\n",
      "AUC score:  0.9779111606547062\n",
      "Num of comments missclassified:  5921\n",
      "[[141429   1921]\n",
      " [  4000  12230]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.97250   0.98660   0.97950    143350\n",
      "          1    0.86425   0.75354   0.80511     16230\n",
      "\n",
      "avg / total    0.96149   0.96290   0.96176    159580\n",
      "\n",
      "lemmatize_english_words\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 172s 1ms/step - loss: 0.1194 - acc: 0.9563\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.0984 - acc: 0.9630\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.0938 - acc: 0.9645\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 172s 1ms/step - loss: 0.1220 - acc: 0.9552\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1010 - acc: 0.9626\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.0960 - acc: 0.9640\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 173s 1ms/step - loss: 0.1216 - acc: 0.9550\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1004 - acc: 0.9623\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.0957 - acc: 0.9640\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 173s 1ms/step - loss: 0.1237 - acc: 0.9551\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1019 - acc: 0.9621\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.0968 - acc: 0.9638\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 173s 1ms/step - loss: 0.1281 - acc: 0.9535\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1032 - acc: 0.9611\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.0972 - acc: 0.9633\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 174s 1ms/step - loss: 0.1309 - acc: 0.9525\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1028 - acc: 0.9615\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.0984 - acc: 0.9633\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 173s 1ms/step - loss: 0.1234 - acc: 0.9551\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1019 - acc: 0.9620\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.0963 - acc: 0.9638\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 173s 1ms/step - loss: 0.1250 - acc: 0.9541\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1014 - acc: 0.9620\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 167s 1ms/step - loss: 0.0954 - acc: 0.9642\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 173s 1ms/step - loss: 0.1212 - acc: 0.9552\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1002 - acc: 0.9625\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 167s 1ms/step - loss: 0.0960 - acc: 0.9639\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 173s 1ms/step - loss: 0.1231 - acc: 0.9545\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 167s 1ms/step - loss: 0.1007 - acc: 0.9622\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.0962 - acc: 0.9640\n",
      "F1-score:  0.8043908825405351\n",
      "Log Loss:  1.2611775399040577\n",
      "Accuracy:  0.9634853991728287\n",
      "AUC score:  0.9789207702925828\n",
      "Num of comments missclassified:  5827\n",
      "[[141772   1578]\n",
      " [  4249  11981]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.97090   0.98899   0.97986    143350\n",
      "          1    0.88362   0.73820   0.80439     16230\n",
      "\n",
      "avg / total    0.96202   0.96349   0.96202    159580\n",
      "\n",
      "stemming_english_words\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 173s 1ms/step - loss: 0.1267 - acc: 0.9541\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1022 - acc: 0.9618\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.0962 - acc: 0.9640\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 172s 1ms/step - loss: 0.1220 - acc: 0.9554\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 166s 1ms/step - loss: 0.1010 - acc: 0.9626\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 166s 1ms/step - loss: 0.0959 - acc: 0.9636\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 173s 1ms/step - loss: 0.1259 - acc: 0.9540\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 166s 1ms/step - loss: 0.1017 - acc: 0.9620\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 167s 1ms/step - loss: 0.0962 - acc: 0.9639\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 173s 1ms/step - loss: 0.1294 - acc: 0.9524\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 167s 1ms/step - loss: 0.1032 - acc: 0.9615\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 167s 1ms/step - loss: 0.0980 - acc: 0.9632\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 173s 1ms/step - loss: 0.1225 - acc: 0.9547\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 167s 1ms/step - loss: 0.1019 - acc: 0.9618\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 167s 1ms/step - loss: 0.0963 - acc: 0.9639\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 173s 1ms/step - loss: 0.1262 - acc: 0.9542\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 167s 1ms/step - loss: 0.1019 - acc: 0.9620\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 167s 1ms/step - loss: 0.0973 - acc: 0.9635\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 174s 1ms/step - loss: 0.1233 - acc: 0.9549\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 167s 1ms/step - loss: 0.1011 - acc: 0.9624\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 167s 1ms/step - loss: 0.0957 - acc: 0.9637\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 174s 1ms/step - loss: 0.1211 - acc: 0.9558\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 167s 1ms/step - loss: 0.1014 - acc: 0.9624\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 167s 1ms/step - loss: 0.0966 - acc: 0.9638\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 174s 1ms/step - loss: 0.1205 - acc: 0.9553\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 167s 1ms/step - loss: 0.1009 - acc: 0.9621\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 167s 1ms/step - loss: 0.0960 - acc: 0.9640\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 175s 1ms/step - loss: 0.1243 - acc: 0.9547\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1031 - acc: 0.9618\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.0973 - acc: 0.9637\n",
      "F1-score:  0.806609947643979\n",
      "Log Loss:  1.2791438255844705\n",
      "Accuracy:  0.9629652838701591\n",
      "AUC score:  0.9785092794308189\n",
      "Num of comments missclassified:  5910\n",
      "[[141345   2005]\n",
      " [  3905  12325]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.97312   0.98601   0.97952    143350\n",
      "          1    0.86008   0.75940   0.80661     16230\n",
      "\n",
      "avg / total    0.96162   0.96297   0.96194    159580\n",
      "\n",
      "extract_info_from_url\n",
      "Done  50000\n",
      "Done  100000\n",
      "Done  150000\n",
      "Done  200000\n",
      "Done  250000\n",
      "Done  300000\n",
      "\n",
      "\n",
      " *****Processing fold  0  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 175s 1ms/step - loss: 0.1258 - acc: 0.9544\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 167s 1ms/step - loss: 0.1035 - acc: 0.9617\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 167s 1ms/step - loss: 0.0987 - acc: 0.9629\n",
      "\n",
      "\n",
      " *****Processing fold  1  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 174s 1ms/step - loss: 0.1265 - acc: 0.9540\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 167s 1ms/step - loss: 0.1017 - acc: 0.9619\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 167s 1ms/step - loss: 0.0968 - acc: 0.9633\n",
      "\n",
      "\n",
      " *****Processing fold  2  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 175s 1ms/step - loss: 0.1246 - acc: 0.9542\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1014 - acc: 0.9617\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 167s 1ms/step - loss: 0.0962 - acc: 0.9639\n",
      "\n",
      "\n",
      " *****Processing fold  3  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 175s 1ms/step - loss: 0.1285 - acc: 0.9521\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 167s 1ms/step - loss: 0.1046 - acc: 0.9606\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 167s 1ms/step - loss: 0.0994 - acc: 0.9623\n",
      "\n",
      "\n",
      " *****Processing fold  4  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 175s 1ms/step - loss: 0.1266 - acc: 0.9538\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 167s 1ms/step - loss: 0.1034 - acc: 0.9611\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.0981 - acc: 0.9636\n",
      "\n",
      "\n",
      " *****Processing fold  5  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 176s 1ms/step - loss: 0.1273 - acc: 0.9536\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1033 - acc: 0.9619\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.0977 - acc: 0.9636\n",
      "\n",
      "\n",
      " *****Processing fold  6  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 176s 1ms/step - loss: 0.1283 - acc: 0.9536\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1041 - acc: 0.9612\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.0986 - acc: 0.9632\n",
      "\n",
      "\n",
      " *****Processing fold  7  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 176s 1ms/step - loss: 0.1308 - acc: 0.9526\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1042 - acc: 0.9612\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.0982 - acc: 0.9634\n",
      "\n",
      "\n",
      " *****Processing fold  8  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 176s 1ms/step - loss: 0.1305 - acc: 0.9523\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 168s 1ms/step - loss: 0.1052 - acc: 0.9606\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 167s 1ms/step - loss: 0.0979 - acc: 0.9630\n",
      "\n",
      "\n",
      " *****Processing fold  9  of  10  ......\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 178s 1ms/step - loss: 0.1263 - acc: 0.9545\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.1025 - acc: 0.9618\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 169s 1ms/step - loss: 0.0983 - acc: 0.9629\n",
      "F1-score:  0.8032797858099063\n",
      "Log Loss:  1.272216105937132\n",
      "Accuracy:  0.9631658102519113\n",
      "AUC score:  0.9786177996755309\n",
      "Num of comments missclassified:  5878\n",
      "[[141701   1649]\n",
      " [  4229  12001]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.97102   0.98850   0.97968    143350\n",
      "          1    0.87919   0.73943   0.80328     16230\n",
      "\n",
      "avg / total    0.96168   0.96317   0.96174    159580\n",
      "\n",
      "[('stemming_english_words', 0.806609947643979), ('replace_profane_words_using_fuzzy', 0.805108455942859), ('lemmatize_english_words', 0.8043908825405351), ('extract_info_from_url', 0.8032797858099063), ('black_listed_words_regex_mapping', 0.8031000563044414), ('check_if_proper_name_place_or_ethnicity', 0.801067907995619)]\n",
      "Any other transformation not needed\n"
     ]
    }
   ],
   "source": [
    "#Loop through all the transformations to see which one gives the maximum boost to f1_score\n",
    "while(True):\n",
    "    tr_iter_score = []\n",
    "    for tr in transformations:\n",
    "        pp_steps = [tr]\n",
    "        base_res, X = call_fasttext_to_recursive_transformation_Addition(pp_steps, word_dist_dict_most_common_copy,train_data_copy)\n",
    "        tr_iter_score.append((pp_steps[0][0], base_res))\n",
    "    key_neg_f1 = []\n",
    "    for k in tr_iter_score:\n",
    "        key_neg_f1.append((k[0], k[1][k[0]][0]))\n",
    "    ordered = sorted(key_neg_f1,key=itemgetter(1), reverse=True)\n",
    "    print(ordered)\n",
    "    if max_f1 >= ordered[0][1]:\n",
    "        print ('Any other transformation not needed')\n",
    "        break\n",
    "    # Add transformation into the    \n",
    "    tr_scores.append(ordered[0])\n",
    "    max_f1 = ordered[0][1]\n",
    "    transformations.remove([ordered[0][0]])\n",
    "    train_data_copy['comment_text'] = X\n",
    "    word_dist_dict_most_common_copy = get_words_dict_most_common(train_data_copy)\n",
    "    print(transformations)\n",
    "    print ('*******************')\n",
    "    print (tr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = tr_scores + [('stemming_english_words', 0.806609947643979), ('replace_profane_words_using_fuzzy', 0.805108455942859), ('lemmatize_english_words', 0.8043908825405351), ('extract_info_from_url', 0.8032797858099063), ('black_listed_words_regex_mapping', 0.8031000563044414), ('check_if_proper_name_place_or_ethnicity', 0.801067907995619)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('remove_non_alphabet_words', 0.8134880205081013),\n",
       " ('remove_non_alphanumeric', 0.8120045300113249),\n",
       " ('convert_to_lower', 0.8080052927555409),\n",
       " ('stemming_english_words', 0.806609947643979),\n",
       " ('remove_whitespaces', 0.8063916018869177),\n",
       " ('remove_leaky', 0.8051792030968432),\n",
       " ('replace_profane_words_using_fuzzy', 0.805108455942859),\n",
       " ('lemmatize_english_words', 0.8043908825405351),\n",
       " ('remove_stopwords', 0.8040699191234021),\n",
       " ('extract_info_from_url', 0.8032797858099063),\n",
       " ('black_listed_words_regex_mapping', 0.8031000563044414),\n",
       " ('strip_non_printable_chars', 0.8030237724213388),\n",
       " ('replace_abbreviation_words', 0.8023512123438649),\n",
       " ('replace_acronyms', 0.8018030139935414),\n",
       " ('check_if_proper_name_place_or_ethnicity', 0.801067907995619),\n",
       " ('remove_rare_words', 0.7990749557883281),\n",
       " ('remove_words_containing_non_alphabets', 0.7437213819897321)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(z,key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#FastText\n",
    "[('raw', 0.7825343051705849), ('replace_common_words_using_fuzzy', 0.8066558387749014), ('remove_non_alphabet_words', 0.8134880205081013)]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
